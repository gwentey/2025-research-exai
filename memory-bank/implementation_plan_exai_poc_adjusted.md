# IBIS-X : Plan d'Impl√©mentation R√©vis√© (Bas√© sur Avancement Actuel)

**Objectif :** Fournir une s√©quence d'√©tapes de d√©veloppement **ajust√©e √† l'√©tat d'avancement actuel** du projet IBIS-X (tel que d√©crit dans le document "IBIS-X - Assistant IA pour d√©veloppement PoC XAI"), destin√©e √† √™tre suivie par Cursor AI.

**Bas√© sur :** PRD D√©taill√© v2 (`prd_ibis_x_poc_v2`), Tech Stack (`tech_stack_ibis_x_v2`), √âtat d'avancement fourni.

**Environnement Cible :** D√©veloppement local avec Docker & Minikube.

**Principes :** Petites √©tapes, instructions pr√©cises, test de validation, focus sur les t√¢ches restantes (‚¨ú / üöß).

---

## Phase 0 : Finalisation Infrastructure de Base et Pr√©requis

* **[‚úÖ √âtape 0.1 : Structure des Dossiers]** (Suppos√©e faite, v√©rifier si conforme)
    * **Test :** V√©rifier la pr√©sence de `frontend/`, `gateway/`, `service-selection/`, `ml-pipeline/`, `xai-engine/`, `k8s/base/`, `k8s/overlays/minikube/`, `memory-bank/` (avec PRD, TechStack, architecture.md vide, progress.md vide), `.cursor/`.
* **[‚úÖ √âtape 0.2 : Initialisation Services Backend]** (Suppos√©e faite)
    * **Test :** V√©rifier `main.py` minimal, `Dockerfile`, fichier d√©pendances dans chaque service backend.
* **[‚úÖ √âtape 0.3 : Initialisation Frontend Angular]**
    * **Instruction :** Dans `frontend/`, initialise un nouveau projet Angular (`ng new frontend --directory . --routing --style=css`). Ajoute Angular Material (`ng add @angular/material`). Choisis un th√®me.
    * **Test :** V√©rifier cr√©ation projet, ajout d√©pendances (`package.json`, `angular.json`), d√©marrage (`ng serve`).
* **[‚úÖ √âtape 0.4 : Configuration Base K8s (Base)]** (Suppos√©e pr√™te)
    * **Test :** V√©rifier pr√©sence des `Deployment`/`Service` YAML de base pour chaque microservice dans `k8s/base/`.
* **[‚úÖ √âtape 0.5 : Configuration Kustomize (Minikube)]**
    * **Instruction :** Dans `k8s/overlays/minikube/`, cr√©e `kustomization.yaml` r√©f√©ren√ßant `k8s/base/`. Ajoute les patches n√©cessaires pour Minikube (images locales, config via Secrets/ConfigMaps mont√©s).
    * **Test :** `kubectl kustomize k8s/overlays/minikube/` doit g√©n√©rer les manifestes sans erreur.
* **[‚úÖ √âtape 0.6 : Configuration Skaffold]**
    * **Instruction :** Cr√©e `skaffold.yaml`. Configure `artifacts` (build Docker pour chaque service) et `deploy` (via Kustomize `k8s/overlays/minikube/`).
    * **Test :** `skaffold build` doit r√©ussir. `skaffold run` doit tenter le d√©ploiement.
* **[‚úÖ √âtape 0.7 : D√©ploiement PostgreSQL sur Minikube]** (Suppos√©e faite)
    * **Test :** Pods 'Running', PVC 'Bound', Service existe. Connexion via `kubectl exec ... psql` r√©ussit. BDD `ibis_x_db` et user `ibis_x_user` existent.
* **[‚úÖ √âtape 0.8 : Initialisation Tables BDD (datasets, users)]** (Suppos√©e faite via Alembic ou script)
    * **Test :** V√©rifier existence des tables `datasets` et `user` (et `alembic_version`) dans la BDD.
* **[‚úÖ √âtape 0.9 : Stabilisation Environnement Local & Acc√®s]**
    * **Description :** R√©solution des probl√®mes de d√©ploiement Minikube (PVC, ClusterIssuer, Ingress). Configuration de l'acc√®s local via `skaffold dev --profile=local` et port-forwarding int√©gr√© (Frontend: `localhost:8080`, API Gateway: `localhost:9000`).
    * **Statut :** Compl√©t√© et Document√©.
* **[‚¨ú √âtape 0.10 : D√©ploiement Redis sur Minikube]**
    * **Instruction :** Cr√©e `k8s/base/redis-deployment.yaml`. Utilise image `redis:alpine`. Cr√©e `Service` (`redis-service`) ClusterIP port 6379. Applique.
    * **Test :** Pod Redis 'Running'. Connexion via `kubectl exec ... redis-cli PING` retourne `PONG`.

## Phase 1 : Module `service-selection` - Finalisation Fonctionnalit√©s

* **[‚úÖ √âtape 1.1 : Mod√®le `Dataset` SQLAlchemy & Schemas Pydantic Base]** (Suppos√© fait)
    * **Test :** V√©rifier `app/models.py` (classe `Dataset` conforme PRD) et `app/schemas.py` (schemas `DatasetBase`, `DatasetCreate`, `DatasetUpdate`, `DatasetRead` conformes PRD).
* **[‚úÖ √âtape 1.2 : Endpoints CRUD de Base]** (Suppos√© fait)
    * **Test :** V√©rifier fonctionnement `POST /datasets`, `GET /datasets` (simple), `GET /datasets/{id}`, `PUT /datasets/{id}`, `DELETE /datasets/{id}` via client API (Postman/curl).
* **[‚¨ú √âtape 1.3 : Script d'Import Initial]** (Si non fait ou √† refaire)
    * **Instruction :** Cr√©e/Finalise `scripts/import_initial_data.py` (lit `.xlsx`, conversions robustes, insertion via SQLAlchemy).
    * **Test :** Ex√©cuter script. V√©rifier peuplement table `datasets` et correction des conversions.
* **[‚¨ú √âtape 1.4 : Mod√®les Pydantic Avanc√©s]**
    * **Instruction :** Dans `app/schemas.py`, d√©finis/finalise `DatasetFilterCriteria`, `CriterionWeight`, `DatasetScoreRequest`, `DatasetScoredRead` (cf. PRD v2).
    * **Test :** V√©rifier syntaxe et structure des mod√®les Pydantic.
* **[‚¨ú √âtape 1.5 : Endpoint `GET /datasets` (Filtrage Avanc√©)]**
    * **Instruction :** Modifie/Impl√©mente la fonction CRUD `get_datasets` pour accepter `filters: schemas.DatasetFilterCriteria` et construire la requ√™te SQLAlchemy dynamiquement (texte `ilike`, bool√©ens, num√©riques).
    * **Test :** Tester via API divers filtres et combinaisons.
* **[‚¨ú √âtape 1.6 : Logique de Scoring]**
    * **Instruction :** Cr√©e/Impl√©mente `app/scoring.py` avec `calculate_relevance_score(dataset, weights_dict, normalization_stats)` (somme pond√©r√©e, focus PoC: bool√©ens + `num_citations` normalis√©).
    * **Test :** Tests unitaires (`pytest`) pour la fonction de scoring.
* **[‚¨ú √âtape 1.7 : Endpoint `POST /datasets/score` ]**
    * **Instruction :** Impl√©mente `POST /datasets/score` (valide input, filtre BDD, calcule stats normalisation, appelle `calculate_relevance_score` pour chaque, trie, retourne `List[DatasetScoredRead]`).
    * **Test :** Envoyer requ√™te POST via API avec filtres/poids. V√©rifier r√©ponse tri√©e et scores.
* **[‚¨ú √âtape 1.8 : Endpoint `GET /datasets/{id}/preview` ]** (Approche robuste recommand√©e)
    * **Instruction :** Impl√©menter (ou pr√©voir) la g√©n√©ration asynchrone (via Celery dans `ml-pipeline`?) d'un extrait lors de l'upload/validation, stock√© sur PV/Blob. Impl√©menter l'endpoint `/preview` qui lit cet extrait. *Alternative PoC : lecture dynamique si fichier sur PV.*
    * **Test :** Appeler l'endpoint pour un dataset avec preview disponible. V√©rifier le retour de l'extrait.
* **[‚¨ú √âtape 1.9 : Endpoint `GET /datasets/{id}/stats` ]**
    * **Instruction :** Impl√©menter l'endpoint `/stats`. Charger les donn√©es (ou un √©chantillon) depuis `file_reference`. Utiliser Pandas pour calculer des statistiques descriptives de base (ex: `df.describe()`, comptage valeurs manquantes par colonne). Retourner en JSON.
    * **Test :** Appeler l'endpoint. V√©rifier le retour des statistiques calcul√©es.
* **[üöß √âtape 1.10 : Finalisation D√©ploiement K8s `service-selection`]**
    * **Instruction :** Finaliser `k8s/base/service-selection-deployment.yaml`. Configurer `DATABASE_URL` via Secret. Ajouter les probes liveness/readiness (`/healthcheck`?). Mettre √† jour l'overlay Minikube. Appliquer.
    * **Test :** `kubectl apply -k k8s/overlays/minikube/`. V√©rifier que le pod est 'Running' et passe les probes. V√©rifier que les endpoints API fonctionnent via la Gateway (une fois routage configur√©).

## Phase 2 : Module `gateway` - Finalisation

* **[‚úÖ √âtape 2.1 : Authentification `fastapi-users`]** (Suppos√©e fonctionnelle)
    * **Test :** Re-v√©rifier enregistrement, login JWT, acc√®s endpoint prot√©g√© `/users/me`.
* **[‚¨ú √âtape 2.2 : Routage Reverse Proxy]**
    * **Instruction :** Impl√©mente le routage dans `gateway/main.py` (ou routeur d√©di√©) pour :
        * `/api/v1/datasets/*` -> `service-selection:8081`
        * `/api/v1/pipelines/*` -> `service-ml-pipeline:8082`
        * `/api/v1/explanations/*` -> `service-xai:8083`
        * Utilise `httpx.AsyncClient`. V√©rifie l'authentification (`Depends(current_active_user)`) AVANT de relayer.
    * **Test :** Une fois `service-selection` finalis√©, tester l'acc√®s √† ses endpoints via la gateway (`/api/v1/datasets/...`) apr√®s authentification. Tester l'acc√®s sans token (doit √©chouer).
* **[‚¨ú √âtape 2.3 : Finalisation D√©ploiement K8s `gateway`]**
    * **Instruction :** Finaliser `k8s/base/gateway-deployment.yaml`. Configurer `DATABASE_URL` et `SECRET_KEY` via Secret. Ajouter probes. Mettre √† jour overlay. Appliquer.
    * **Test :** `kubectl apply -k ...`. V√©rifier pod 'Running' et probes OK. V√©rifier fonctionnement Auth et routage vers `service-selection`.

## Phase 3 : Infrastructure Asynchrone (Celery)

* **[‚úÖ √âtape 3.1 : Redis D√©ploy√©]** (Fait √† l'√©tape 0.9)
    * **Test :** Re-v√©rifier que le service `redis-service` est accessible dans le cluster.
* **[‚¨ú √âtape 3.2 : Configuration Celery dans Services ML/XAI]**
    * **Instruction :** Dans `ml-pipeline/app/` et `xai-engine/app/`, ajoute `celery`, `redis` aux d√©pendances. Cr√©e `celery_app.py` (cf. Plan pr√©c√©dent, √âtape 4.2). Cr√©e `Dockerfile.worker` pour chaque.
    * **Test :** V√©rifier import `celery_app` OK. V√©rifier syntaxe Dockerfiles worker.
* **[‚¨ú √âtape 3.3 : D√©ploiement Worker(s) Celery]** (Pool Partag√© PoC)
    * **Instruction :** Cr√©e `k8s/base/celery-worker-deployment.yaml`. Utilise une image contenant code+deps des deux services (ou monte les volumes). CMD: `celery -A app.celery_app worker -l INFO -Q celery,ml_queue,xai_queue ...`. Configure `CELERY_BROKER_URL` via env var pointant vers `redis-service`. Applique.
    * **Test :** Pod worker 'Running'. Logs indiquent connexion √† Redis et √©coute des queues.

## Phase 4 : Module `ml-pipeline` - Impl√©mentation Compl√®te

* **[‚úÖ √âtape 4.1 : Mod√®le BDD `PipelineRun` & Migration]** (Compl√©t√© 2025-07-29)
    * **Instruction :** Dans `ml-pipeline/app/models.py`, d√©finis `PipelineRun` (cf. PRD). Configure Alembic. G√©n√®re/applique migration.
    * **Test :** Table `experiments` cr√©√©e avec tous les champs n√©cessaires.
* **[‚úÖ √âtape 4.2 : T√¢che Celery `run_ml_pipeline_task`]** (Compl√©t√© 2025-07-29)
    * **Instruction :** Dans `ml-pipeline/app/tasks.py`, impl√©mente la t√¢che compl√®te (cf. Plan pr√©c√©dent, √âtape 5.5) : MAJ statut RUNNING -> charge donn√©es (PV) -> pr√©traitement simple -> split -> instancie/entra√Æne mod√®le (ex: LogReg) -> √©value (accuracy) -> sauvegarde mod√®le (PV) -> MAJ statut SUCCESS/FAILURE + results + model_reference. Utilise la session BDD correctement.
    * **Test :** T√¢che `train_model` compl√®te avec workflow complet impl√©ment√©.
* **[‚úÖ √âtape 4.3 : API Endpoints (`POST /pipelines`, `GET /pipelines/{id}`) ]** (Compl√©t√© 2025-07-29)
    * **Instruction :** Impl√©mente les endpoints dans `ml-pipeline/main.py` (cf. Plan pr√©c√©dent, √âtapes 5.3, 5.4). Prot√©ger avec d√©pendance Auth (via gateway).
    * **Test :** Endpoints cr√©√©s : POST /experiments, GET /experiments/{id}, GET /experiments/{id}/results, GET /algorithms.
* **[‚úÖ √âtape 4.4 : Finalisation D√©ploiement K8s `ml-pipeline`]** (Compl√©t√© 2025-07-29)
    * **Instruction :** Finaliser `k8s/base/ml-pipeline-deployment.yaml` (App FastAPI) et `celery-worker-deployment.yaml` (si worker s√©par√© envisag√© plus tard, sinon le pool partag√© est d√©j√† l√†). Configurer DB/Redis URLs via Secrets. Ajouter probes. MAJ overlay. Appliquer.
    * **Test :** Deployment API et Workers Celery configur√©s avec probes et secrets.

## Phase 5 : Module `xai-engine` - Impl√©mentation Compl√®te

* **[‚¨ú √âtape 5.1 : Mod√®le BDD `ExplanationRequest` & Migration]**
    * **Instruction :** Dans `xai-engine/app/models.py`, d√©finis `ExplanationRequest` (cf. PRD). Alembic. Migration.
    * **Test :** Table `explanation_requests` cr√©√©e.
* **[‚¨ú √âtape 5.2 : T√¢che Celery `generate_explanation_task`]**
    * **Instruction :** Dans `xai-engine/app/tasks.py`, impl√©mente la t√¢che compl√®te (cf. Plan pr√©c√©dent, √âtape 6.5) : MAJ statut RUNNING -> charge mod√®le (PV) -> charge donn√©es (PV) -> s√©lectionne/ex√©cute XAI (SHAP/LIME) -> formate pour audience 'novice' -> sauvegarde r√©sultat (JSON sur PV) -> MAJ statut SUCCESS/FAILURE + results_reference.
    * **Test :** Tests unitaires. Test d√©clenchement manuel.
* **[‚¨ú √âtape 5.3 : API Endpoints (`POST /explanations`, `GET /explanations/{id}`) ]**
    * **Instruction :** Impl√©mente les endpoints dans `xai-engine/main.py` (cf. Plan pr√©c√©dent, √âtapes 6.3, 6.4). Prot√©ger.
    * **Test :** Tests d'int√©gration API via gateway. V√©rifier cr√©ation `ExplanationRequest`, d√©clenchement t√¢che, r√©cup√©ration statut/r√©f√©rence r√©sultat.
* **[‚¨ú √âtape 5.4 : Finalisation D√©ploiement K8s `xai-engine`]**
    * **Instruction :** Finaliser `k8s/base/xai-engine-deployment.yaml`. Configurer DB/Redis URLs via Secrets. Probes. MAJ overlay. Appliquer.
    * **Test :** Pod 'Running'. API r√©pond via gateway. T√¢ches s'ex√©cutent via worker.

## Phase 6 : Frontend - Impl√©mentation & Int√©gration

* **[‚¨ú √âtape 6.1 : Services & Auth]**
    * **Instruction :** Impl√©mente `AuthService`, `AuthInterceptor`. Cr√©e `AuthModule` avec composants Login/Register (utilisant `MatCard`, `MatFormField`, `MatInput`, `MatButton`).
    * **Test :** Flux connexion/d√©connexion OK, token g√©r√©, intercepteur actif.
* **[‚¨ú √âtape 6.2 : Module S√©lection Dataset]**
    * **Instruction :** Cr√©e `DatasetSelectionModule`, `dataset.service.ts`, `dataset-list.component` (formulaire filtres/poids r√©actif, bouton score, `MatTable` avec `MatPaginator`/`MatSort` pour r√©sultats).
    * **Test :** Affichage liste, filtres, scoring, tri/pagination table OK.
* **[‚úÖ √âtape 6.3 : Module Pipeline ML]** (Compl√©t√© 2025-07-29)
    * **Instruction :** Cr√©e `MLPipelineModule`, `pipeline.service.ts`, `pipeline-launcher.component` (s√©lection dataset, choix t√¢che/algo via `MatSelect`, bouton lancement, affichage statut/r√©sultats via polling et `MatCard`/`MatChip`).
    * **Test :** Wizard 5 √©tapes complet avec Angular Material, int√©gration depuis projets, suivi temps r√©el, affichage r√©sultats.
* **[‚¨ú √âtape 6.4 : Module XAI]**
    * **Instruction :** Cr√©e `XAIModule`, `explanation.service.ts`, `explanation-requester.component` (s√©lection run ML, choix audience `MatSelect`, bouton demande, affichage statut/r√©sultat simple).
    * **Test :** Demande explication OK, suivi statut OK, affichage r√©sultat (top features) OK.
* **[‚¨ú √âtape 6.5 : D√©ploiement K8s Frontend]**
    * **Instruction :** Cr√©e `Dockerfile` (build + Nginx). Finalise `k8s/base/frontend-deployment.yaml` et `service.yaml`. MAJ overlay. Applique.
    * **Test :** Pod 'Running'. Application accessible (via `minikube service` ou Ingress).

## Phase 7 : Ingress (Recommand√©)

* **[‚úÖ √âtape 7.1 : Activation & Configuration NGINX Ingress]**
    * **Instruction :** Active addon Ingress Minikube. Cr√©e `k8s/base/ingress.yaml`. D√©finit r√®gles : `/` -> frontend-service, `/api/v1/` -> gateway-service (ou directement les services si gateway simplifi√©e). Applique. *(Note: R√©alis√© sur AKS avec Helm pour Nginx et Cert-Manager)*
    * **Test :** Acc√©der √† l'IP de Minikube (`minikube ip`). V√©rifier que le frontend charge. Acc√©der √† `/api/v1/datasets` (via IP Minikube), v√©rifier r√©ponse (apr√®s login). *(Note: Test√© avec succ√®s sur les domaines publics `https://ibisx.fr/` et `https://api.ibisx.fr/`)*

## Phase 8 : Finalisation PoC et Test End-to-End

* **[‚¨ú √âtape 8.1 : V√©rification Routage Gateway Complet]**
    * **Test :** Tester via Ingress/Gateway l'acc√®s aux endpoints principaux de *tous* les services backend apr√®s authentification.
* **[‚¨ú √âtape 8.2 : Test Sc√©nario Principal E2E]**
    * **Instruction :** Ex√©cuter le sc√©nario complet depuis l'interface Angular (Login -> S√©lection -> ML -> XAI -> Logout).
    * **Test :** Le flux doit fonctionner sans erreur bloquante et les r√©sultats interm√©diaires/finaux doivent √™tre coh√©rents.
* **[‚¨ú √âtape 8.3 : Mise √† jour Documentation `memory-bank`]**
    * **Instruction :** Mettre √† jour `architecture.md` (description r√¥les/interactions services) et `progress.md` (lister √©tapes compl√©t√©es).
    * **Test :** V√©rifier que les fichiers sont √† jour et corrects.

---
