= Guide Utilisateur : Pipeline ML
:description: Guide d'utilisation de la pipeline ML d'IBIS-X pour les utilisateurs non-experts en science des donn√©es.
:sectlinks:
:sectanchors:

== Introduction √† la Pipeline ML

La *Pipeline ML d'IBIS-X* vous permet d'entra√Æner des mod√®les de machine learning sans expertise technique approfondie. Le syst√®me guide chaque √©tape du processus, depuis la s√©lection des donn√©es jusqu'√† l'√©valuation des r√©sultats.

[NOTE]
====
üéØ *Objectif*

D√©mocratiser l'acc√®s au machine learning en rendant l'entra√Ænement de mod√®les accessible √† tous, ind√©pendamment du niveau technique.
====

== Workflow Complet

=== √âtape 1 : S√©lection du Dataset

. Acc√©dez √† la section *"Datasets"* depuis le menu principal
. Utilisez les filtres pour trouver le dataset adapt√© √† votre projet
. Consultez les m√©triques de qualit√© et les d√©tails du dataset
. Cliquez sur *"S√©lectionner pour ML"* pour proc√©der

[TIP]
====
üí° *Conseil*

Privil√©giez les datasets avec :
* Score de qualit√© > 80%
* Donn√©es anonymis√©es
* Format adapt√© √† votre probl√©matique (classification/r√©gression)
====

=== √âtape 2 : Configuration du Pr√©processing

==== Analyse Automatique des Donn√©es

Le syst√®me analyse automatiquement votre dataset et fournit :

* *Vue d'ensemble* : Nombre de lignes, colonnes, usage m√©moire
* *Types de colonnes* : Num√©riques, cat√©gorielles, dates
* *Donn√©es manquantes* : Pourcentage et patterns par colonne  
* *Outliers* : D√©tection via m√©thodes IQR et Z-Score
* *Score de qualit√©* : Note globale de 0 √† 100

==== Configuration Recommand√©e

Le syst√®me propose automatiquement :

[cols="1,2,3"]
|===
|Param√®tre |Recommandation |Explication

|*Colonne cible*
|Derni√®re colonne du dataset
|Variable √† pr√©dire

|*Type de t√¢che*
|Classification ou R√©gression
|Bas√© sur le type de la colonne cible

|*Gestion valeurs manquantes*
|Strat√©gie optimale par colonne
|Moyenne, m√©diane, mode ou KNN selon le type

|*Normalisation*
|Recommand√©e si √©chelles diff√©rentes
|Am√©liore la performance des algorithmes

|*Split train/test*
|80% / 20%
|Proportion standard pour √©valuation
|===

[WARNING]
====
‚ö†Ô∏è *Attention*

Si le score de qualit√© est < 60%, consid√©rez :
* Nettoyer le dataset manuellement
* Contacter l'√©quipe support pour assistance
* Choisir un dataset alternatif
====

=== √âtape 3 : S√©lection de l'Algorithme

==== Algorithmes Disponibles

[cols="1,2,2,3"]
|===
|Algorithme |Classification |R√©gression |Cas d'Usage Recommand√©s

|*Decision Tree*
|‚úÖ Oui
|‚úÖ Oui
|* Donn√©es petites √† moyennes
* Besoin d'interpr√©tabilit√©
* Premi√®re approche

|*Random Forest*
|‚úÖ Oui  
|‚úÖ Oui
|* Tous types de datasets
* Meilleure performance g√©n√©rale
* Robuste aux outliers
|===

==== Hyperparam√®tres Simplifi√©s

Pour chaque algorithme, le syst√®me propose des param√®tres optimis√©s avec explications :

===== Decision Tree

* *Profondeur maximum* (1-50) : Contr√¥le la complexit√© de l'arbre
  ** Faible (5) = Mod√®le simple, moins de surapprentissage
  ** √âlev√©e (20+) = Mod√®le complexe, risque de surapprentissage

* *Crit√®re de division* : 
  ** `gini` = Standard pour classification
  ** `entropy` = Alternative, parfois plus pr√©cise

===== Random Forest

* *Nombre d'arbres* (10-500) : Plus d'arbres = meilleure performance mais plus lent
* *Profondeur maximum* : M√™me principe que Decision Tree
* *Bootstrap* : Utilisation d'√©chantillons al√©atoires (recommand√© : activ√©)

[TIP]
====
üí° *Conseil d√©butant*

Commencez avec les valeurs par d√©faut sugg√©r√©es. Vous pourrez exp√©rimenter avec des param√®tres personnalis√©s une fois familiaris√© avec le syst√®me.
====

=== √âtape 4 : Lancement et Suivi

==== Soumission de l'Exp√©rience

. V√©rifiez le r√©sum√© de votre configuration
. Cliquez sur *"Lancer l'Entra√Ænement"*
. L'exp√©rience est mise en file d'attente automatiquement

==== Suivi en Temps R√©el

L'interface affiche :

* *Statut* : En attente ‚Üí En cours ‚Üí Termin√©/√âchou√©
* *Progression* : Barre de progression de 0 √† 100%
* *√âtape actuelle* : Chargement ‚Üí Pr√©processing ‚Üí Entra√Ænement ‚Üí √âvaluation
* *Temps √©coul√©* : Dur√©e depuis le lancement

[cols="1,2,3"]
|===
|Statut |Signification |Action

|*En attente*
|Exp√©rience en file d'attente
|Patientez, sera trait√©e automatiquement

|*En cours*
|Entra√Ænement en cours d'ex√©cution
|Suivez la progression, n'interrompez pas

|*Termin√©*
|Entra√Ænement r√©ussi
|Consultez les r√©sultats

|*√âchou√©*
|Erreur pendant l'entra√Ænement
|Consultez l'erreur, ajustez la configuration
|===

==== Annulation d'Exp√©rience

Vous pouvez annuler une exp√©rience :
* En attente : Annulation imm√©diate
* En cours : Arr√™t propre du processus (peut prendre quelques minutes)

== Interpr√©tation des R√©sultats

=== M√©triques de Performance

==== Classification

[cols="1,2,3"]
|===
|M√©trique |Interpr√©tation |Valeur Id√©ale

|*Accuracy (Pr√©cision)*
|Pourcentage de pr√©dictions correctes
|> 80% = Excellent, 60-80% = Bon, < 60% = √Ä am√©liorer

|*Precision*
|Parmi les pr√©dictions positives, combien sont correctes
|> 0.8 = Tr√®s bon, 0.6-0.8 = Acceptable

|*Recall (Rappel)*
|Parmi les vrais positifs, combien sont d√©tect√©s
|> 0.8 = Tr√®s bon, d√©pend du cas d'usage

|*F1-Score*
|Moyenne harmonique de Precision et Recall
|> 0.8 = Excellent √©quilibre
|===

==== R√©gression

[cols="1,2,3"]
|===
|M√©trique |Interpr√©tation |Valeur Id√©ale

|*MAE (Erreur Absolue Moyenne)*
|Erreur moyenne en unit√©s originales
|Plus faible = meilleur

|*RMSE (Racine de l'Erreur Quadratique)*
|P√©nalise davantage les grosses erreurs
|Plus faible = meilleur

|*R¬≤ (Coefficient de D√©termination)*
|Pourcentage de variance expliqu√©e
|> 0.8 = Excellent, 0.6-0.8 = Bon, < 0.6 = M√©diocre
|===

=== Visualisations Explicatives

==== Matrice de Confusion (Classification)

[source]
----
         Pr√©dites
R√©elles    A    B    C
    A     85    3    2    (90 vrais A)
    B      5   78    7    (90 vrais B)  
    C      1    4   85    (90 vrais C)
----

* *Diagonale* : Pr√©dictions correctes (plus √©lev√©e = mieux)
* *Hors diagonale* : Erreurs de classification

==== Importance des Features

Graphique montrant quelles variables influencent le plus les pr√©dictions :

[source]
----
Age                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 25%
Revenu             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   20%
√âducation          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     15%
R√©gion             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       12%
Experience         ‚ñà‚ñà‚ñà‚ñà         8%
...
----

[TIP]
====
üí° *Utilisation pratique*

Les features les plus importantes sont celles sur lesquelles vous devriez concentrer vos efforts de collecte et d'am√©lioration des donn√©es.
====

==== Courbe ROC (Classification Binaire)

Mesure la capacit√© du mod√®le √† distinguer entre deux classes :

* *AUC = 0.5* : Mod√®le al√©atoire (pas mieux qu'une pi√®ce de monnaie)
* *AUC = 0.7-0.8* : Performance acceptable
* *AUC = 0.8-0.9* : Bonne performance
* *AUC > 0.9* : Excellente performance

== Gestion des Quotas

=== Limites Utilisateur

[cols="1,2,3"]
|===
|Quota |Limite |Objectif

|*Exp√©riences simultan√©es*
|5
|√âviter la surcharge syst√®me

|*Exp√©riences par jour*
|20
|Usage raisonnable des ressources

|*Stockage total*
|1 GB
|Limite de stockage des mod√®les

|*Exp√©riences totales*
|100
|Limite globale par utilisateur
|===

=== Gestion Intelligente

* *Auto-nettoyage* : Anciens mod√®les supprim√©s apr√®s 30 jours
* *Priorisation* : Files d'attente avec priorit√© utilisateur
* *Alertes proactives* : Notification avant d'atteindre les limites

== Cas d'Usage Pratiques

=== Exemple 1 : Pr√©diction de Performance √âtudiante

. *Dataset* : Notes, assiduit√©, donn√©es socio-√©conomiques
. *Objectif* : Pr√©dire le risque d'√©chec scolaire
. *Configuration recommand√©e* :
  ** Algorithme : Random Forest
  ** Colonne cible : "√©chec_scolaire" (Oui/Non)
  ** Pr√©processing : Gestion des absences avec m√©diane

. *Interpr√©tation* :
  ** F1-Score > 0.75 = Mod√®le utilisable pour intervention pr√©coce
  ** Features importantes = Facteurs de risque √† surveiller

=== Exemple 2 : Analyse de Satisfaction Client

. *Dataset* : Enqu√™tes de satisfaction, donn√©es d'usage
. *Objectif* : Pr√©dire la note de satisfaction (1-10)
. *Configuration recommand√©e* :
  ** Algorithme : Random Forest
  ** Type : R√©gression
  ** Pr√©processing : Normalisation recommand√©e

. *Interpr√©tation* :
  ** R¬≤ > 0.6 = Mod√®le explique bien la satisfaction
  ** MAE < 1.0 = Erreur acceptable d'un point

== D√©pannage Utilisateur

=== Probl√®mes Fr√©quents

[cols="1,2,3"]
|===
|Probl√®me |Sympt√¥me |Solution

|*Dataset incompatible*
|Erreur lors du chargement
|V√©rifiez le format, contactez le support

|*Entra√Ænement tr√®s long*
|> 2h sans progression
|Utilisez un √©chantillon plus petit

|*M√©triques faibles*
|Accuracy < 60%
|Changez d'algorithme ou de pr√©processing

|*Quota atteint*
|Impossible de lancer
|Attendez la fin d'autres exp√©riences

|*Exp√©rience bloqu√©e*
|Statut "En cours" > 4h
|Annulez et relancez
|===

=== Optimisation des R√©sultats

==== Si les performances sont d√©cevantes :

. *V√©rifiez la qualit√© des donn√©es*
  ** Score < 70% ? Nettoyez le dataset
  ** Beaucoup de valeurs manquantes ? Changez la strat√©gie

. *Exp√©rimentez avec les algorithmes*
  ** Decision Tree pour commencer (rapide, interpr√©table)
  ** Random Forest pour am√©liorer la performance

. *Ajustez les hyperparam√®tres*
  ** Augmentez le nombre d'arbres (Random Forest)
  ** Modifiez la profondeur maximum
  ** Testez diff√©rents crit√®res de division

. *Reconfigurez le pr√©processing*
  ** Changez la strat√©gie de valeurs manquantes
  ** Activez/d√©sactivez la normalisation
  ** Ajustez le split train/test

== Interface Utilisateur

=== Navigation

. *Tableau de bord* ‚Üí Vue d'ensemble de vos exp√©riences
. *Nouvelle exp√©rience* ‚Üí Lancer un entra√Ænement
. *Historique* ‚Üí Consulter les exp√©riences pass√©es
. *Monitoring* ‚Üí Suivre les performances syst√®me

=== Indicateurs Visuels

* üü¢ *Vert* : Exp√©rience r√©ussie, m√©triques bonnes
* üü° *Orange* : Exp√©rience termin√©e, performance √† am√©liorer
* üî¥ *Rouge* : Exp√©rience √©chou√©e, erreur √† corriger
* üîµ *Bleu* : Exp√©rience en cours, patientez

=== Notifications

Le syst√®me vous notifie automatiquement :

* üìß *Par email* : Fin d'entra√Ænement (succ√®s/√©chec)
* üîî *Dans l'interface* : Changement de statut en temps r√©el
* üìä *Alertes quotas* : Approche des limites

== Bonnes Pratiques

=== Pr√©paration des Donn√©es

. *V√©rifiez la qualit√©* avant de lancer l'entra√Ænement
. *Comprenez vos variables* : Que signifie chaque colonne ?
. *D√©finissez clairement l'objectif* : Que voulez-vous pr√©dire ?
. *Validez la logique m√©tier* : Le mod√®le a-t-il un sens ?

=== Exp√©rimentation M√©thodique

. *Commencez simple* : Decision Tree avec param√®tres par d√©faut
. *√âtablissez une baseline* : Premier mod√®le comme r√©f√©rence
. *It√©rez progressivement* : Un param√®tre √† la fois
. *Documentez vos tests* : Notez ce qui fonctionne

=== Interpr√©tation Responsable

. *Contextualisez les r√©sultats* : 80% d'accuracy est-il suffisant pour votre cas ?
. *Identifiez les biais* : Le mod√®le est-il √©quitable pour tous les groupes ?
. *Validez sur nouveaux donn√©es* : Le mod√®le fonctionne-t-il sur d'autres cas ?
. *Communiquez les limites* : Soyez transparent sur les incertitudes

== Support et Assistance

=== Ressources d'Aide

* *FAQ int√©gr√©e* : R√©ponses aux questions fr√©quentes
* *Tooltips contextuels* : Aide directe dans l'interface
* *Exemples interactifs* : Cas d'usage pr√™ts √† tester
* *Documentation technique* : Pour aller plus loin

=== Contacts

* *Support technique* : support@ibis-x.fr
* *Formation utilisateur* : formation@ibis-x.fr
* *Retours et suggestions* : feedback@ibis-x.fr

[NOTE]
====
üìö *Formation recommand√©e*

Pour maximiser l'efficacit√© d'IBIS-X, nous recommandons de suivre la formation d'introduction au machine learning (2h en ligne).
====

== Glossaire

[cols="1,3"]
|===
|Terme |D√©finition

|*Accuracy*
|Pourcentage de pr√©dictions correctes sur l'ensemble de test

|*Algorithme*
|M√©thode math√©matique utilis√©e pour apprendre des patterns dans les donn√©es

|*Classification*
|Pr√©diction de cat√©gories (Ex: Spam/Non-spam, Succ√®s/√âchec)

|*Dataset*
|Ensemble de donn√©es structur√©es utilis√©es pour l'entra√Ænement

|*Feature*
|Variable d'entr√©e du mod√®le (colonne du dataset)

|*Hyperparam√®tre*
|Param√®tre de configuration de l'algorithme

|*Overfitting*
|Surapprentissage - le mod√®le m√©morise au lieu d'apprendre

|*Pipeline*
|S√©quence automatis√©e de traitements des donn√©es

|*Preprocessing*
|Pr√©paration et nettoyage des donn√©es avant entra√Ænement

|*R√©gression*
|Pr√©diction de valeurs num√©riques (Ex: Prix, Temp√©rature)

|*Split Train/Test*
|Division des donn√©es entre entra√Ænement et √©valuation

|*Target*
|Variable √† pr√©dire (colonne cible du dataset)
|===

== Conclusion

La Pipeline ML d'IBIS-X vous accompagne dans toutes les √©tapes de l'entra√Ænement de mod√®les, de la pr√©paration des donn√©es √† l'interpr√©tation des r√©sultats. Le syst√®me intelligent propose des configurations optimales tout en vous laissant la libert√© d'exp√©rimenter.

[IMPORTANT]
====
üéì *Apprentissage continu*

Plus vous utilisez le syst√®me, plus vous d√©velopperez votre intuition pour :
* Choisir les bons algorithmes
* Configurer les hyperparam√®tres
* Interpr√©ter les r√©sultats
* Optimiser la qualit√© des donn√©es
====
