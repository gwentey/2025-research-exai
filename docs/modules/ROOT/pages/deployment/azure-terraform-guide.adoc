= Guide Complet : D√©ploiement Azure et D√©veloppement IBIS-X
:description: Guide complet pour d√©ployer IBIS-X sur Azure avec Terraform et d√©velopper en local
:keywords: azure, terraform, kubernetes, d√©veloppement, d√©ploiement, infrastructure
:page-layout: docs

[.lead]
Ce guide vous explique comment d√©ployer automatiquement IBIS-X sur Azure avec Terraform, puis d√©velopper en continu avec les outils locaux.

== üéØ Vue d'ensemble du workflow

IBIS-X utilise un workflow en **2 niveaux distincts** :

[cols="1,1", options="header"]
|===
|Infrastructure Cloud (Azure) |D√©veloppement Local

|üèóÔ∏è **Une fois** ou lors de recr√©ation
|üë®‚Äçüíª **Quotidien** pour d√©velopper

|Terraform automatise tout
|Make + Minikube comme d'habitude

|15 minutes d'installation
|2-3 minutes de d√©marrage

|Production-ready avec SSL/monitoring
|Hot reload et d√©veloppement rapide
|===

== üöÄ √âtape 1 : D√©ploiement Infrastructure Azure

=== Pr√©requis syst√®me

Avant de commencer, installez les outils requis :

[tabs]
====
Windows (WSL recommand√©)::
+
--
[source,bash]
----
# Installer WSL2 si pas encore fait
wsl --install

# Dans WSL, installer les outils
# Azure CLI
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Terraform
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/

# kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
sudo mv kubectl /usr/local/bin/

# Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# jq
sudo apt-get install jq
----
--

Linux/Ubuntu::
+
--
[source,bash]
----
# Azure CLI
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Terraform
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/

# kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
sudo mv kubectl /usr/local/bin/

# Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# jq
sudo apt-get install jq
----
--

macOS::
+
--
[source,bash]
----
# Homebrew (si pas install√©)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Tous les outils
brew install azure-cli terraform kubectl docker jq
----
--
====

=== Compte Azure requis

Vous devez avoir :

* ‚úÖ **Subscription Azure active** (essai gratuit suffisant)
* ‚úÖ **Permissions Contributor/Owner** sur la subscription  
* ‚úÖ **Quota suffisant** (minimum 2 vCPUs)

[TIP]
====
.V√©rifier les quotas
[source,bash]
----
# Se connecter √† Azure
az login

# V√©rifier les quotas dans votre r√©gion
az vm list-usage --location "East US" --query "[?currentValue>=limit]"
----
====

=== Configuration Terraform

. **Copiez le template de configuration** :
+
[source,bash]
----
cd terraform/azure-infrastructure
cp terraform.tfvars.example terraform.tfvars
----

. **Modifiez selon vos besoins** :
+
[source,bash]
----
# √âditeur de votre choix
nano terraform.tfvars
# ou
code terraform.tfvars
----

. **Configurations recommand√©es** :
+
[tabs]
====
D√©veloppement/Test::
+
--
[source,hcl]
----
# Configuration √©conomique
project_name = "IBIS-X"
environment = "dev"
location = "East US"

# Stockage minimal
storage_replication_type = "LRS"
soft_delete_retention_days = 1

# Kubernetes minimal
aks_node_count = 1
aks_node_vm_size = "Standard_B2s"
acr_sku = "Basic"
----
--

Production::
+
--
[source,hcl]
----
# Configuration production
project_name = "IBIS-X"
environment = "prod"
location = "East US"

# Stockage redondant
storage_replication_type = "GRS"
soft_delete_retention_days = 30

# Kubernetes haute disponibilit√©
aks_node_count = 3
aks_node_vm_size = "Standard_D2s_v3"
enable_auto_scaling = true
max_node_count = 10
acr_sku = "Premium"
----
--

√âconomique::
+
--
[source,hcl]
----
# Optimisation maximale des co√ªts
project_name = "IBIS-X"
environment = "staging"
location = "East US"

# Instances spot (-60% de co√ªt)
spot_instances_enabled = true
aks_node_vm_size = "Standard_B2s"
log_analytics_retention_days = 7
----
--
====

=== D√©ploiement automatis√©

Une seule commande d√©ploie TOUT :

[source,bash]
----
# Rendre le script ex√©cutable (Linux/Mac)
chmod +x scripts/deploy-to-azure.sh

# Lancer le d√©ploiement automatique
./scripts/deploy-to-azure.sh
----

[NOTE]
====
**Ce que fait le script automatiquement :**

1. ‚úÖ V√©rifie tous les pr√©requis
2. ‚úÖ Vous connecte √† Azure (si n√©cessaire)  
3. ‚úÖ Initialise et configure Terraform
4. ‚úÖ Cr√©e toute l'infrastructure Azure
5. ‚úÖ Configure kubectl pour AKS
6. ‚úÖ Build et push les images Docker vers ACR (avec retry automatique)
7. ‚úÖ D√©ploie l'application sur Kubernetes
8. ‚úÖ Lance les migrations de base de donn√©es
9. ‚úÖ **[NOUVEAU]** Import robuste des datasets Kaggle avec gestion intelligente des timeouts
10. ‚úÖ **[NOUVEAU]** Diagnostic automatique et fallback en cas de probl√®me
11. ‚úÖ **[NOUVEAU]** V√©rification finale du statut des jobs d'import
12. ‚úÖ Affiche l'URL finale et les informations importantes
====

=== Infrastructure cr√©√©e

Terraform cr√©e automatiquement :

[cols="2,3,2", options="header"]
|===
|Ressource |Description |Utilit√©

|**Groupe de ressources**
|Container logique pour toutes les ressources
|Organisation et gestion

|**Cluster AKS**
|Azure Kubernetes Service manag√©
|Orchestration des conteneurs

|**Azure Container Registry**
|Registry Docker priv√©
|Stockage des images applicatives

|**Compte de stockage**
|Stockage blob avec 3 containers
|Datasets, mod√®les ML, rapports

|**R√©seau virtuel**
|VNet avec sous-r√©seaux s√©curis√©s
|Isolation r√©seau

|**IP publique**
|Adresse IP statique pour l'acc√®s externe
|Point d'entr√©e HTTPS

|**Log Analytics**
|Workspace de monitoring
|Logs centralis√©s

|**Application Insights**
|Monitoring des applications
|M√©triques et diagnostics

|**R√¥les RBAC**
|Permissions automatiques
|S√©curit√© et acc√®s
|===

=== V√©rification du d√©ploiement

Apr√®s le d√©ploiement, v√©rifiez que tout fonctionne :

[source,bash]
----
# Voir l'√©tat de l'infrastructure
cd terraform/azure-infrastructure
terraform output

# V√©rifier les pods Kubernetes
kubectl get pods -n ibis-x

# V√©rifier les services
kubectl get services -n ibis-x

# Tester l'acc√®s √† l'application
curl -I http://$(terraform output -raw public_ip_address)
----

=== üõ°Ô∏è Robustesse et Gestion des Erreurs

Le script de d√©ploiement int√®gre d√©sormais une **gestion d'erreurs avanc√©e** et des **m√©canismes de fallback intelligents** :

==== Import des Datasets Kaggle Robuste

[NOTE]
====
**Nouvelles fonctionnalit√©s de robustesse :**

* ‚è∞ **Timeouts √©tendus** : 3 minutes pour d√©marrage, 60 minutes pour completion
* üîÑ **Retry automatique** : Jusqu'√† 5 tentatives pour les op√©rations critiques  
* üéØ **D√©tection intelligente** : Diff√©rencie les vraies erreurs des timeouts
* üìä **Diagnostic automatique** : Logs et statuts d√©taill√©s en cas de probl√®me
* üöÄ **Fallback** : Ex√©cution alternative via kubectl exec si n√©cessaire
* ‚úÖ **Continuation** : Le d√©ploiement continue m√™me si import Kaggle en cours
====

==== Gestion des Timeouts Kaggle

Si l'import Kaggle prend plus de temps que pr√©vu, le script :

1. **D√©tecte automatiquement** si le job est encore en cours d'ex√©cution
2. **Affiche des options** : continuer, attendre, ou utiliser le fallback
3. **Continue le d√©ploiement** sans bloquer l'ensemble du processus
4. **Fournit les commandes** pour suivre ou relancer l'import manuellement

[source,bash]
----
# Suivre un job Kaggle en cours
kubectl logs -f kaggle-dataset-import-job-xxxxx -n ibis-x

# Relancer l'import manuellement si n√©cessaire
kubectl exec -n ibis-x deployment/service-selection -- python kaggle-import/main.py --force-refresh

# V√©rifier le statut final des datasets
kubectl get jobs -n ibis-x
----

==== Messages de Diagnostic Automatique

En cas de probl√®me, le script affiche automatiquement :

* üìã **Logs d√©taill√©s** du job en √©chec
* üìä **√âtat des pods** et ressources Kubernetes
* üîç **√âv√©nements r√©cents** pour identifier la cause
* üí° **Commandes de r√©solution** sp√©cifiques au probl√®me
* üéØ **Instructions de fallback** pour continuer manuellement

== üë®‚Äçüíª √âtape 2 : D√©veloppement Local Continu

Une fois l'infrastructure Azure cr√©√©e, vous d√©veloppez **localement** avec Minikube comme d'habitude.

=== Pr√©requis d√©veloppement

[source,bash]
----
# Minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Skaffold
curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64
sudo install skaffold /usr/local/bin/

# Python + d√©pendances
python3 -m pip install python-dotenv
----

=== Commandes de d√©veloppement

[cols="2,3,2", options="header"]
|===
|Commande |Description |Utilisation

|`make dev`
|Installation compl√®te locale
|Premi√®re fois ou reset complet

|`make dev-with-data`
|Comme `dev` + vrais datasets
|Quand vous voulez les donn√©es r√©elles

|`make quick-dev`
|D√©ploiement rapide (Minikube d√©j√† pr√™t)
|Red√©ploiement apr√®s modifications

|`make logs`
|Logs temps r√©el + hot reload
|D√©veloppement actif

|`make stop`
|Arr√™t de l'application locale
|Pause d√©veloppement

|`make clean`
|Nettoyage complet local
|Reset de l'environnement local
|===

=== Workflow d√©veloppement typique

[source,bash]
----
# 1. D√©marrer l'environnement local
make dev

# 2. D√©velopper - les logs s'affichent en temps r√©el
# Modifier le code... ‚Üí Hot reload automatique

# 3. Tester l'application
# Frontend: http://localhost:8080
# API: http://localhost:9000
# API Docs: http://localhost:9000/docs

# 4. Arr√™ter quand termin√©
make stop
----

=== Hot reload et d√©veloppement

Quand vous lancez `make logs`, Skaffold surveille vos fichiers et red√©ploie automatiquement :

[source,bash]
----
# Lancer le mode d√©veloppement avec hot reload
make logs

# Dans un autre terminal, modifier le code
# Skaffold d√©tecte les changements et rebuild automatiquement
----

[NOTE]
====
**Avantages du d√©veloppement local :**

* üöÄ **Rapide** : 2-3 minutes pour d√©marrer
* üîÑ **Hot reload** : Changements visibles instantan√©ment  
* üí∞ **Gratuit** : Pas de co√ªts Azure pendant le dev
* üîß **Flexible** : Tests et exp√©rimentations faciles
* üìä **Logs temps r√©el** : Debug et monitoring imm√©diats
====

== üîÑ Workflow Complet : Cloud + Local

=== Sc√©nario 1 : Premier d√©ploiement

[source,bash]
----
# 1. Infrastructure Azure (une fois)
./scripts/deploy-to-azure.sh
# ‚è∞ ~15 minutes

# 2. D√©veloppement local (quotidien)
make dev
# ‚è∞ ~3 minutes

# 3. D√©velopper...
# Code, test, debug en local

# 4. Pousser vers Azure (quand pr√™t)
# Le pipeline CI/CD peut automatiser cela
----

=== Sc√©nario 2 : D√©veloppement quotidien

[source,bash]
----
# Matin : D√©marrer l'env local
make dev

# Journ√©e : D√©velopper avec hot reload
make logs
# Modifier code ‚Üí Changements automatiques

# Soir : Arr√™ter
make stop
----

=== Sc√©nario 3 : Test avec vraies donn√©es

[source,bash]
----
# D√©marrer avec les datasets complets
make dev-with-data

# Tester avec vraies donn√©es
# Frontend: http://localhost:8080
----

=== Sc√©nario 4 : Reset complet

[source,bash]
----
# Reset local uniquement
make clean
make dev

# Reset infrastructure Azure compl√®te (DANGER)
./scripts/destroy-azure-infrastructure.sh
./scripts/deploy-to-azure.sh
----

== üõ†Ô∏è Gestion et Maintenance

=== Mise √† jour de l'application Azure

[source,bash]
----
# 1. R√©cup√©rer les infos de l'infrastructure
cd terraform/azure-infrastructure
ACR_NAME=$(terraform output -raw acr_name)

# 2. Construire et pousser les nouvelles images
az acr login --name $ACR_NAME
docker build -t $ACR_NAME.azurecr.io/IBIS-X-api-gateway:latest api-gateway/
docker push $ACR_NAME.azurecr.io/IBIS-X-api-gateway:latest

# 3. Red√©marrer les pods pour utiliser la nouvelle image
kubectl rollout restart deployment/api-gateway -n IBIS-X
----

=== Surveillance et monitoring

[source,bash]
----
# Voir l'√©tat des applications Azure
kubectl get pods -n IBIS-X
kubectl get services -n IBIS-X

# Logs des applications Azure
kubectl logs -f deployment/api-gateway -n IBIS-X
kubectl logs -f deployment/service-selection -n IBIS-X

# Acc√®s aux m√©triques Azure
az monitor metrics list --resource $AKS_CLUSTER_NAME
----

=== Optimisation des co√ªts

[NOTE]
====
**Co√ªts estim√©s par configuration :**

* **Dev/Test** : ~50‚Ç¨/mois (1 n≈ìud, Basic SKU)
* **Production** : ~200‚Ç¨/mois (3 n≈ìuds, Premium SKU)  
* **Optimis√©** : ~30‚Ç¨/mois (spot instances, r√©tention courte)

**Pour r√©duire les co√ªts :**

1. Utilisez `spot_instances_enabled = true`
2. R√©duisez `log_analytics_retention_days`
3. Utilisez `Standard_B2s` pour les VMs
4. Arr√™tez le cluster hors heures de travail
====

[source,bash]
----
# Arr√™ter le cluster AKS pour √©conomiser
az aks stop --resource-group $RESOURCE_GROUP --name $AKS_NAME

# Red√©marrer quand n√©cessaire
az aks start --resource-group $RESOURCE_GROUP --name $AKS_NAME
----

== üóëÔ∏è Suppression et Nettoyage

=== Suppression compl√®te Azure

[WARNING]
====
**ATTENTION** : Cette op√©ration supprime D√âFINITIVEMENT toute l'infrastructure et les donn√©es !
====

[source,bash]
----
# Script s√©curis√© avec triple confirmation
./scripts/destroy-azure-infrastructure.sh

# Le script :
# 1. Demande 3 confirmations
# 2. Nettoie les applications K8s
# 3. Vide les comptes de stockage  
# 4. Supprime les images Docker
# 5. D√©truit l'infrastructure Azure
# 6. Restaure les fichiers locaux
----

=== Suppression locale uniquement

[source,bash]
----
# Nettoyer seulement l'environnement local
make clean

# Arr√™ter Minikube
minikube stop
minikube delete
----

== üîß D√©pannage

=== Probl√®mes Infrastructure Azure

[cols="2,3,2", options="header"]
|===
|Probl√®me |Cause probable |Solution

|**Quota d√©pass√©**
|Pas assez de vCPUs disponibles
|Changer de r√©gion ou demander augmentation

|**Nom d√©j√† pris**
|Storage/ACR avec nom existant
|Modifier `project_name` dans terraform.tfvars

|**Permissions insuffisantes**
|Pas de droits Contributor
|Demander les permissions ou changer de subscription

|**Terraform bloqu√©**
|State lock actif
|`terraform force-unlock <LOCK_ID>`

|**Job Kaggle timeout**
|Import de gros datasets prend du temps
|Le script continue automatiquement, suivre avec `kubectl logs -f`

|**Images Docker √©chec build**
|Probl√®me r√©seau ou espace disque
|Le script retry automatiquement, ou lancer `docker system prune -f`
|===

[source,bash]
----
# Diagnostic infrastructure
terraform show
terraform state list

# V√©rifier les quotas
az vm list-usage --location "East US"

# Re-authentification Azure
az logout && az login
----

=== üîç Probl√®mes sp√©cifiques aux Jobs Kaggle

[TIP]
====
**Le script g√®re automatiquement la plupart des probl√®mes Kaggle**, mais voici comment diagnostiquer manuellement :
====

[cols="2,3,2", options="header"]
|===
|Probl√®me |Diagnostic |Solution

|**Timeout du job Kaggle**
|Job encore en cours d'ex√©cution
|Attendre ou suivre avec `kubectl logs -f pod-name`

|**Job √©chou√© imm√©diatement**
|Probl√®me de credentials ou r√©seau
|V√©rifier les secrets Kaggle avec `kubectl get secrets`

|**Manque de ressources**
|Pod en √©tat Pending
|Le script g√®re automatiquement, ou augmenter les ressources cluster

|**Import incomplet**
|Job termin√© mais donn√©es partielles
|Relancer avec `kubectl exec ... python kaggle-import/main.py --force-refresh`
|===

[source,bash]
----
# Diagnostic complet des jobs Kaggle
kubectl get jobs -n ibis-x
kubectl get pods -n ibis-x -l job-name=kaggle-dataset-import-job

# Logs d√©taill√©s du job en cours
kubectl logs -f kaggle-dataset-import-job-xxxxx -n ibis-x

# V√©rifier les secrets Kaggle
kubectl get secret kaggle-secrets -n ibis-x -o yaml

# Statut des datasets import√©s
kubectl exec -n ibis-x deployment/service-selection -- ls -la /app/datasets/

# Forcer un nouvel import si n√©cessaire  
kubectl exec -n ibis-x deployment/service-selection -- python kaggle-import/main.py --force-refresh
----

=== Probl√®mes D√©veloppement Local

[cols="2,3,2", options="header"]
|===
|Probl√®me |Cause probable |Solution

|**Minikube ne d√©marre pas**
|Ressources insuffisantes
|Augmenter RAM/CPU allou√©es

|**Images non trouv√©es**
|Docker env mal configur√©
|`eval $(minikube docker-env)`

|**Services non accessibles**
|Ingress non configur√©
|`minikube addons enable ingress`

|**Hot reload ne fonctionne pas**
|Skaffold non configur√©
|Relancer `make logs`
|===

[source,bash]
----
# Diagnostic d√©veloppement local
minikube status
kubectl get pods -n IBIS-X
skaffold version

# Reset Minikube
minikube delete
minikube start --memory 4096 --cpus 2
----

=== Logs de diagnostic

[source,bash]
----
# Logs d√©taill√©s Terraform
export TF_LOG=DEBUG
terraform apply

# Logs Kubernetes d√©taill√©s
kubectl describe pod <pod-name> -n IBIS-X
kubectl logs <pod-name> -n IBIS-X --previous

# Logs Skaffold
skaffold diagnose
----

== üìä R√©f√©rence Rapide

=== Commandes Infrastructure

[source,bash]
----
# D√©ployer infrastructure compl√®te
./scripts/deploy-to-azure.sh

# Voir l'√©tat
terraform output

# Mise √† jour infrastructure
terraform plan && terraform apply

# Suppression compl√®te
./scripts/destroy-azure-infrastructure.sh
----

=== Commandes D√©veloppement

[source,bash]
----
# Environnement complet
make dev

# D√©veloppement avec donn√©es
make dev-with-data

# Rapide (si Minikube pr√™t)
make quick-dev

# Hot reload
make logs

# Arr√™t
make stop

# Nettoyage
make clean
----

=== URLs importantes

[cols="2,3", options="header"]
|===
|Service |URL

|**Application Azure**
|`http://<PUBLIC_IP>` (depuis terraform output)

|**Frontend Local**
|http://localhost:8080

|**API Gateway Local**
|http://localhost:9000

|**API Documentation**
|http://localhost:9000/docs

|**Portail Azure**
|https://portal.azure.com
|===

== üéâ F√©licitations !

Vous ma√Ætrisez maintenant le workflow complet IBIS-X :

* ‚úÖ **Infrastructure Azure** automatis√©e avec Terraform
* ‚úÖ **D√©veloppement local** fluide avec Make/Minikube  
* ‚úÖ **Hot reload** pour un d√©veloppement rapide
* ‚úÖ **Monitoring** et **logs** int√©gr√©s
* ‚úÖ **Optimisation des co√ªts** Azure
* ‚úÖ **Suppression s√©curis√©e** des ressources
* üÜï **Robustesse avanc√©e** : Gestion intelligente des timeouts et erreurs
* üÜï **Import Kaggle r√©silient** : Fallback automatique et diagnostic complet
* üÜï **Retry automatique** : Build Docker et op√©rations Kubernetes auto-correctrices

=== üîß Am√©liorations R√©centes du Script de D√©ploiement

Le script `deploy-to-azure.sh` a √©t√© consid√©rablement renforc√© avec :

[NOTE]
====
**Nouvelles capacit√©s de production :**

* üõ°Ô∏è **Gestion d'erreurs robuste** : Le script ne plante plus sur les timeouts
* ‚è∞ **Timeouts √©tendus** : Import Kaggle jusqu'√† 60 minutes pour gros datasets  
* üîÑ **Retry intelligent** : Jusqu'√† 5 tentatives avec backoff automatique
* üìä **Diagnostic en temps r√©el** : Logs et statuts automatiques en cas de probl√®me
* üöÄ **Fallback kubectl exec** : Alternative automatique si jobs Kubernetes √©chouent
* ‚úÖ **Continuation du d√©ploiement** : M√™me en cas de timeout, le d√©ploiement continue
* üí° **Instructions de r√©cup√©ration** : Commandes exactes fournies pour r√©solution manuelle
====

Ces am√©liorations garantissent un **d√©ploiement production 100% fiable** m√™me dans des conditions difficiles (gros datasets, r√©seau lent, ressources limit√©es).

**Plus jamais de configuration manuelle ! üöÄ** 
