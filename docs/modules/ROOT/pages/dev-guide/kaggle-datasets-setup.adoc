= Configuration des Datasets Kaggle - Architecture UUID
:description: Guide de configuration et utilisation des vrais datasets Kaggle avec architecture UUID dans IBIS-X
:keywords: kaggle, datasets, configuration, uuid, credentials, dÃ©veloppement
:page-layout: docs

[.lead]
Ce guide dÃ©crit le nouveau systÃ¨me d'import automatique de datasets depuis Kaggle avec architecture UUID sÃ©curisÃ©e pour IBIS-X.

[IMPORTANT]
====
**IBIS-X utilise UNIQUEMENT des vrais datasets** provenant de Kaggle. Les fausses donnÃ©es ne sont plus autorisÃ©es, mÃªme en dÃ©veloppement.
====

== ğŸ†• Nouveau SystÃ¨me UUID

=== Architecture SÃ©curisÃ©e

* **Stockage MinIO** : `datasets/{uuid_dataset}/{uuid_file}.parquet`
* **Base PostgreSQL** : UUID automatiques pour toutes les entitÃ©s
* **MÃ©tadonnÃ©es complÃ¨tes** : Analyse automatique des colonnes avec types, statistiques et dÃ©tection PII
* **TraÃ§abilitÃ©** : Conservation du nom original + UUID de stockage

=== Commande SimplifiÃ©e

[source,bash]
----
make dev-data  # Import automatique des 7 datasets Kaggle
----

== PrÃ©requis

=== 1. Application IBIS-X

L'application doit Ãªtre lancÃ©e avant l'import :

[source,bash]
----
make dev  # Lance l'application complÃ¨te avec MinIO
----

=== 2. Credentials Kaggle

Pour utiliser l'API Kaggle, vous devez :

. CrÃ©er un compte sur https://www.kaggle.com[Kaggle]
. Aller dans Account â†’ API â†’ Create New API Token  
. TÃ©lÃ©charger le fichier `kaggle.json`
. Ajouter les credentials dans le fichier `.env` :

[source,bash]
----
# Kaggle API (OBLIGATOIRE)
KAGGLE_USERNAME=votre_username
KAGGLE_KEY=votre_api_key

# Base de donnÃ©es (configurÃ© automatiquement)
DATABASE_URL=postgresql://user:password@localhost:5432/ibisxdb

# Stockage d'objets (configurÃ© automatiquement)
STORAGE_TYPE=minio
MINIO_ENDPOINT=http://minio-service.ibis-x.svc.cluster.local:6700
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
STORAGE_BUCKET=ibis-x-datasets
----

== ğŸš€ Utilisation Rapide

=== Import Automatique Complet

**Commande unique** pour importer tous les datasets avec validation :

[source,bash]
----
make dev-data
----

Cette commande :

* âœ… VÃ©rifie que l'application IBIS-X est accessible
* âœ… Importe les 7 datasets Kaggle avec structure UUID
* âœ… Analyse automatiquement les colonnes (types, statistiques, PII)
* âœ… Stocke dans MinIO avec UUID sÃ©curisÃ©s
* âœ… Valide l'intÃ©gritÃ© des donnÃ©es

=== Tests et Diagnostic

[source,bash]
----
# Test complet du systÃ¨me UUID
cd datasets/kaggle-import
make test-uuid-system

# Test des credentials Kaggle
make test-auth

# Import d'un dataset spÃ©cifique
make import-dataset DATASET=student_performance

# Validation des datasets importÃ©s
make validate-datasets
----

=== Commandes AvancÃ©es

[source,bash]
----
# Forcer le re-tÃ©lÃ©chargement (ignore cache)
cd datasets/kaggle-import
make force-refresh

# Lister les datasets configurÃ©s
make list-datasets

# Afficher l'Ã©tat des imports
make status
----

== ğŸ“Š Datasets ConfigurÃ©s

=== 7 Vrais Datasets Kaggle PrÃªts

**Architecture UUID** : Chaque dataset est stockÃ© avec un UUID unique pour la sÃ©curitÃ©.

=== Domaine Ã‰ducation (5 datasets)

. **Student Performance** - `spscientist/students-performance-in-exams`
   - TÃ¢che: Classification, Target: `math_score`
. **Student Stress** - `samyakb/student-stress-factors`  
   - TÃ¢che: Regression, Target: `stress_level`
. **Student Depression** - `adilshamim8/student-depression-dataset`
   - TÃ¢che: Classification, Target: `depression`
. **Academic Performance** - `nikhil7280/student-performance-multiple-linear-regression`
   - TÃ¢che: Regression, Target: `cgpa`
. **Riiid Answer Prediction** - `c/riiid-test-answer-prediction`
   - TÃ¢che: Classification, Target: `answered_correctly` (large dataset)

=== Autres Domaines (2 datasets)  

[start=6]
. **Social Media Addiction** - `adilshamim8/social-media-addiction-vs-relationships`
   - Domaine: Social Media, Target: `addiction_level`
. **OULAD Dataset** - `vjcalling/ouladdata`
   - Domaine: Education, Target: `final_result` (multi-file dataset)

=== MÃ©tadonnÃ©es Automatiques

Pour chaque dataset importÃ© :

* ğŸ“Š **Analyse des colonnes** : Types, statistiques, exemples
* ğŸ” **DÃ©tection PII** : Identification automatique des donnÃ©es personnelles  
* âš–ï¸ **CritÃ¨res Ã©thiques** : Templates intelligents par domaine
* ğŸ—ƒï¸ **Structure UUID** : Stockage sÃ©curisÃ© et traÃ§able

== ğŸ› ï¸ Configuration AvancÃ©e

=== Ajout d'un Nouveau Dataset

. **Ã‰diter la configuration** :
+
[source,bash]
----
# Fichier: datasets/kaggle-import/kaggle_datasets_config.yaml
nouveau_dataset:
  kaggle_ref: "username/dataset-name"
  domain: "education"  # UtilisÃ© pour les templates Ã©thiques
  description: "Description du dataset"
  ml_task: "classification"  # ou "regression"
  target_column: "colonne_cible"
----

. **Importer et tester** :
+
[source,bash]
----
cd datasets/kaggle-import
make import-dataset DATASET=nouveau_dataset
----

=== Architecture UUID DÃ©taillÃ©e

**Structure MinIO** :

[source]
----
ibis-x-datasets/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ 12345678-1234-1234-1234-123456789abc/  # UUID dataset
â”‚   â”‚   â”œâ”€â”€ abcdef12-3456-7890-abcd-ef1234567890.parquet  # UUID fichier 1
â”‚   â”‚   â””â”€â”€ fedcba09-8765-4321-dcba-098765432109.parquet  # UUID fichier 2
â”‚   â””â”€â”€ 87654321-4321-4321-4321-ba0987654321/  # Autre dataset
----

**Base PostgreSQL** :

* `datasets` : MÃ©tadonnÃ©es complÃ¨tes (31+ champs)
* `dataset_files` : Informations fichiers avec UUID  
* `file_columns` : Analyse dÃ©taillÃ©e des colonnes

=== Cache et Performance

* **Cache intelligent** : 7 jours, Ã©vite les re-tÃ©lÃ©chargements
* **Conversion Parquet** : Compression optimale, gains 10-50x
* **Analyse parallÃ¨le** : Colonnes analysÃ©es en simultanÃ©

=== Monitoring et Diagnostic

[source,bash]
----
# Validation complÃ¨te des donnÃ©es
make validate-datasets

# Diagnostic systÃ¨me UUID  
cd datasets/kaggle-import
make test-uuid-system

# Logs dÃ©taillÃ©s avec Ã©tapes
tail -f kaggle_import.log

# Ã‰tat complet des imports
make status
----

== ğŸ”§ DÃ©pannage

=== Erreurs Communes

[cols="3,4,3", options="header"]
|===
|Erreur |Cause |Solution

|"KAGGLE_USERNAME manquant dans .env"
|Credentials non configurÃ©s
|Ajoutez vos credentials Kaggle dans `.env`

|Import Kaggle Ã©chouÃ©
|Connexion ou credentials invalides
|VÃ©rifiez connexion internet et credentials

|Validation Ã©chouÃ©e
|Fausses donnÃ©es dÃ©tectÃ©es
|Nettoyez avec `make clean` puis `make dev-data`

|Application non accessible
|Services non prÃªts
|VÃ©rifiez que `make dev` est terminÃ©
|===

=== Diagnostic AvancÃ©

[source,bash]
----
# Voir les logs du job Kaggle
kubectl logs -n ibis-x job/kaggle-dataset-import-job

# Relancer manuellement l'import
kubectl delete job kaggle-dataset-import-job -n ibis-x
kubectl apply -f k8s/base/jobs/kaggle-dataset-import-job.yaml -n ibis-x

# VÃ©rifier le contenu de MinIO
kubectl port-forward -n ibis-x service/minio-service 6701:6701
# Puis allez sur http://localhost:6701 (minioadmin/minioadmin)
----

== ğŸ“ Notes Importantes

. **Le script `init_datasets.py` est OBSOLÃˆTE** et ne doit plus Ãªtre utilisÃ©
. **Les datasets sont stockÃ©s avec des UUIDs** dans MinIO (ex: `1bde81b1-2ac8-4681-aa96-4de9b04e42e8/`)
. **Le premier dÃ©marrage est plus long** mais garantit l'utilisation de vraies donnÃ©es
. **Les datasets sont mis en cache** pendant 7 jours pour Ã©viter les re-tÃ©lÃ©chargements

== ğŸš¨ Changements par rapport Ã  l'ancien systÃ¨me

[cols="1,1", options="header"]
|===
|Ancien SystÃ¨me |Nouveau SystÃ¨me

|Fausses donnÃ©es gÃ©nÃ©rÃ©es
|âœ… Vrais datasets Kaggle

|Dossiers nommÃ©s (`academic_performance/`)
|âœ… UUIDs (`1bde81b1-2ac8-4681-aa96-4de9b04e42e8/`)

|DÃ©marrage rapide
|âœ… DÃ©marrage plus long mais donnÃ©es rÃ©elles

|Script `init_datasets.py`
|âœ… Commande `make dev-data`
|===

== ğŸ’¡ Pour les DÃ©veloppeurs

Si vous devez dÃ©bugger le processus d'import :

[source,bash]
----
# Voir les logs du job Kaggle
kubectl logs -n ibis-x job/kaggle-dataset-import-job

# Relancer manuellement l'import
kubectl delete job kaggle-dataset-import-job -n ibis-x
kubectl apply -f k8s/base/jobs/kaggle-dataset-import-job.yaml -n ibis-x

# VÃ©rifier le contenu de MinIO
kubectl port-forward -n ibis-x service/minio-service 6701:6701
# Puis allez sur http://localhost:6701 (minioadmin/minioadmin)
----

[.text-center]
**ğŸ¯ Objectif : 100% de vrais datasets, 0% de fausses donnÃ©es !**