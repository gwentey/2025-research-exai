= Architecture Technique du Projet EXAI

Ce document détaille l'architecture logicielle de la plateforme EXAI. Pour les instructions d'installation et de déploiement, veuillez consulter le guide xref:getting-started.adoc[Installation & Démarrage Rapide].

== 1. Vision d'Ensemble et Objectifs

Le projet EXAI vise à créer un **outil scientifique (PoC)** répondant à trois défis :

1.  Aide à la **sélection de datasets** (critères techniques, éthiques, métier).
2.  Guidage interactif pour les **pipelines de Machine Learning**.
3.  Recommandation et application de techniques d'**IA Explicable (XAI)**.

Pour atteindre ces objectifs avec **modularité**, **scalabilité** et **maintenabilité**, EXAI repose sur une architecture en **microservices conteneurisés** orchestrés par **Kubernetes**.

*   **Microservices :** Chaque grande fonctionnalité (sélection de données, entraînement ML, explicabilité XAI, interface utilisateur) est gérée par un service indépendant. Cela permet de développer, déployer et mettre à l'échelle chaque partie séparément.
*   **Conteneurisation (Docker) :** Chaque microservice est packagé dans une image Docker avec toutes ses dépendances. Cela garantit la cohérence entre les environnements (développement, test, production).
*   **Orchestration (Kubernetes) :** Kubernetes gère le déploiement, la mise à l'échelle, la mise en réseau et la communication entre les conteneurs/microservices. Pour le développement local, nous utilisons **Minikube** qui simule un cluster Kubernetes.

== 2. Diagramme d'Architecture

_(Essentiel : Un diagramme est nécessaire ici pour visualiser les interactions !)_

[IMPORTANT]
====
Un diagramme d'architecture illustrant les composants décrits ci-dessous et leurs interactions principales doit être inséré ici.

Le moyen le plus simple est de créer le diagramme avec un outil externe (comme https://draw.io[draw.io^], Lucidchart, Miro...) et de l'enregistrer sous forme d'image (par exemple, `architecture-diagram.png`) dans le dossier `docs/modules/ROOT/assets/images/`. Ensuite, incluez-le avec la ligne suivante :

[source,asciidoc]
----
image::architecture-diagram.png[Diagramme d'architecture EXAI, L=auto]
----

(Assurez-vous que le chemin d'accès à l'image est correct par rapport à l'emplacement de ce fichier `architecture.adoc`.)
====

== 3. Description Détaillée des Composants

=== 3.1 Frontend (`frontend/`)
*   **Rôle :** Interface utilisateur web interactive pour la plateforme EXAI.
*   **Responsabilités :** Permettre à l'utilisateur de naviguer dans les fonctionnalités (sélection datasets, configuration pipeline ML, visualisation XAI), afficher les informations et résultats.
*   **Technologies :** Angular, Tailwind CSS.
*   **Interactions :** Communique exclusivement avec l'API Gateway via des requêtes HTTP REST/JSON.
*   **Justification :** Angular offre un framework robuste pour les applications Single Page complexes. Tailwind facilite la création rapide d'interfaces modernes.

=== 3.2 API Gateway (`api-gateway/`)
*   **Rôle :** Point d'entrée unique pour toutes les requêtes provenant du Frontend (ou d'autres clients externes).
*   **Responsabilités :**
    *   Authentification et autorisation des requêtes (via JWT).
    *   Routage des requêtes vers le microservice interne approprié (Sélection, ML, XAI).
    *   Agrégation potentielle de réponses provenant de plusieurs services.
    *   Gestion centralisée du CORS (Cross-Origin Resource Sharing).
*   **Technologies :** FastAPI (Python).
*   **Interactions :** Reçoit les requêtes du Frontend, les transmet aux services backend (Sélection, ML, XAI) via REST.
*   **Justification :** FastAPI est performant, facile à utiliser, intègre la validation de données (Pydantic) et génère automatiquement la documentation OpenAPI (Swagger UI), idéal pour une gateway.

=== 3.3 Service Sélection (`service-selection/`)
*   **Rôle :** Gérer le catalogue de datasets et fournir des fonctionnalités de sélection.
*   **Responsabilités :**
    *   Stocker et récupérer les métadonnées des datasets (nom, description, type, caractéristiques...).
    *   Implémenter la logique de recherche et de filtrage des datasets selon les critères utilisateur.
    *   Calculer les scores de pertinence des datasets.
*   **Technologies :** FastAPI (Python), SQLAlchemy (potentiellement, pour l'ORM), PostgreSQL (pour le stockage).
*   **Interactions :** Reçoit des requêtes de l'API Gateway, interagit avec la base de données PostgreSQL.
*   **Justification :** FastAPI pour la rapidité de développement API. PostgreSQL est une base de données relationnelle robuste et éprouvée.

=== 3.4 Service ML (`service-ml/`)
*   **Rôle :** Gérer les aspects liés à l'entraînement et à l'évaluation des modèles de Machine Learning.
*   **Responsabilités (Prévues) :**
    *   Prétraitement des données (nettoyage, normalisation...).
    *   Entraînement de modèles (classification, régression...) basés sur les choix utilisateur.
    *   Évaluation des performances des modèles.
    *   Gestion des tâches longues (entraînement) de manière asynchrone.
*   **Technologies :** FastAPI (Python), Scikit-learn, Pandas, Celery (pour les tâches asynchrones), Redis (comme broker pour Celery).
*   **Interactions :** Reçoit des requêtes de l'API Gateway, lit potentiellement des données (via le Service Sélection ou directement ?), utilise Celery/Redis pour les tâches longues, peut interagir avec le Service XAI.
*   **Justification :** Scikit-learn est la bibliothèque standard pour le ML en Python. Celery/Redis gèrent efficacement les traitements longs sans bloquer l'API.

=== 3.5 Service XAI (`service-xai/`)
*   **Rôle :** Fournir des fonctionnalités d'explicabilité pour les modèles ML.
*   **Responsabilités (Prévues) :**
    *   Recommander des méthodes XAI adaptées (LIME, SHAP...) en fonction du modèle, des données, du contexte.
    *   Générer les explications (calculs potentiellement longs).
    *   Formater les résultats des explications pour la visualisation.
    *   Gérer les tâches de génération d'explication de manière asynchrone.
*   **Technologies :** FastAPI (Python), SHAP, LIME, autres bibliothèques XAI, Celery, Redis.
*   **Interactions :** Reçoit des requêtes de l'API Gateway, interagit probablement avec le Service ML (pour obtenir le modèle, les données), utilise Celery/Redis.
*   **Justification :** Bibliothèques XAI dédiées (SHAP, LIME). Celery/Redis pour les calculs longs.

=== 3.6 Base de Données (`k8s/postgres/`)
*   **Rôle :** Stockage persistant des données relationnelles.
*   **Responsabilités :** Principalement utilisée par le Service Sélection pour stocker les métadonnées des datasets. Pourrait être utilisée par d'autres services si nécessaire.
*   **Technologies :** PostgreSQL.
*   **Interactions :** Accessible par les microservices (principalement Service Sélection) via le réseau interne de Kubernetes.
*   **Justification :** Système de gestion de base de données relationnelle open-source, fiable, performant et riche en fonctionnalités.

=== 3.7 Orchestration & Infrastructure (`k8s/`, Dockerfiles)
*   **Rôle :** Définir, construire et gérer l'exécution de l'ensemble des services.
*   **Responsabilités :**
    *   Définir comment construire les images conteneurs (via les `Dockerfile` dans chaque service).
    *   Définir comment déployer et configurer chaque service dans Kubernetes (via les manifestes YAML dans `k8s/` ou les sous-dossiers `k8s/` de chaque service).
    *   Gérer la mise en réseau, le stockage persistant (via Kubernetes).
*   **Technologies :** Docker, Kubernetes, Minikube (pour le local).
*   **Justification :** Standards de l'industrie pour la conteneurisation et l'orchestration, favorisant la reproductibilité et la scalabilité.

== 4. Flux de Données et Communication

*   **Communication Inter-Services :** La communication entre le Frontend et l'API Gateway, ainsi qu'entre l'API Gateway et les microservices backend, se fait principalement via des **API REST synchrones** (requête/réponse HTTP/JSON).
*   **Tâches Asynchrones :** Pour les opérations longues (entraînement de modèles ML, génération d'explications XAI), les services ML et XAI utilisent **Celery** avec **Redis** comme broker de messages. L'API reçoit la requête, la place dans une file d'attente Redis, et un worker Celery (processus séparé) la prend en charge. Cela évite de bloquer les requêtes API.
*   **Sécurité :** L'**API Gateway** est responsable de la validation des jetons **JWT** pour sécuriser l'accès aux API.

== 5. Structure du Code Source

Voici une vue typique de l'organisation attendue du code source :

```text
/
├── frontend/                 # Code source de l'interface Angular
│   ├── src/
│   ├── angular.json
│   ├── Dockerfile              # Pour construire l'image du frontend
│   └── k8s/                  # Manifestes K8s spécifiques au frontend
│       ├── deployment.yaml
│       └── service.yaml
├── api-gateway/              # Code source de l'API Gateway
│   ├── app/
│   ├── requirements.txt
│   ├── Dockerfile
│   └── k8s/
│       ├── deployment.yaml
│       └── service.yaml
├── service-selection/        # Code source du Service Sélection
│   ├── app/
│   ├── requirements.txt
│   ├── Dockerfile
│   └── k8s/
│       ├── deployment.yaml
│       └── service.yaml
├── service-ml/               # Code source du Service ML
│   ├── app/
│   ├── worker/               # Code pour les workers Celery
│   ├── requirements.txt
│   ├── Dockerfile
│   └── k8s/
│       ├── deployment.yaml   # Déploiement de l'API FastAPI
│       ├── service.yaml
│       └── worker-deployment.yaml # Déploiement des workers Celery
├── service-xai/              # Code source du Service XAI (structure similaire à ML)
│   ├── ...
├── k8s/                      # Configurations Kubernetes globales/partagées
│   ├── postgres/             # Config K8s pour PostgreSQL
│   │   ├── deployment.yaml
│   │   ├── service.yaml
│   │   ├── persistentvolumeclaim.yaml
│   │   └── init-db.sql
│   └── redis/                # Config K8s pour Redis (si nécessaire)
│       └── ...
├── docs/                     # Documentation Antora (ce que vous lisez)
│   └── modules/ROOT/
│       ├── pages/
│       └── nav.adoc
├── antora.yml                # Configuration du composant Antora
├── antora-playbook.yml       # Playbook pour générer la documentation
└── README.md                 # README général du projet
```

Cette structure vise à séparer clairement chaque microservice tout en gardant les configurations Kubernetes associées proches du code source du service concerné. 