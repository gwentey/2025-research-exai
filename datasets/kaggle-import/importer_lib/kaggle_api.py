"""
G√®re les interactions avec l'API Kaggle.

- Authentification
- R√©cup√©ration des m√©tadonn√©es
- T√©l√©chargement des datasets
"""
import kaggle
import logging
import time
from pathlib import Path
from typing import Dict, Any, List

from . import config

logger = logging.getLogger(__name__)

class KaggleAPI:
    """Wrapper pour l'API Kaggle."""

    def __init__(self):
        self._authenticate()

    def _authenticate(self):
        """Authentifie le client aupr√®s de l'API Kaggle."""
        try:
            kaggle.api.authenticate()
            logger.info("Authentification Kaggle r√©ussie.")
        except Exception as e:
            logger.error(f"√âchec de l'authentification Kaggle: {e}")
            logger.error("Veuillez vous assurer que votre fichier kaggle.json est correctement configur√©.")
            raise

    def get_metadata(self, kaggle_ref: str) -> Dict[str, Any]:
        """
        R√©cup√®re les m√©tadonn√©es d'un dataset depuis Kaggle avec une politique de re-essai.

        Args:
            kaggle_ref: La r√©f√©rence du dataset (ex: 'user/dataset-name').

        Returns:
            Un dictionnaire contenant les m√©tadonn√©es du dataset.
        """
        logger.info(f"R√©cup√©ration des m√©tadonn√©es pour '{kaggle_ref}'...")
        for attempt in range(config.MAX_KAGGLE_API_RETRIES):
            try:
                # La m√©thode dataset_metadata t√©l√©charge un fichier metadata.json
                # dans le path sp√©cifi√©.
                temp_dir = Path(config.CACHE_DIR) / "tmp_meta"
                temp_dir.mkdir(exist_ok=True)
                
                # kaggle.api.dataset_metadata est d√©pr√©ci√©, mais toujours utilis√© par la lib.
                # La nouvelle approche est d'utiliser dataset_view, mais l'ancienne fonctionne encore.
                dataset_info = kaggle.api.dataset_metadata(kaggle_ref, path=str(temp_dir))

                # Nettoyer les fichiers temporaires
                for item in temp_dir.iterdir():
                    item.unlink()
                temp_dir.rmdir()
                
                # Extraire les m√©tadonn√©es pertinentes de l'objet retourn√©
                return self._extract_relevant_metadata(dataset_info)

            except Exception as e:
                logger.warning(f"Tentative {attempt + 1}/{config.MAX_KAGGLE_API_RETRIES} √©chou√©e pour '{kaggle_ref}': {e}")
                if attempt + 1 == config.MAX_KAGGLE_API_RETRIES:
                    logger.error(f"Toutes les tentatives ont √©chou√© pour la r√©cup√©ration des m√©tadonn√©es de '{kaggle_ref}'.")
                    return {'title': kaggle_ref, 'error': str(e)}
                time.sleep(2 ** attempt)  # Backoff exponentiel
        return {} # Devrait √™tre inatteignable

    def download_files(self, kaggle_ref: str, download_path: Path) -> List[Path]:
        """
        T√©l√©charge et d√©zippe les fichiers d'un dataset Kaggle.

        Args:
            kaggle_ref: La r√©f√©rence du dataset.
            download_path: Le r√©pertoire de destination pour les fichiers t√©l√©charg√©s.

        Returns:
            La liste des chemins des fichiers CSV t√©l√©charg√©s.
        """
        logger.info(f"T√©l√©chargement du dataset '{kaggle_ref}' vers '{download_path}'...")
        try:
            kaggle.api.dataset_download_files(
                kaggle_ref,
                path=str(download_path),
                unzip=True,
                quiet=False
            )
            
            # Recherche r√©cursive des fichiers .csv
            downloaded_files = list(download_path.glob("**/*.csv"))
            logger.info(f"{len(downloaded_files)} fichier(s) CSV t√©l√©charg√©(s) pour '{kaggle_ref}'.")
            return downloaded_files
        except Exception as e:
            error_msg = str(e).lower()
            
            # Gestion sp√©cifique des erreurs 403 pour les datasets de comp√©tition
            if "403" in error_msg or "forbidden" in error_msg:
                if kaggle_ref.startswith("c/"):
                    logger.warning(f"‚ö†Ô∏è  DATASET DE COMP√âTITION NON ACCESSIBLE : '{kaggle_ref}'")
                    logger.warning("   ‚Üí Ce dataset de comp√©tition Kaggle n'est plus accessible via l'API")
                    logger.warning("   ‚Üí Raison possible : comp√©tition termin√©e, acc√®s restreint, ou permissions insuffisantes")
                    logger.warning("   ‚Üí SOLUTION : Remplacer par un dataset public √©quivalent ou contacter l'administrateur Kaggle")
                else:
                    logger.warning(f"‚ö†Ô∏è  ACC√àS REFUS√â : '{kaggle_ref}' - V√©rifiez vos permissions Kaggle")
                
                # Retourner une liste vide au lieu de faire √©chouer le processus
                logger.info(f"üîÑ CONTINUE : Passer au dataset suivant...")
                return []
            else:
                # Pour les autres erreurs, continuer √† les propager
                logger.error(f"‚ùå Erreur lors du t√©l√©chargement de '{kaggle_ref}': {e}")
                raise

    def _extract_relevant_metadata(self, dataset_info: object) -> Dict[str, Any]:
        """Extrait les m√©tadonn√©es utiles de l'objet retourn√© par l'API Kaggle."""
        
        def safe_getattr(obj, attr, default=None):
            """R√©cup√®re un attribut en toute s√©curit√©."""
            value = getattr(obj, attr, default)
            # Si c'est une m√©thode, on l'appelle
            if callable(value) and not isinstance(value, type):
                try:
                    return value()
                except Exception:
                    return default
            return value

        return {
            'title': safe_getattr(dataset_info, 'title', ''),
            'subtitle': safe_getattr(dataset_info, 'subtitle', ''),
            'description': safe_getattr(dataset_info, 'description', ''),
            'usabilityRating': safe_getattr(dataset_info, 'usabilityRating', 0.0),
            'lastUpdated': safe_getattr(dataset_info, 'lastUpdated', ''),
            'downloadCount': safe_getattr(dataset_info, 'downloadCount', 0),
            'voteCount': safe_getattr(dataset_info, 'voteCount', 0),
            'size': safe_getattr(dataset_info, 'size', ''),
            'licenseName': safe_getattr(dataset_info, 'licenseName', 'unknown'),
            'keywords': safe_getattr(dataset_info, 'keywords', []),
            'ownerName': safe_getattr(dataset_info, 'ownerName', ''),
        }


