#!/usr/bin/env python3
"""
Script de validation pour v√©rifier que les VRAIS datasets Kaggle sont import√©s.

Ce script v√©rifie :
1. Que les datasets sont stock√©s avec des UUIDs dans MinIO
2. Que les m√©tadonn√©es correspondent aux vrais datasets Kaggle
3. Que les fichiers sont bien au format Parquet
4. Qu'aucune fausse donn√©e n'existe
"""

import os
import sys
import subprocess
import json
from pathlib import Path

def check_kubectl():
    """V√©rifie que kubectl est disponible."""
    try:
        subprocess.run(["kubectl", "version", "--client"], capture_output=True, check=True)
        return True
    except:
        print("‚ùå kubectl n'est pas install√© ou accessible")
        return False

def get_datasets_from_db():
    """R√©cup√®re la liste des datasets depuis la base de donn√©es."""
    try:
        # Ex√©cuter une requ√™te SQL via kubectl
        cmd = [
            "kubectl", "exec", "-n", "ibis-x", 
            "deployment/service-selection", "--",
            "python", "-c",
            """
import os
import sys
sys.path.append('/app')
from database import SessionLocal
from models import Dataset, DatasetFile

with SessionLocal() as session:
    datasets = session.query(Dataset).all()
    for ds in datasets:
        files = session.query(DatasetFile).filter(DatasetFile.dataset_id == ds.id).all()
        print(f'DATASET|{ds.id}|{ds.dataset_name}|{ds.storage_path}|{len(files)}')
        for f in files:
            print(f'  FILE|{f.file_name_in_storage}|{f.format}|{f.size_bytes}')
"""
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"‚ùå Erreur lors de la r√©cup√©ration des datasets: {result.stderr}")
            return []
        
        datasets = []
        current_dataset = None
        
        for line in result.stdout.strip().split('\n'):
            if line.startswith('DATASET|'):
                parts = line.split('|')
                current_dataset = {
                    'id': parts[1],
                    'name': parts[2],
                    'storage_path': parts[3],
                    'file_count': int(parts[4]),
                    'files': []
                }
                datasets.append(current_dataset)
            elif line.strip().startswith('FILE|') and current_dataset:
                parts = line.strip().split('|')
                current_dataset['files'].append({
                    'name': parts[1],
                    'format': parts[2],
                    'size': int(parts[3]) if parts[3] != 'None' else 0
                })
        
        return datasets
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des datasets: {e}")
        return []

def validate_datasets(datasets):
    """Valide que les datasets sont corrects."""
    print("\nüîç === VALIDATION DES DATASETS ===")
    
    valid_count = 0
    invalid_count = 0
    
    # Mapping des vrais noms de datasets Kaggle
    EXPECTED_DATASETS = {
        "Students Performance in Exams",
        "Student Stress Factors", 
        "Student Depression Dataset",
        "Students' Social Media Addiction",
        "Riiid Answer Correctness",
        "OULAD",
        "Student Academic Performance"
    }
    
    for dataset in datasets:
        print(f"\nüìä Dataset: {dataset['name']}")
        print(f"   ID: {dataset['id']}")
        print(f"   Storage Path: {dataset['storage_path']}")
        
        # V√©rification 1: Le storage_path doit contenir un UUID
        is_valid = True
        
        if not dataset['storage_path'] or dataset['storage_path'] == 'None':
            print("   ‚ùå Pas de storage_path d√©fini")
            is_valid = False
        elif not any(char in dataset['storage_path'] for char in ['-']):
            print("   ‚ùå Storage path ne contient pas d'UUID")
            is_valid = False
        else:
            print("   ‚úÖ Storage path contient un UUID")
        
        # V√©rification 2: Le nom doit correspondre √† un vrai dataset
        if dataset['name'] in EXPECTED_DATASETS:
            print("   ‚úÖ Nom correspond √† un vrai dataset Kaggle")
        else:
            print(f"   ‚ö†Ô∏è  Nom '{dataset['name']}' ne correspond pas exactement aux datasets Kaggle attendus")
            # Ne pas invalider car le nom peut varier l√©g√®rement
        
        # V√©rification 3: Les fichiers doivent √™tre au format Parquet
        if dataset['file_count'] == 0:
            print("   ‚ùå Aucun fichier trouv√©")
            is_valid = False
        else:
            print(f"   üìÅ {dataset['file_count']} fichier(s) trouv√©(s):")
            parquet_found = False
            for file in dataset['files']:
                print(f"      - {file['name']} ({file['format']}, {file['size']} bytes)")
                if file['format'] == 'parquet':
                    parquet_found = True
            
            if parquet_found:
                print("   ‚úÖ Fichiers Parquet trouv√©s")
            else:
                print("   ‚ùå Aucun fichier Parquet trouv√©")
                is_valid = False
        
        # V√©rification 4: Taille des fichiers (les vrais datasets sont substantiels)
        total_size = sum(f['size'] for f in dataset['files'])
        if total_size < 1000:  # Moins de 1KB = probablement faux
            print(f"   ‚ùå Taille totale trop petite ({total_size} bytes) - probablement de fausses donn√©es")
            is_valid = False
        else:
            print(f"   ‚úÖ Taille totale raisonnable ({total_size / 1024 / 1024:.2f} MB)")
        
        if is_valid:
            valid_count += 1
            print("   ‚úÖ DATASET VALIDE")
        else:
            invalid_count += 1
            print("   ‚ùå DATASET INVALIDE")
    
    return valid_count, invalid_count

def check_minio_structure():
    """V√©rifie la structure dans MinIO."""
    print("\n‚òÅÔ∏è  === V√âRIFICATION MINIO ===")
    
    try:
        # Lister les objets dans MinIO
        cmd = [
            "kubectl", "exec", "-n", "ibis-x",
            "deployment/service-selection", "--",
            "python", "-c",
            """
import os
import sys
sys.path.append('/app')
from common.storage_client import get_storage_client

try:
    client = get_storage_client()
    files = client.list_files('')
    
    # Organiser par dossier
    folders = {}
    for file in files:
        if '/' in file:
            folder = file.split('/')[0]
            if folder not in folders:
                folders[folder] = 0
            folders[folder] += 1
    
    for folder, count in sorted(folders.items()):
        print(f'FOLDER|{folder}|{count}')
        
except Exception as e:
    print(f'ERROR|{str(e)}')
"""
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            for line in result.stdout.strip().split('\n'):
                if line.startswith('FOLDER|'):
                    parts = line.split('|')
                    folder = parts[1]
                    count = int(parts[2])
                    
                    # V√©rifier si c'est un UUID
                    if '-' in folder and len(folder) == 36:
                        print(f"   ‚úÖ Dossier UUID trouv√©: {folder} ({count} fichiers)")
                    else:
                        print(f"   ‚ùå Dossier non-UUID trouv√©: {folder} ({count} fichiers) - FAUSSES DONN√âES!")
                elif line.startswith('ERROR|'):
                    print(f"   ‚ùå Erreur MinIO: {line.split('|')[1]}")
        else:
            print(f"   ‚ùå Impossible d'acc√©der √† MinIO: {result.stderr}")
            
    except Exception as e:
        print(f"   ‚ùå Erreur lors de la v√©rification MinIO: {e}")

def main():
    print("üîç === VALIDATION DES DATASETS KAGGLE ===")
    print("Ce script v√©rifie que les VRAIS datasets sont import√©s depuis Kaggle\n")
    
    if not check_kubectl():
        return 1
    
    # R√©cup√©rer les datasets depuis la base de donn√©es
    datasets = get_datasets_from_db()
    
    if not datasets:
        print("‚ùå Aucun dataset trouv√© dans la base de donn√©es")
        print("üí° Assurez-vous d'avoir ex√©cut√© 'make dev' avec les credentials Kaggle")
        return 1
    
    print(f"üìä {len(datasets)} dataset(s) trouv√©(s) dans la base de donn√©es")
    
    # Valider les datasets
    valid, invalid = validate_datasets(datasets)
    
    # V√©rifier la structure MinIO
    check_minio_structure()
    
    # R√©sum√© final
    print("\n" + "="*60)
    print("üìä R√âSUM√â DE LA VALIDATION")
    print("="*60)
    print(f"‚úÖ Datasets valides: {valid}")
    print(f"‚ùå Datasets invalides: {invalid}")
    
    if invalid > 0:
        print("\n‚ùå VALIDATION √âCHOU√âE")
        print("Des fausses donn√©es ont √©t√© d√©tect√©es !")
        print("\nüí° Pour corriger :")
        print("1. Assurez-vous d'avoir configur√© KAGGLE_USERNAME et KAGGLE_KEY dans .env")
        print("2. Ex√©cutez 'make clean' pour nettoyer")
        print("3. Ex√©cutez 'make dev' pour r√©importer les vrais datasets")
        return 1
    else:
        print("\n‚úÖ VALIDATION R√âUSSIE")
        print("Tous les datasets sont des VRAIS datasets import√©s depuis Kaggle !")
        return 0

if __name__ == "__main__":
    sys.exit(main())