#!/bin/bash

# üöÄ SCRIPT DE D√âPLOIEMENT PRODUCTION IBIS-X SUR AZURE
# Usage: Infrastructure + D√©ploiement Production
# Pour le d√©veloppement local, utilisez: make dev

set -e

# ==========================================
# üé® FONCTIONS DE LOGGING (D√âFINIES EN PREMIER)
# ==========================================

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonctions utilitaires
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ==========================================
# üéØ CONFIGURATION PRODUCTION
# ==========================================

# D√©tection si ex√©cut√© depuis GitHub Actions
IS_GITHUB_ACTIONS="${GITHUB_ACTIONS:-false}"
IS_WINDOWS=false

# Auto-d√©tection Windows
if [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]] || [[ -n "${WINDIR}" ]]; then
    IS_WINDOWS=true
fi

# Configuration production
if [[ "$IS_GITHUB_ACTIONS" == "true" ]]; then
    # üè≠ MODE GITHUB ACTIONS
    DEPLOYMENT_MODE="github-actions"
    
    # Variables d'environnement (depuis GitHub Actions)
    export AZURE_CONTAINER_REGISTRY="${AZURE_CONTAINER_REGISTRY:-ibisprodacr}"
    export AZURE_RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-ibis-x-perso-rg}"
    export AKS_CLUSTER_NAME="${AKS_CLUSTER_NAME:-ibis-x-prod-aks}"
    export K8S_NAMESPACE="${K8S_NAMESPACE:-ibis-x}"
    
    # Tags versionn√©s avec SHA du commit
    if [[ -n "$GITHUB_SHA" ]]; then
        export IMAGE_TAG="${GITHUB_SHA:0:7}"
    else
        export IMAGE_TAG="latest"
    fi
    
    export USE_GITHUB_SECRETS=true
    export WITH_DATA="${WITH_DATA:-true}"
    export ANGULAR_ENV="production"
    
else
    # üõ†Ô∏è MODE SCRIPT MANUEL
    DEPLOYMENT_MODE="manual-production"
    
    # Configuration par d√©faut (peut √™tre surcharg√©e par variables d'environnement)
    export AZURE_CONTAINER_REGISTRY="${AZURE_CONTAINER_REGISTRY:-ibisprodacr}"
    export AZURE_RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-ibis-x-perso-rg}"
    export AKS_CLUSTER_NAME="${AKS_CLUSTER_NAME:-ibis-x-prod-aks}"
    export K8S_NAMESPACE="${K8S_NAMESPACE:-ibis-x}"
    export IMAGE_TAG="${IMAGE_TAG:-latest}"
    export USE_GITHUB_SECRETS=false
    export WITH_DATA="${WITH_DATA:-false}"
    # ‚úÖ FORCER PRODUCTION: Toujours en mode production pour Azure
    export ANGULAR_ENV="production"
    
    log_info "üéØ Mode Manuel Production - Frontend configur√© automatiquement en PRODUCTION"
fi

# ==========================================
# üìÅ VARIABLES DE CONFIGURATION
# ==========================================

# Script de d√©ploiement automatis√© pour IBIS-X sur Azure
# Ce script utilise Terraform pour cr√©er l'infrastructure et d√©ploie l'application

# Variables de configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TERRAFORM_DIR="$PROJECT_ROOT/terraform/azure-infrastructure"
K8S_DIR="$PROJECT_ROOT/k8s"

# D√©tection de l'OS pour adapter les commandes
if [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]] || command -v powershell &> /dev/null; then
    IS_WINDOWS=true
else
    IS_WINDOWS=false
fi

# Variables globales pour partager entre les fonctions
export STORAGE_ACCOUNT=""
export STORAGE_KEY=""
export ACR_NAME=""
export AKS_NAME=""
export RESOURCE_GROUP=""
export PUBLIC_IP=""

# ==========================================
# üìä AFFICHAGE CONFIGURATION
# ==========================================

# Afficher la configuration d√©tect√©e
if [[ "$IS_GITHUB_ACTIONS" == "true" ]]; then
    log_info "üè≠ MODE: GitHub Actions"
    log_info "üì¶ ACR: $AZURE_CONTAINER_REGISTRY"
    log_info "üè∑Ô∏è Tag images: $IMAGE_TAG"
    log_info "üîê Secrets: GitHub Secrets (inject√©s)"
else
    log_info "üõ†Ô∏è MODE: Script Manuel"
    log_info "üì¶ ACR: $AZURE_CONTAINER_REGISTRY"
    log_info "üè∑Ô∏è Tag images: $IMAGE_TAG"
    log_info "üîê Secrets: Configuration manuelle requise"
    log_info "‚ÑπÔ∏è  Utilisez 'make dev' pour le d√©veloppement local"
fi
log_info "üåê Frontend: Mode $ANGULAR_ENV"
log_info "üìä Donn√©es: WITH_DATA=$WITH_DATA"

# Fonction pour v√©rifier les versions Kubernetes disponibles
check_kubernetes_versions() {
    log_info "V√©rification des versions Kubernetes disponibles..."
    
    # Obtenir la r√©gion depuis terraform.tfvars ou utiliser une valeur par d√©faut
    local region="East US"
    if [ -f "$TERRAFORM_DIR/terraform.tfvars" ]; then
        region=$(grep -E '^location\s*=' "$TERRAFORM_DIR/terraform.tfvars" | cut -d'"' -f2 2>/dev/null || echo "East US")
    fi
    
    # V√©rifier les versions disponibles
    local available_versions=$(az aks get-versions --location "$region" --output json | jq -r '.orchestrators[] | select(.supportPlan[] | contains("KubernetesOfficial")) | .orchestratorVersion' | sort -V)
    
    if [ -z "$available_versions" ]; then
        log_warning "Impossible de r√©cup√©rer les versions Kubernetes. V√©rifiez votre connexion Azure."
        return
    fi
    
    # Afficher les versions recommand√©es
    local recommended_versions=$(echo "$available_versions" | tail -5)
    log_info "Versions Kubernetes recommand√©es pour la r√©gion '$region':"
    echo "$recommended_versions" | while read version; do
        echo "  - $version"
    done
    
    # V√©rifier si la version configur√©e est support√©e
    local current_version=""
    if [ -f "$TERRAFORM_DIR/terraform.tfvars" ]; then
        current_version=$(grep -E '^kubernetes_version\s*=' "$TERRAFORM_DIR/terraform.tfvars" | cut -d'"' -f2 2>/dev/null)
    fi
    
    if [ -n "$current_version" ]; then
        if echo "$available_versions" | grep -q "^$current_version$"; then
            log_success "Version Kubernetes configur√©e ($current_version) est support√©e"
        else
            log_warning "Version Kubernetes configur√©e ($current_version) n'est pas support√©e !"
            log_warning "Versions recommand√©es : $(echo "$recommended_versions" | tail -3 | tr '\n' ' ')"
        fi
    fi
}

# Fonction pour v√©rifier les pr√©requis
check_prerequisites() {
    log_info "V√©rification des pr√©requis..."
    
    # V√©rifier Azure CLI
    if ! command -v az &> /dev/null; then
        log_error "Azure CLI n'est pas install√©. Installez-le depuis https://docs.microsoft.com/en-us/cli/azure/install-azure-cli"
        exit 1
    fi
    
    # V√©rifier/Installer Terraform
    if ! command -v terraform &> /dev/null; then
        log_warning "Terraform n'est pas install√©. Installation automatique..."
        if [[ "$IS_WINDOWS" == true ]]; then
            if command -v winget &> /dev/null; then
                winget install HashiCorp.Terraform
                # Recharger les variables d'environnement
                if command -v refreshenv &> /dev/null; then
                    refreshenv
                fi
            else
                log_error "Terraform non install√© et winget indisponible. Installez manuellement depuis https://www.terraform.io/downloads.html"
        exit 1
            fi
        else
            # Installation sur Linux/MacOS
            if command -v wget &> /dev/null && command -v unzip &> /dev/null; then
                TF_VERSION="1.6.0"
                wget "https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip"
                unzip "terraform_${TF_VERSION}_linux_amd64.zip"
                sudo mv terraform /usr/local/bin/
                rm "terraform_${TF_VERSION}_linux_amd64.zip"
            else
                log_error "Terraform non install√©. Installez manuellement depuis https://www.terraform.io/downloads.html"
                exit 1
            fi
        fi
        
        # V√©rifier que l'installation a r√©ussi
        if ! command -v terraform &> /dev/null; then
            log_error "√âchec de l'installation automatique de Terraform. Installez manuellement."
            exit 1
        else
            log_success "Terraform install√© avec succ√®s"
        fi
    fi
    
    # V√©rifier kubectl
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl n'est pas install√©. Installez-le depuis https://kubernetes.io/docs/tasks/tools/"
        exit 1
    fi
    
    # V√©rifier Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker n'est pas install√©. Installez-le depuis https://docs.docker.com/get-docker/"
        exit 1
    fi
    
    # V√©rifier/Installer jq pour le parsing JSON
    if ! command -v jq &> /dev/null; then
        log_warning "jq n'est pas install√©. Installation automatique..."
        if [[ "$IS_WINDOWS" == true ]]; then
            if command -v winget &> /dev/null; then
                winget install jqlang.jq
            else
                log_warning "jq non install√©. Install√© manuellement depuis https://jqlang.github.io/jq/"
            fi
        else
            if command -v apt-get &> /dev/null; then
                sudo apt-get install -y jq
            elif command -v yum &> /dev/null; then
                sudo yum install -y jq
            elif command -v brew &> /dev/null; then
                brew install jq
            else
                log_warning "jq non install√©. Install√© manuellement depuis https://jqlang.github.io/jq/"
            fi
        fi
    fi
    
    # V√©rifier/Installer Helm
    if ! command -v helm &> /dev/null; then
        log_warning "Helm n'est pas install√©. Installation automatique..."
        install_helm
    else
        log_success "Helm est d√©j√† install√©"
    fi
    
    log_success "Tous les pr√©requis sont install√©s"
}

# Nouvelle fonction pour installer Helm
install_helm() {
    log_info "Installation de Helm..."
    
    # T√©l√©charger et installer Helm
    curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    chmod 700 get_helm.sh
    ./get_helm.sh
    rm get_helm.sh
    
    # V√©rifier l'installation
    if command -v helm &> /dev/null; then
        log_success "Helm install√© avec succ√®s: $(helm version --short)"
    else
        log_error "√âchec de l'installation de Helm"
        exit 1
    fi
}

# ‚úÖ FONCTION AUTOMATIQUE RENFORC√âE : Configuration IP statique pour NGINX Ingress
configure_static_ip_for_nginx() {
    log_info "üîß Configuration automatique RENFORC√âE de l'IP statique pour NGINX Ingress..."
    
    # 1. R√©cup√©rer l'IP statique depuis Azure CLI (plus fiable que Terraform)
    local static_ip=""
    local node_resource_group=""
    
    # Trouver le resource group automatique cr√©√© par AKS
    node_resource_group=$(az group list --query "[?contains(name, 'MC_${RESOURCE_GROUP}_${AKS_NAME}')].name" --output tsv 2>/dev/null | head -1)
    
    if [[ -n "$node_resource_group" ]]; then
        log_info "üîç Recherche IP statique dans : $node_resource_group..."
        
        # Nom standard de l'IP statique pour ingress
        local ip_name="ibis-x-prod-ingress-ip"
        
        # Essayer de r√©cup√©rer l'IP statique existante
        static_ip=$(az network public-ip show --resource-group "$node_resource_group" --name "$ip_name" --query "ipAddress" --output tsv 2>/dev/null || echo "")
        
        # Si l'IP n'existe pas, la cr√©er OBLIGATOIREMENT
        if [[ -z "$static_ip" ]]; then
            log_info "üîß Cr√©ation OBLIGATOIRE de l'IP statique manquante..."
            local create_result=$(az network public-ip create \
                --resource-group "$node_resource_group" \
                --name "$ip_name" \
                --allocation-method Static \
                --sku Standard \
                --location eastus \
                --query "publicIp.ipAddress" --output tsv 2>/dev/null || echo "")
            
            if [[ -n "$create_result" ]]; then
                static_ip="$create_result"
                log_success "‚úÖ IP statique cr√©√©e : $static_ip"
            else
                log_error "‚ùå √âCHEC critique : Impossible de cr√©er l'IP statique !"
                exit 1
            fi
        else
            log_success "‚úÖ IP statique existante trouv√©e : $static_ip"
        fi
        
        # Double v√©rification : s'assurer que l'IP existe et est accessible
        local ip_exists=$(az network public-ip show --resource-group "$node_resource_group" --name "$ip_name" --query "ipAddress" --output tsv 2>/dev/null || echo "")
        if [[ -z "$ip_exists" ]] || [[ "$ip_exists" != "$static_ip" ]]; then
            log_error "‚ùå ERREUR CRITIQUE : L'IP statique est incoh√©rente (trouv√©e: $ip_exists, attendue: $static_ip) !"
            exit 1
        fi
        
        log_success "‚úÖ V√©rification IP statique confirm√©e : $static_ip (accessible et coh√©rente)"
    else
        log_error "‚ùå ERREUR CRITIQUE : Resource group AKS non trouv√© !"
        exit 1
    fi
    
    # 3. VALIDATION OBLIGATOIRE
    if [[ -z "$static_ip" ]] || [[ -z "$node_resource_group" ]]; then
        log_error "‚ùå ERREUR CRITIQUE : Impossible de configurer l'IP statique !"
        log_error "   IP statique: ${static_ip:-NON TROUV√âE}"
        log_error "   Node RG: ${node_resource_group:-NON TROUV√â}"
        exit 1
    fi
    
    # 4. Mettre √† jour automatiquement le fichier nginx-ingress-values.yaml
    local nginx_values_file="$K8S_DIR/helm-values/nginx-ingress-values.yaml"
    local nginx_values_backup="$nginx_values_file.backup-$(date +%s)"
    
    log_info "üìù Mise √† jour FORC√âE de nginx-ingress-values.yaml..."
    log_info "   üéØ IP statique FORC√âE: $static_ip"
    log_info "   üéØ Resource Group: $node_resource_group"
    
    # Sauvegarder le fichier original
    cp "$nginx_values_file" "$nginx_values_backup" 2>/dev/null || true
    
    # Cr√©er la nouvelle configuration avec IP statique FORC√âE
    cat > "$nginx_values_file" << EOF
controller:
  replicaCount: 2
  nodeSelector:
    kubernetes.io/os: linux
  service:
    type: LoadBalancer
    loadBalancerIP: "$static_ip"
    annotations:
      # FORCE L'IP STATIQUE - Configuration par deploy-to-azure.sh
      service.beta.kubernetes.io/azure-load-balancer-static-ip: "$static_ip"
      service.beta.kubernetes.io/azure-load-balancer-resource-group: "$node_resource_group"
      service.beta.kubernetes.io/azure-load-balancer-health-probe-request-path: /healthz
      # EMP√äCHER Azure d'utiliser une IP dynamique
      service.beta.kubernetes.io/azure-load-balancer-mode: "shared"
  admissionWebhooks:
    patch:
      nodeSelector:
        kubernetes.io/os: linux

defaultBackend:
  nodeSelector:
    kubernetes.io/os: linux
EOF
    
    # Exporter pour usage ult√©rieur
    export PUBLIC_IP="$static_ip"
    export NODE_RESOURCE_GROUP="$node_resource_group"
    export STATIC_IP_CONFIRMED="$static_ip"
    
    log_success "‚úÖ Configuration IP statique FORC√âE termin√©e !"
    log_success "   üéØ NGINX utilisera OBLIGATOIREMENT l'IP: $static_ip"
    log_success "   üíæ Sauvegarde: $nginx_values_backup"
}

# ‚úÖ FONCTION RENFORC√âE pour installer NGINX Ingress Controller avec IP statique FORC√âE
install_nginx_ingress() {
    log_info "üöÄ Installation RENFORC√âE de NGINX Ingress Controller avec IP statique FORC√âE..."
    
    # ‚úÖ AUTOMATISATION IP STATIQUE RENFORC√âE
    configure_static_ip_for_nginx
    
    # Utiliser les variables export√©es par configure_static_ip_for_nginx
    local static_ip="$STATIC_IP_CONFIRMED"
    local node_resource_group="$NODE_RESOURCE_GROUP"
    
    if [[ -z "$static_ip" ]]; then
        log_error "‚ùå ERREUR CRITIQUE : IP statique non configur√©e !"
        exit 1
    fi
    
    log_info "üéØ IP statique confirm√©e pour NGINX : $static_ip"
    
    # V√©rifier si NGINX existe d√©j√† avec une IP diff√©rente
    local existing_nginx_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
    
    if [[ -n "$existing_nginx_ip" && "$existing_nginx_ip" != "$static_ip" ]]; then
        log_warning "‚ö†Ô∏è NGINX existant avec IP incorrecte ($existing_nginx_ip ‚â† $static_ip)"
        log_info "üîÑ Suppression et recr√©ation de NGINX avec IP statique..."
        helm uninstall ingress-nginx -n ingress-nginx 2>/dev/null || true
        kubectl delete namespace ingress-nginx --ignore-not-found=true
        sleep 10
    fi
    
    # Ajouter le repository Helm NGINX
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    
    # Installation FORC√âE avec toutes les annotations IP statique
    log_info "üì¶ Installation NGINX avec IP statique FORC√âE : $static_ip"
    helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
        --namespace ingress-nginx \
        --create-namespace \
        --set controller.service.loadBalancerIP="$static_ip" \
        --set controller.service.type=LoadBalancer \
        --set "controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-static-ip=$static_ip" \
        --set "controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-resource-group=$node_resource_group" \
        --set "controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-health-probe-request-path=/healthz" \
        --set "controller.service.annotations.service\.beta\.kubernetes\.io/azure-load-balancer-mode=shared" \
        --set controller.replicaCount=2 \
        --set "controller.nodeSelector.kubernetes\.io/os=linux" \
        --set "defaultBackend.nodeSelector.kubernetes\.io/os=linux" \
        --wait --timeout=10m
    
    # ‚úÖ VALIDATION POST-INSTALLATION : V√©rifier que NGINX utilise bien l'IP statique
    log_info "üîç VALIDATION : V√©rification de l'IP assign√©e √† NGINX..."
    
    local max_attempts=30
    local attempt=0
    local nginx_actual_ip=""
    
    while [[ $attempt -lt $max_attempts ]]; do
        nginx_actual_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
        
        if [[ "$nginx_actual_ip" == "$static_ip" ]]; then
            log_success "‚úÖ SUCC√àS : NGINX utilise l'IP statique correcte : $nginx_actual_ip"
            break
        elif [[ -n "$nginx_actual_ip" && "$nginx_actual_ip" != "$static_ip" ]]; then
            log_error "‚ùå √âCHEC CRITIQUE : NGINX utilise une IP incorrecte !"
            log_error "   IP attendue : $static_ip"
            log_error "   IP actuelle : $nginx_actual_ip"
            log_info "üîÑ Tentative de correction..."
            
            # Forcer la correction
            kubectl patch svc ingress-nginx-controller -n ingress-nginx -p "{\"spec\":{\"loadBalancerIP\":\"$static_ip\"}}"
        fi
        
        attempt=$((attempt + 1))
        log_info "‚è≥ Attente IP statique... ($attempt/$max_attempts) - IP actuelle: ${nginx_actual_ip:-PENDING}"
        sleep 10
    done
    
    # Validation finale
    nginx_actual_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
    
    if [[ "$nginx_actual_ip" == "$static_ip" ]]; then
        log_success "üéâ NGINX Ingress Controller install√© avec IP statique CONFIRM√âE : $static_ip"
        
        # Afficher l'√©tat final pour confirmation
        log_info "üìä √âtat final NGINX Ingress :"
        kubectl get svc -n ingress-nginx ingress-nginx-controller
    else
        log_error "‚ùå √âCHEC FINAL : NGINX n'utilise pas l'IP statique !"
        log_error "   IP attendue : $static_ip"
        log_error "   IP actuelle : ${nginx_actual_ip:-AUCUNE}"
        log_error "üîß Veuillez corriger manuellement ou relancer le script"
        exit 1
    fi
}

# Nouvelle fonction pour installer Cert-Manager
install_cert_manager() {
    log_info "Installation de Cert-Manager..."
    
    # Ajouter le repository Helm Cert-Manager
    helm repo add jetstack https://charts.jetstack.io
    helm repo update
    
    # Installer Cert-Manager
    helm upgrade --install cert-manager jetstack/cert-manager \
        --namespace cert-manager \
        --create-namespace \
        --version v1.13.0 \
        --set installCRDs=true \
        --wait
    
    log_success "Cert-Manager install√©"
}

# Fonction pour v√©rifier que les noms de projet sont corrects
verify_project_names() {
    log_info "V√©rification des noms de projet IBIS-X..."
    
    # Les noms sont d√©j√† corrects depuis la migration, pas besoin de modification
    log_success "Noms de projet IBIS-X v√©rifi√©s"
}

# Fonction pour v√©rifier la connexion Azure
check_azure_login() {
    log_info "V√©rification de la connexion Azure..."
    
    if ! az account show &> /dev/null; then
        log_warning "Vous n'√™tes pas connect√© √† Azure. Connexion en cours..."
        az login
    fi
    
    # Afficher le compte actuel
    ACCOUNT_INFO=$(az account show --output json)
    SUBSCRIPTION_NAME=$(echo "$ACCOUNT_INFO" | jq -r '.name')
    SUBSCRIPTION_ID=$(echo "$ACCOUNT_INFO" | jq -r '.id')
    
    log_success "Connect√© √† Azure:"
    echo "  Subscription: $SUBSCRIPTION_NAME"
    echo "  ID: $SUBSCRIPTION_ID"
}

# Fonction pour initialiser Terraform
init_terraform() {
    log_info "Initialisation de Terraform..."
    
    cd "$TERRAFORM_DIR"
    
    # V√©rifier si terraform.tfvars existe
    if [ ! -f "terraform.tfvars" ]; then
        log_warning "Le fichier terraform.tfvars n'existe pas."
        echo "Cr√©ation du fichier terraform.tfvars √† partir du template..."
        cp terraform.tfvars.example terraform.tfvars
        
        log_warning "IMPORTANT: Veuillez modifier le fichier terraform.tfvars selon vos besoins avant de continuer."
        read -p "Appuyez sur Entr√©e pour ouvrir le fichier terraform.tfvars dans l'√©diteur par d√©faut..."
        
        # Ouvrir l'√©diteur
        ${EDITOR:-nano} terraform.tfvars
        
        echo
        read -p "Avez-vous termin√© la configuration du fichier terraform.tfvars ? (y/N): " confirm
        if [[ $confirm != [yY] && $confirm != [yY][eE][sS] ]]; then
            log_error "Configuration annul√©e. Veuillez configurer terraform.tfvars et relancer le script."
            exit 1
        fi
    fi
    
    # Initialiser Terraform
    terraform init
    
    log_success "Terraform initialis√© avec succ√®s"
}

# Fonction pour planifier et appliquer Terraform
deploy_infrastructure() {
    log_info "D√©ploiement de l'infrastructure Azure..."
    
    cd "$TERRAFORM_DIR"
    
    # Planifier le d√©ploiement
    log_info "G√©n√©ration du plan Terraform..."
    terraform plan -out=tfplan
    
    # Demander confirmation
    echo
    log_warning "Terraform va cr√©er/modifier les ressources Azure ci-dessus."
    read -p "Voulez-vous continuer ? (y/N): " confirm
    
    if [[ $confirm != [yY] && $confirm != [yY][eE][sS] ]]; then
        log_error "D√©ploiement annul√© par l'utilisateur"
        exit 1
    fi
    
    # Appliquer le plan
    log_info "Application du plan Terraform..."
    terraform apply tfplan
    
    log_success "Infrastructure Azure d√©ploy√©e avec succ√®s !"
}

# Fonction pour r√©cup√©rer les informations d'infrastructure
get_terraform_outputs() {
    log_info "üìä R√©cup√©ration des informations d'infrastructure - Mode: $DEPLOYMENT_MODE"
    
    if [[ "$USE_GITHUB_SECRETS" == "true" ]]; then
        # üè≠ MODE GITHUB ACTIONS: Variables d'environnement pr√©d√©finies
        log_info "üè≠ Utilisation des variables GitHub Actions..."
        get_github_infrastructure_info
    else
        # üõ†Ô∏è MODE MANUEL: Variables d'environnement ou d√©tection Azure CLI
        log_info "üõ†Ô∏è Configuration manuelle ou d√©tection Azure..."
        get_manual_infrastructure_info
    fi
    
    # Validation finale
    if [[ -z "$ACR_NAME" ]] || [[ -z "$AKS_NAME" ]] || [[ -z "$RESOURCE_GROUP" ]]; then
        log_error "‚ùå Informations d'infrastructure manquantes !"
        log_error "ACR: $ACR_NAME | AKS: $AKS_NAME | RG: $RESOURCE_GROUP"
        exit 1
    fi
    
    # Mise √† jour automatique de tous les fichiers avec le bon nom ACR
    log_info "üîß Mise √† jour automatique des fichiers avec ACR: $ACR_NAME"
    update_all_acr_references
    
    log_success "‚úÖ Informations d'infrastructure r√©cup√©r√©es:"
    echo "  Mode: $DEPLOYMENT_MODE"
    echo "  ACR Registry: $ACR_NAME"
    echo "  AKS Cluster: $AKS_NAME"
    echo "  Resource Group: $RESOURCE_GROUP"
    echo "  Storage Account: ${STORAGE_ACCOUNT:-N/A}"
    echo "  Public IP: ${PUBLIC_IP:-N/A}"
}

# Fonction pour r√©cup√©rer les infos GitHub Actions
get_github_infrastructure_info() {
    log_info "üìã Configuration depuis variables d'environnement GitHub Actions..."
    
    # Les variables sont d√©j√† d√©finies par GitHub Actions
    export ACR_NAME="$AZURE_CONTAINER_REGISTRY"
    export AKS_NAME="$AKS_CLUSTER_NAME"
    export RESOURCE_GROUP="$AZURE_RESOURCE_GROUP"
    
    # R√©cup√©rer l'IP publique si possible
    PUBLIC_IP=$(az network public-ip list --resource-group "$RESOURCE_GROUP" --query "[0].ipAddress" -o tsv 2>/dev/null || echo "")
    export PUBLIC_IP
    
    # Storage sera r√©cup√©r√© dynamiquement par les fonctions de secrets
    log_success "‚úÖ Configuration GitHub Actions charg√©e"
}

# Fonction pour r√©cup√©rer les infos manuellement
get_manual_infrastructure_info() {
    log_info "üõ†Ô∏è Configuration manuelle - Variables d'environnement ou Azure CLI..."
    
    # Utiliser les variables d'environnement pr√©d√©finies (d√©j√† export√©es)
    export ACR_NAME="$AZURE_CONTAINER_REGISTRY"
    export AKS_NAME="$AKS_CLUSTER_NAME"
    export RESOURCE_GROUP="$AZURE_RESOURCE_GROUP"
    
    # Si l'infrastructure a √©t√© cr√©√©e par Terraform, essayer de r√©cup√©rer depuis Terraform
    if [[ -f "$TERRAFORM_DIR/terraform.tfstate" ]]; then
        log_info "üìÇ Infrastructure Terraform d√©tect√©e, r√©cup√©ration des outputs..."
        cd "$TERRAFORM_DIR"
        
        # R√©cup√©rer les outputs Terraform
        local tf_storage=$(terraform output -raw storage_account_name 2>/dev/null || echo "")
        local tf_acr=$(terraform output -raw acr_name 2>/dev/null || echo "")
        local tf_aks=$(terraform output -raw aks_cluster_name 2>/dev/null || echo "")
        local tf_rg=$(terraform output -raw resource_group_name 2>/dev/null || echo "")
        local tf_ip=$(terraform output -raw public_ip_address 2>/dev/null || echo "")
        
        # Utiliser les valeurs Terraform si disponibles
        if [[ -n "$tf_acr" ]]; then
            export ACR_NAME="$tf_acr"
            export AKS_NAME="$tf_aks"
            export RESOURCE_GROUP="$tf_rg"
            export STORAGE_ACCOUNT="$tf_storage"
            export PUBLIC_IP="$tf_ip"
            
            if [[ -n "$tf_storage" ]]; then
                STORAGE_KEY=$(terraform output -raw storage_account_primary_key 2>/dev/null || echo "")
                export STORAGE_KEY
            fi
            
            log_success "‚úÖ Configuration r√©cup√©r√©e depuis Terraform"
        else
            log_warning "‚ö†Ô∏è Terraform outputs vides, utilisation des variables d'environnement"
        fi
        
        cd "$PROJECT_ROOT"
    fi
    
    # Fallback Azure CLI pour r√©cup√©rer l'IP publique
    if [[ -z "$PUBLIC_IP" ]]; then
        PUBLIC_IP=$(az network public-ip list --resource-group "$RESOURCE_GROUP" --query "[0].ipAddress" -o tsv 2>/dev/null || echo "")
        export PUBLIC_IP
    fi
    
    log_info "üìã Configuration finale:"
    log_info "  ACR: $ACR_NAME"
    log_info "  AKS: $AKS_NAME" 
    log_info "  Resource Group: $RESOURCE_GROUP"
    
    log_success "‚úÖ Configuration manuelle charg√©e"
}

# Fonction pour l'initialisation automatique des donn√©es (selon environnement)
initialize_sample_data() {
    if [[ "$WITH_DATA" == "true" ]]; then
        log_info "üìä Initialisation des donn√©es d'exemple..."
        
        # Attendre que service-selection soit pr√™t
        log_info "‚è≥ Attente que service-selection soit pr√™t..."
        kubectl wait --for=condition=ready pod -l app=service-selection -n "${K8S_NAMESPACE:-ibis-x}" --timeout=5m
        
        # Initialiser les donn√©es
        log_info "üöÄ Lancement de l'initialisation des datasets..."
        kubectl exec -n "${K8S_NAMESPACE:-ibis-x}" deployment/service-selection -- python scripts/init_datasets.py all
        
        log_success "‚úÖ Donn√©es d'exemple initialis√©es"
    else
        log_info "üìä Initialisation des donn√©es d√©sactiv√©e (WITH_DATA=$WITH_DATA)"
    fi
}

# Fonction pour attendre et v√©rifier les migrations
wait_for_migrations() {
    log_info "‚è≥ Attente des migrations de base de donn√©es..."
    
    # Attendre PostgreSQL
    log_info "üóÑÔ∏è Attente que PostgreSQL soit pr√™t..."
    kubectl wait pod --selector=app=postgresql --for=condition=Ready -n "${K8S_NAMESPACE:-ibis-x}" --timeout=5m
    
    # Attendre les migrations
    log_info "üîÑ Attente des jobs de migration..."
    if kubectl wait --for=condition=complete job/api-gateway-migration-job -n "${K8S_NAMESPACE:-ibis-x}" --timeout=5m 2>/dev/null; then
        log_success "‚úÖ Migration API Gateway termin√©e"
    else
        log_warning "‚ö†Ô∏è Migration API Gateway non trouv√©e ou √©chou√©e"
    fi
    
    if kubectl wait --for=condition=complete job/service-selection-migration-job -n "${K8S_NAMESPACE:-ibis-x}" --timeout=5m 2>/dev/null; then
        log_success "‚úÖ Migration Service Selection termin√©e"
    else
        log_warning "‚ö†Ô∏è Migration Service Selection non trouv√©e ou √©chou√©e"
    fi
    
    # Red√©marrer les applications (comme dans GitHub Actions)
    if [[ "$DEPLOYMENT_MODE" == "production" ]]; then
        log_info "üîÑ Red√©marrage des applications (mode production)..."
        kubectl rollout restart deployment api-gateway -n "${K8S_NAMESPACE:-ibis-x}" 2>/dev/null || true
        kubectl rollout restart deployment service-selection -n "${K8S_NAMESPACE:-ibis-x}" 2>/dev/null || true
    fi
    
    log_success "‚úÖ Migrations et red√©marrages termin√©s"
}

# Fonction de nettoyage des jobs (comme dans GitHub Actions)
cleanup_migration_jobs() {
    if [[ "$DEPLOYMENT_MODE" == "production" ]]; then
        log_info "üßπ Nettoyage des jobs de migration (mode production)..."
        kubectl delete job api-gateway-migration-job service-selection-migration-job -n "${K8S_NAMESPACE:-ibis-x}" --ignore-not-found=true
        log_success "‚úÖ Jobs de migration nettoy√©s"
    else
        log_info "üßπ Conservation des jobs de migration (mode d√©veloppement)"
    fi
}

# Fonction pour configurer kubectl
configure_kubectl() {
    log_info "Configuration de kubectl pour AKS..."
    
    # R√©cup√©rer les credentials AKS
    az aks get-credentials --resource-group "$RESOURCE_GROUP" --name "$AKS_NAME" --overwrite-existing
    
    # V√©rifier la connexion
    kubectl cluster-info
    
    log_success "kubectl configur√© pour AKS"
}

# Fonction pour mettre √† jour les secrets Kubernetes
update_k8s_secrets() {
    log_info "Mise √† jour des secrets Kubernetes..."
    
    # Cr√©er le namespace s'il n'existe pas
    kubectl create namespace ibis-x --dry-run=client -o yaml | kubectl apply -f -
    
    # Les secrets seront cr√©√©s automatiquement par create_missing_secrets()
    # Cette fonction se contente de pr√©parer le namespace
    
    log_success "Namespace et pr√©paration des secrets termin√©s"
}

# ‚úÖ FONCTION AUTOMATIQUE : Configuration Frontend pour Production
configure_frontend_for_production() {
    log_info "üåê Configuration automatique du frontend pour la production..."
    
    if [[ "$ANGULAR_ENV" == "production" ]]; then
        log_info "üìù Mise √† jour FORC√âE des URLs frontend pour le domaine de production..."
        
        # Sauvegarder le fichier environment.prod.ts
        local env_file="$PROJECT_ROOT/frontend/src/environments/environment.prod.ts"
        local env_backup="$env_file.backup-$(date +%s)"
        
        if [[ -f "$env_file" ]]; then
            cp "$env_file" "$env_backup"
            log_info "üíæ Sauvegarde: $env_backup"
        fi
        
        # URLs de production FIXES
        local api_url="https://api.ibisx.fr"
        local frontend_domain="ibisx.fr"
        
        log_info "üéØ CONFIGURATION PRODUCTION FORC√âE:"
        log_info "   API URL: $api_url"
        log_info "   Frontend Domain: $frontend_domain"
        log_info "   Production Mode: TRUE"
        
        # Si PUBLIC_IP est disponible, on peut aussi le proposer comme fallback
        if [[ -n "$PUBLIC_IP" ]] && [[ "$PUBLIC_IP" != "N/A" ]]; then
            log_info "üì° IP publique statique: $PUBLIC_IP"
        fi
        
        # Cr√©er le fichier environment.prod.ts avec les bonnes URLs (FORC√â)
        cat > "$env_file" << EOF
export const environment = {
  production: true,
  // URL publique de l'API Gateway via l'Ingress Controller - toujours en HTTPS
  apiUrl: '$api_url',
  // Domaine de production pour le frontend
  productionDomain: '$frontend_domain'
};
EOF
        
        log_success "‚úÖ Frontend FORC√â en mode production:"
        log_success "   ‚úÖ production: true"
        log_success "   ‚úÖ API URL: $api_url"
        log_success "   ‚úÖ Domaine: $frontend_domain"
        log_success "   üìÑ Fichier: $env_file"
        
        # V√©rifier que le fichier est correct
        if grep -q "https://api.ibisx.fr" "$env_file" && grep -q "production: true" "$env_file"; then
            log_success "‚úÖ V√©rification OK - URLs de production confirm√©es"
        else
            log_error "‚ùå ERREUR: Configuration frontend incorrecte !"
            cat "$env_file"
            exit 1
        fi
    else
        log_info "üõ†Ô∏è Mode d√©veloppement - configuration frontend inchang√©e"
    fi
}

# Fonction INTELLIGENTE pour construire et pousser les images Docker
build_and_push_images() {
    log_info "üèóÔ∏è Construction et push des images Docker vers ACR..."
    log_info "üè∑Ô∏è Mode: $DEPLOYMENT_MODE | Tag: $IMAGE_TAG | Angular: $ANGULAR_ENV"
    
    # ‚úÖ NOUVEAU: Configurer le frontend avant le build
    configure_frontend_for_production
    
    # ‚úÖ FORCER REBUILD FRONTEND EN PRODUCTION: Supprimer l'image locale existante
    if [[ "$DEPLOYMENT_MODE" == "manual-production" ]] || [[ "$ANGULAR_ENV" == "production" ]]; then
        log_info "üîÑ Suppression de l'image frontend existante pour forcer le rebuild en production..."
        docker rmi "$ACR_NAME.azurecr.io/frontend:latest" 2>/dev/null || true
        docker rmi "frontend:latest" 2>/dev/null || true
        log_info "‚úÖ Images frontend locales supprim√©es - rebuild forc√©"
    fi
    
    # Se connecter √† ACR
    az acr login --name "$ACR_NAME"
    
    cd "$PROJECT_ROOT"
    
    # Fonction helper pour build/push avec gestion intelligente des tags
    build_and_push_image() {
        local service_name="$1"
        local dockerfile_path="$2"
        local build_context="$3"
        local build_args="$4"
        
        log_info "üì¶ Construction de l'image $service_name..."
        
        # Tags selon l'environnement
        local base_image="$ACR_NAME.azurecr.io/$service_name"
        local tags_args=""
        
        if [[ "$DEPLOYMENT_MODE" == "production" ]]; then
            # En production : tag avec SHA + latest
            tags_args="-t $base_image:$IMAGE_TAG -t $base_image:latest"
        else
            # En local : seulement latest
            tags_args="-t $base_image:latest"
        fi
        
        # Construire avec les arguments appropri√©s
        local docker_cmd="docker build $tags_args $build_args -f $dockerfile_path $build_context"
        
        if eval "$docker_cmd"; then
            # Pousser tous les tags
            if [[ "$DEPLOYMENT_MODE" == "production" ]]; then
                docker push "$base_image:$IMAGE_TAG"
                docker push "$base_image:latest"
                log_success "‚úÖ Image $service_name push√©e (tags: $IMAGE_TAG, latest)"
            else
                docker push "$base_image:latest"
                log_success "‚úÖ Image $service_name push√©e (tag: latest)"
            fi
        else
            log_error "‚ùå √âchec construction de l'image $service_name"
            exit 1
        fi
    }
    
    # 1. API Gateway
    build_and_push_image "ibis-x-api-gateway" "api-gateway/Dockerfile" "api-gateway/" ""
    
    # 2. Service Selection (contexte racine pour acc√©der aux modules communs)
    build_and_push_image "service-selection" "service-selection/Dockerfile" "." ""
    
    # 3. Frontend (avec build args sp√©cifiques √† l'environnement)
    local frontend_build_args=""
    if [[ "$DEPLOYMENT_MODE" == "manual-production" ]] || [[ "$ANGULAR_ENV" == "production" ]]; then
        frontend_build_args="--build-arg ANGULAR_ENV=production --no-cache"
        log_info "üåê Frontend: Build FORC√â en mode PRODUCTION (--no-cache)"
        log_info "üìù Variables d'environnement: ANGULAR_ENV=production"
        log_info "üîó API URL: https://api.ibisx.fr"
        log_info "üåê Domain: ibisx.fr"
    else
        frontend_build_args="--build-arg ANGULAR_ENV=development"
        log_info "üåê Frontend: Build en mode DEVELOPMENT"
    fi
    
    build_and_push_image "frontend" "frontend/Dockerfile" "frontend/" "$frontend_build_args"
    
    log_success "üöÄ Toutes les images Docker push√©es vers ACR : $ACR_NAME"
}

# Fonction pour d√©ployer l'application sur Kubernetes
deploy_application() {
    log_info "D√©ploiement de l'application IBIS-X sur AKS..."
    
    cd "$PROJECT_ROOT"
    
    # Les placeholders ACR ont d√©j√† √©t√© remplac√©s lors de get_terraform_outputs
    
    # V√©rifier les noms de projet
    verify_project_names
    
    # Installer les composants Kubernetes n√©cessaires
    install_nginx_ingress
    install_cert_manager
    
    # Attendre que les contr√¥leurs soient pr√™ts
    log_info "Attente que NGINX Ingress soit pr√™t..."
    kubectl wait --namespace ingress-nginx \
        --for=condition=ready pod \
        --selector=app.kubernetes.io/component=controller \
        --timeout=300s
    
    log_info "Attente que Cert-Manager soit pr√™t..."
    kubectl wait --namespace cert-manager \
        --for=condition=ready pod \
        --selector=app.kubernetes.io/name=cert-manager \
        --timeout=300s
    
    # Les placeholders ACR ont d√©j√† √©t√© remplac√©s
    
    # D√©ploiement automatique avec strat√©gie optimis√©e par OS
    log_info "D√©ploiement automatique avec strat√©gie optimis√©e..."
    
    # Sauvegarder le r√©pertoire courant
    ORIGINAL_DIR=$(pwd)
    
    # Sur Windows, utiliser directement le d√©ploiement robuste (kustomize a des probl√®mes avec les chemins)
    # Sur Linux/MacOS, essayer d'abord kustomize
    if [[ "$IS_WINDOWS" == true ]]; then
        log_info "Windows d√©tect√© - utilisation du d√©ploiement robuste optimis√©..."
        
        # D√©ploiement robuste √©tape par √©tape
        log_info "D√©ploiement automatique des composants..."
        
        # 1. Secrets de base (d√©j√† cr√©√©s par create_missing_secrets)
        kubectl apply -f "$K8S_DIR/base/api-gateway/gateway-secrets.yaml" 2>/dev/null || true
        kubectl apply -f "$K8S_DIR/base/service-selection/db-secrets.yaml" 2>/dev/null || true
        
        # 2. PostgreSQL
        kubectl apply -f "$K8S_DIR/overlays/azure/postgresql-statefulset.yaml" || true
        kubectl apply -f "$K8S_DIR/base/postgres/postgresql-service.yaml" || true
        
        # 3. Applications avec images automatiquement corrig√©es
        deploy_app_with_correct_images
        
        # 4. Services
        kubectl apply -f "$K8S_DIR/base/api-gateway/service.yaml" || true
        kubectl apply -f "$K8S_DIR/base/service-selection/service.yaml" || true  
        kubectl apply -f "$K8S_DIR/base/frontend/service.yaml" || true
        
        # 5. Ingress et certificats
        kubectl apply -f "$K8S_DIR/base/common/letsencrypt-prod-issuer.yaml" || true
        kubectl apply -f "$K8S_DIR/base/common/ingress.yaml" || true
        
        log_success "D√©ploiement robuste Windows termin√© avec succ√®s"
    else
        # Sur Linux/MacOS, essayer d'abord Kustomize
        log_info "Linux/MacOS d√©tect√© - tentative Kustomize puis fallback si n√©cessaire..."
        
        cd "$K8S_DIR/overlays/azure/" || exit 1
        
        if kubectl apply -k . 2>/dev/null; then
            cd "$ORIGINAL_DIR"
            log_success "D√©ploiement Kustomize r√©ussi"
        else
            log_info "Kustomize √©chou√© - utilisation du d√©ploiement alternatif..."
            cd "$ORIGINAL_DIR"
            
            # D√©ploiement robuste √©tape par √©tape
            log_info "D√©ploiement automatique des composants..."
            
            # 1. Secrets de base (d√©j√† cr√©√©s par create_missing_secrets)
            kubectl apply -f "$K8S_DIR/base/api-gateway/gateway-secrets.yaml" 2>/dev/null || true
            kubectl apply -f "$K8S_DIR/base/service-selection/db-secrets.yaml" 2>/dev/null || true
            
            # 2. PostgreSQL
            kubectl apply -f "$K8S_DIR/overlays/azure/postgresql-statefulset.yaml" || true
            kubectl apply -f "$K8S_DIR/base/postgres/postgresql-service.yaml" || true
            
            # 3. Applications avec images automatiquement corrig√©es
            deploy_app_with_correct_images
            
            # 4. Services
            kubectl apply -f "$K8S_DIR/base/api-gateway/service.yaml" || true
            kubectl apply -f "$K8S_DIR/base/service-selection/service.yaml" || true  
            kubectl apply -f "$K8S_DIR/base/frontend/service.yaml" || true
            
            # 5. Ingress et certificats
            kubectl apply -f "$K8S_DIR/base/common/letsencrypt-prod-issuer.yaml" || true
            kubectl apply -f "$K8S_DIR/base/common/ingress.yaml" || true
            
            log_success "D√©ploiement alternatif automatique termin√©"
        fi
    fi
}

# Fonction pour d√©ployer les applications avec les bonnes images automatiquement
deploy_app_with_correct_images() {
    log_info "D√©ploiement automatique des applications avec images corrig√©es..."
    
    # Cr√©er fichiers temporaires avec les bonnes images (m√©thode robuste)
    local TEMP_DIR=""
    if [[ "$IS_WINDOWS" == true ]]; then
        TEMP_DIR="$TEMP/ibis-x-deploy-$$"
    else
        TEMP_DIR="/tmp/ibis-x-deploy-$$"
    fi
    mkdir -p "$TEMP_DIR"
    
    # 1. API Gateway
    log_info "D√©ploiement API Gateway avec image ACR $ACR_NAME..."
    sed "s|image: ibis-x-api-gateway|image: $ACR_NAME.azurecr.io/ibis-x-api-gateway:latest|" "$K8S_DIR/base/api-gateway/deployment.yaml" > "$TEMP_DIR/api-gateway-deployment.yaml"
    kubectl apply -f "$TEMP_DIR/api-gateway-deployment.yaml"
    kubectl apply -f "$K8S_DIR/base/api-gateway/service.yaml" 2>/dev/null || true
    
    # 2. Service Selection  
    log_info "D√©ploiement Service Selection avec image ACR $ACR_NAME..."
    sed "s|image: service-selection|image: $ACR_NAME.azurecr.io/service-selection:latest|" "$K8S_DIR/base/service-selection/deployment.yaml" > "$TEMP_DIR/service-selection-deployment.yaml"
    kubectl apply -f "$TEMP_DIR/service-selection-deployment.yaml"
    kubectl apply -f "$K8S_DIR/base/service-selection/service.yaml" 2>/dev/null || true
    
    # 3. Frontend
    log_info "D√©ploiement Frontend avec image ACR $ACR_NAME..."
    sed "s|image: frontend|image: $ACR_NAME.azurecr.io/frontend:latest|" "$K8S_DIR/base/frontend/deployment.yaml" > "$TEMP_DIR/frontend-deployment.yaml"
    kubectl apply -f "$TEMP_DIR/frontend-deployment.yaml"
    kubectl apply -f "$K8S_DIR/base/frontend/service.yaml" 2>/dev/null || true
    
    # 4. Secrets n√©cessaires (cr√©√©s automatiquement)
    log_info "Cr√©ation automatique des secrets manquants..."
    kubectl apply -f "$K8S_DIR/base/api-gateway/gateway-secrets.yaml" 2>/dev/null || true
    kubectl apply -f "$K8S_DIR/base/service-selection/db-secrets.yaml" 2>/dev/null || true
    
    # 5. Red√©marrage forc√© pour prendre en compte les nouvelles images et secrets
    log_info "Red√©marrage automatique des pods avec nouvelles images ACR..."
    kubectl delete pods -l app=api-gateway -n ibis-x --ignore-not-found=true 2>/dev/null || true
    kubectl delete pods -l app=service-selection -n ibis-x --ignore-not-found=true 2>/dev/null || true
    kubectl delete pods -l app=frontend -n ibis-x --ignore-not-found=true 2>/dev/null || true
    
    # 6. Mise √† jour automatique des images vers ACR  
    log_info "Mise √† jour automatique des images vers ACR..."
    kubectl set image deployment/api-gateway api-gateway=$ACR_NAME.azurecr.io/ibis-x-api-gateway:latest -n ibis-x 2>/dev/null || true
    kubectl set image deployment/service-selection service-selection=$ACR_NAME.azurecr.io/service-selection:latest -n ibis-x 2>/dev/null || true
    kubectl set image deployment/frontend frontend=$ACR_NAME.azurecr.io/frontend:latest -n ibis-x 2>/dev/null || true
    
    # 7. Ingress et certificats SSL automatiques
    log_info "D√©ploiement de l'ingress et g√©n√©ration automatique des certificats SSL..."
    kubectl apply -f "$K8S_DIR/base/common/letsencrypt-prod-issuer.yaml" 2>/dev/null || true
    kubectl apply -f "$K8S_DIR/base/common/ingress.yaml" 2>/dev/null || true
    
    # Nettoyer les fichiers temporaires
    rm -rf "$TEMP_DIR" 2>/dev/null || true
    
    log_success "‚úÖ D√âPLOIEMENT 100% AUTOMATIQUE R√âUSSI ! Applications en ligne avec images ACR, secrets, et SSL !"
}

# ‚úÖ FONCTION AUTOMATIQUE : Forcer Rebuild et Red√©ploiement Frontend Production
force_frontend_production_rebuild() {
    log_info "üöÄ Reconstruction automatique du frontend en mode production..."
    
    # 1. Configurer l'environnement de production
    configure_frontend_for_production
    
    # 2. Supprimer les images existantes pour forcer le rebuild
    log_info "üßπ Suppression des images frontend existantes..."
    docker rmi "$ACR_NAME.azurecr.io/frontend:latest" 2>/dev/null || true
    docker rmi "$ACR_NAME.azurecr.io/frontend:prod-fix" 2>/dev/null || true
    docker rmi "frontend:latest" 2>/dev/null || true
    
    # 3. Rebuild avec les nouvelles variables d'environnement
    cd "$PROJECT_ROOT/frontend"
    log_info "üèóÔ∏è Construction frontend avec ANGULAR_ENV=production..."
    log_info "üìù API URL configur√©e: https://api.ibisx.fr"
    log_info "üåê Domain configur√©: ibisx.fr"
    
    # Build avec --no-cache pour √™tre s√ªr que les changements sont pris en compte
    docker build \
        --build-arg ANGULAR_ENV=production \
        --no-cache \
        -t "$ACR_NAME.azurecr.io/frontend:prod-fixed" \
        -t "$ACR_NAME.azurecr.io/frontend:latest" .
    
    # 4. Push vers ACR
    log_info "üì§ Push vers ACR..."
    az acr login --name "$ACR_NAME"
    docker push "$ACR_NAME.azurecr.io/frontend:prod-fixed"
    docker push "$ACR_NAME.azurecr.io/frontend:latest"
    
    # 5. Red√©ployer le frontend avec la nouvelle image
    log_info "üîÑ Red√©ploiement automatique du frontend..."
    kubectl set image deployment/frontend frontend="$ACR_NAME.azurecr.io/frontend:prod-fixed" -n ibis-x
    kubectl rollout restart deployment/frontend -n ibis-x
    
    # 6. Attendre que le rollout soit termin√©
    log_info "‚è≥ Attente du rollout frontend..."
    kubectl rollout status deployment/frontend -n ibis-x --timeout=300s
    
    cd "$PROJECT_ROOT"
    log_success "‚úÖ Frontend reconstruit et red√©ploy√© en mode production !"
}

# Fonction SIMPLE et EFFICACE pour remplacer les placeholders ACR
update_all_acr_references() {
    log_info "üîç Remplacement des placeholders ACR : PLACEHOLDER_ACR ‚Üí $ACR_NAME"
    
    local updated_files=0
    
    # Fichiers critiques √† mettre √† jour
    local critical_files=(
        "$K8S_DIR/base/jobs/api-gateway-migration-job.yaml"
        "$K8S_DIR/base/jobs/service-selection-migration-job.yaml"
        "$K8S_DIR/overlays/azure/kustomization.yaml"
        "$K8S_DIR/overlays/azure/migration-jobs-image-patch.yaml"
        "$K8S_DIR/overlays/azure/service-selection-migration-job-patch.yaml"
    )
    
    # Fonction simple pour remplacer PLACEHOLDER_ACR dans un fichier
    replace_placeholder_in_file() {
        local file_path="$1"
        local file_name=$(basename "$file_path")
        
        if [[ ! -f "$file_path" ]]; then
            log_warning "‚ö†Ô∏è Fichier introuvable: $file_path"
            return 1
        fi
        
        # V√©rifier si le fichier contient des placeholders
        if ! grep -q "PLACEHOLDER_ACR" "$file_path" 2>/dev/null; then
            log_info "‚úÖ $file_name - aucun placeholder √† remplacer"
            return 0
        fi
        
        log_info "üîß Remplacement des placeholders dans $file_name..."
        
        # Remplacement simple et direct
        if sed -i "s|PLACEHOLDER_ACR|$ACR_NAME|g" "$file_path" 2>/dev/null; then
            # V√©rifier que le remplacement a fonctionn√©
            if grep -q "$ACR_NAME\.azurecr\.io" "$file_path" 2>/dev/null; then
                log_success "‚úÖ $file_name mis √† jour avec $ACR_NAME"
                return 0
            else
                log_error "‚ùå √âchec de v√©rification pour $file_name"
                return 1
            fi
        else
            log_error "‚ùå √âchec du remplacement pour $file_name"
            return 1
        fi
    }
    
    # Remplacer les placeholders dans chaque fichier critique
    log_info "üéØ Remplacement des placeholders dans tous les fichiers..."
    
    for file in "${critical_files[@]}"; do
        if replace_placeholder_in_file "$file"; then
            updated_files=$((updated_files + 1))
        fi
    done
    
    log_success "üéØ Remplacement termin√© - $updated_files fichier(s) trait√©s avec ACR : $ACR_NAME"
    
    return 0
}

# Fonction INTELLIGENTE pour g√©rer automatiquement les jobs de migration avec les bonnes images ACR
fix_migration_jobs() {
    log_info "üîç V√âRIFICATION INTELLIGENTE des jobs de migration avec ACR $ACR_NAME..."
    
    # Les fichiers ont d√©j√† √©t√© corrig√©s avec les placeholders ACR
    
    # V√©rifier les jobs existants et leur statut
    local api_job_exists=$(kubectl get job api-gateway-migration-job -n ibis-x 2>/dev/null && echo "true" || echo "false")
    local service_job_exists=$(kubectl get job service-selection-migration-job -n ibis-x 2>/dev/null && echo "true" || echo "false")
    
    local api_complete="False"
    local service_complete="False"
    
    if [[ "$api_job_exists" == "true" ]]; then
        api_complete=$(kubectl get job api-gateway-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
    fi
    
    if [[ "$service_job_exists" == "true" ]]; then
        service_complete=$(kubectl get job service-selection-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
    fi
    
    # Si les jobs existent et sont termin√©s avec succ√®s, ne pas les recr√©er
    if [[ "$api_complete" == "True" ]] && [[ "$service_complete" == "True" ]]; then
        log_success "‚úÖ Migrations d√©j√† termin√©es avec succ√®s - aucune action n√©cessaire"
        return 0
    fi
    
    # V√©rifier s'il y a des jobs d√©faillants (ImagePullBackOff ou Failed)
    local failed_migration_pods=$(kubectl get pods -n ibis-x -o jsonpath='{.items[?(@.metadata.name=~".*migration.*")].metadata.name}' 2>/dev/null || echo "")
    local has_failed_jobs=false
    
    if [[ -n "$failed_migration_pods" ]]; then
        for pod in $failed_migration_pods; do
            local pod_status=$(kubectl get pod "$pod" -n ibis-x -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
            local container_status=$(kubectl get pod "$pod" -n ibis-x -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null || echo "")
            
            if [[ "$pod_status" == "Failed" ]] || [[ "$container_status" == "ImagePullBackOff" ]]; then
                has_failed_jobs=true
                log_warning "‚ùå Job d√©faillant d√©tect√©: $pod (Status: $pod_status, Reason: $container_status)"
            fi
        done
    fi
    
    # Si jobs d√©faillants OU jobs non existants, les recr√©er
    if [[ "$has_failed_jobs" == true ]] || [[ "$api_job_exists" == "false" ]] || [[ "$service_job_exists" == "false" ]]; then
        log_info "üßπ NETTOYAGE et RECR√âATION des jobs de migration..."
        
        # Supprimer tous les jobs de migration existants
        kubectl delete job api-gateway-migration-job service-selection-migration-job -n ibis-x 2>/dev/null || true
        sleep 3
        
        # Cr√©er les nouveaux jobs avec les fichiers corrig√©s
        log_info "üöÄ Cr√©ation des jobs de migration avec ACR corrig√© $ACR_NAME..."
        kubectl apply -f "$K8S_DIR/base/jobs/api-gateway-migration-job.yaml" || {
            log_error "‚ùå √âchec cr√©ation job API Gateway"
            return 1
        }
        kubectl apply -f "$K8S_DIR/base/jobs/service-selection-migration-job.yaml" || {
            log_error "‚ùå √âchec cr√©ation job Service Selection"
            return 1
        }
        
        log_success "‚úÖ Jobs de migration cr√©√©s avec les bonnes images ACR"
    fi
    
    # Attendre et v√©rifier la compl√©tion avec feedback am√©lior√©
    log_info "‚è≥ Attente de la compl√©tion des migrations (timeout: 5min)..."
    
    local timeout=300
    local elapsed=0
    local check_interval=15
    
    while [[ $elapsed -lt $timeout ]]; do
        # Nettoyer les sorties kubectl pour √©viter les caract√®res parasites
        api_complete=$(kubectl get job api-gateway-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
        service_complete=$(kubectl get job service-selection-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
        
        local api_failed=$(kubectl get job api-gateway-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
        local service_failed=$(kubectl get job service-selection-migration-job -n ibis-x -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' 2>/dev/null | tr -d '\r\n' || echo "False")
        
        if [[ "$api_complete" == "True" ]] && [[ "$service_complete" == "True" ]]; then
            log_success "‚úÖ TOUTES LES MIGRATIONS TERMIN√âES AVEC SUCC√àS !"
            return 0
        fi
        
        if [[ "$api_failed" == "True" ]] || [[ "$service_failed" == "True" ]]; then
            log_error "‚ùå √âchec de migration d√©tect√© - Affichage des logs..."
            kubectl get jobs -n ibis-x 2>/dev/null || true
            kubectl get pods -n ibis-x | grep migration 2>/dev/null || true
            return 1
        fi
        
        log_info "‚è≥ Migrations en cours... API: $api_complete, Service: $service_complete (${elapsed}s/${timeout}s)"
        sleep $check_interval
        elapsed=$((elapsed + check_interval))
    done
    
    # Si on arrive ici, il y a eu un timeout
    log_warning "‚ö†Ô∏è TIMEOUT atteint - V√©rification du statut final..."
    kubectl get jobs -n ibis-x 2>/dev/null || true
    kubectl get pods -n ibis-x | grep migration 2>/dev/null || true
    
    log_success "üéØ Gestion automatique des jobs de migration termin√©e (avec timeout)"
    return 1
}

# ‚úÖ FONCTION AUTOMATIQUE : V√©rification et correction IP statique NGINX
verify_and_fix_nginx_static_ip() {
    log_info "üîç V√âRIFICATION AUTOMATIQUE : IP statique NGINX..."
    
    # R√©cup√©rer l'IP statique configur√©e
    local expected_static_ip="$STATIC_IP_CONFIRMED"
    if [[ -z "$expected_static_ip" ]]; then
        # Fallback : r√©cup√©rer depuis Azure
        local node_resource_group=$(az group list --query "[?contains(name, 'MC_${RESOURCE_GROUP}_${AKS_NAME}')].name" --output tsv 2>/dev/null | head -1)
        if [[ -n "$node_resource_group" ]]; then
            expected_static_ip=$(az network public-ip show --resource-group "$node_resource_group" --name "ibis-x-prod-ingress-ip" --query "ipAddress" --output tsv 2>/dev/null || echo "")
        fi
    fi
    
    if [[ -z "$expected_static_ip" ]]; then
        log_warning "‚ö†Ô∏è Impossible de d√©terminer l'IP statique attendue"
        return 0
    fi
    
    # V√©rifier l'IP actuelle de NGINX
    local nginx_current_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
    
    log_info "üéØ IP statique attendue : $expected_static_ip"
    log_info "üîç IP actuelle NGINX : ${nginx_current_ip:-AUCUNE}"
    
    if [[ "$nginx_current_ip" == "$expected_static_ip" ]]; then
        log_success "‚úÖ NGINX utilise l'IP statique correcte : $nginx_current_ip"
        
        # V√©rifier aussi que l'ingress application utilise la bonne IP
        local ingress_ip=$(kubectl get ingress -n ibis-x ibis-x-ingress -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
        if [[ "$ingress_ip" == "$expected_static_ip" ]]; then
            log_success "‚úÖ Ingress application utilise l'IP statique correcte : $ingress_ip"
        else
            log_warning "‚ö†Ô∏è Ingress application : IP diff√©rente ou en attente (${ingress_ip:-PENDING})"
        fi
    else
        log_error "‚ùå PROBL√àME D√âTECT√â : NGINX utilise une IP incorrecte !"
        log_error "   IP attendue : $expected_static_ip"
        log_error "   IP actuelle : ${nginx_current_ip:-AUCUNE}"
        
        log_info "üîß CORRECTION AUTOMATIQUE en cours..."
        
        # Forcer la correction
        kubectl patch svc ingress-nginx-controller -n ingress-nginx -p "{\"spec\":{\"loadBalancerIP\":\"$expected_static_ip\"}}" 2>/dev/null || true
        
        # Attendre et v√©rifier √† nouveau
        sleep 30
        nginx_current_ip=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
        
        if [[ "$nginx_current_ip" == "$expected_static_ip" ]]; then
            log_success "‚úÖ CORRECTION R√âUSSIE : NGINX utilise maintenant l'IP statique : $nginx_current_ip"
        else
            log_warning "‚ö†Ô∏è CORRECTION PARTIELLE : Recr√©ation de NGINX recommand√©e"
            log_warning "   Lancez √† nouveau le script pour forcer la recr√©ation"
        fi
    fi
}

# Fonction de v√©rification finale et auto-correction RENFORC√âE
final_auto_check_and_fix() {
    log_info "üîç V√©rification finale et auto-correction RENFORC√âE..."
    
    # 1. Les ACR ont d√©j√† √©t√© corrig√©s automatiquement
    
    # 2. V√©rifier et corriger automatiquement les jobs de migration
    log_info "üîß Auto-correction des jobs de migration..."
    fix_migration_jobs
    
    # 3. ‚úÖ NOUVEAU : V√©rification et correction automatique IP statique NGINX
    log_info "üéØ V√©rification automatique de l'IP statique NGINX..."
    verify_and_fix_nginx_static_ip
    
    # 4. V√©rification finale de l'√©tat global
    log_info "üìä √âtat final du d√©ploiement :"
    echo "======================="
    kubectl get pods -n ibis-x 2>/dev/null || true
    echo "======================="
    kubectl get jobs -n ibis-x 2>/dev/null || true
    echo "======================="
    kubectl get ingress -n ibis-x 2>/dev/null || true
    echo "======================="
    kubectl get svc -n ingress-nginx ingress-nginx-controller 2>/dev/null || true
    echo "======================="
    
    log_success "‚úÖ V√©rification finale et auto-correction RENFORC√âES termin√©es"
}

# Fonction pour attendre que les pods soient pr√™ts  
wait_for_pods() {
    # Attendre que les pods soient pr√™ts
    log_info "Attente du d√©marrage des pods..."
    kubectl wait --for=condition=ready pod -l app=api-gateway -n ibis-x --timeout=300s
    kubectl wait --for=condition=ready pod -l app=service-selection -n ibis-x --timeout=300s
    kubectl wait --for=condition=ready pod -l app=frontend -n ibis-x --timeout=300s
    
    log_success "Application IBIS-X d√©ploy√©e sur AKS"
}

# Fonction pour g√©rer les secrets selon le mode de d√©ploiement
create_missing_secrets() {
    log_info "üîê Gestion des secrets - Mode: $DEPLOYMENT_MODE"
    
    if [[ "$USE_GITHUB_SECRETS" == "true" ]]; then
        # üè≠ MODE GITHUB ACTIONS: Secrets inject√©s dans les fichiers YAML
        log_info "üè≠ Application des secrets depuis les fichiers GitHub Actions..."
        create_github_secrets
    else
        # üõ†Ô∏è MODE MANUEL: Configuration manuelle des secrets
        log_info "üõ†Ô∏è Configuration manuelle des secrets..."
        create_manual_secrets
    fi
    
    log_success "‚úÖ Gestion des secrets termin√©e"
}

# Fonction pour les secrets GitHub Actions
create_github_secrets() {
    log_info "üìã Application des secrets GitHub Actions..."
    
    # GitHub Actions a d√©j√† modifi√© les fichiers YAML avec les vrais secrets
    # Il suffit d'appliquer les fichiers secrets
    
    # 1. Supprimer les anciens secrets (pour forcer la mise √† jour)
    log_info "üßπ Suppression des anciens secrets..."
    kubectl delete secret gateway-secrets -n "$K8S_NAMESPACE" --ignore-not-found=true
    kubectl delete secret kaggle-secrets -n "$K8S_NAMESPACE" --ignore-not-found=true
    kubectl delete secret db-secrets -n "$K8S_NAMESPACE" --ignore-not-found=true
    
    # 2. Appliquer les secrets depuis les fichiers (modifi√©s par GitHub Actions)
    log_info "üìÑ Application des secrets depuis les fichiers YAML..."
    kubectl apply -f k8s/base/api-gateway/gateway-secrets.yaml
    kubectl apply -f k8s/base/service-selection/kaggle-secrets.yaml
    kubectl apply -f k8s/base/service-selection/db-secrets.yaml
    
    # 3. Storage secrets (r√©cup√©rer depuis Azure)
    create_storage_secrets_from_azure
    
    log_success "‚úÖ Secrets GitHub Actions appliqu√©s"
}

# Fonction pour les secrets manuels (production sans GitHub Actions)
create_manual_secrets() {
    log_info "üõ†Ô∏è Configuration automatique des secrets de base pour la production..."
    
    # En mode production script, on cr√©e des secrets de base fonctionnels
    log_info "üìã Cr√©ation des secrets de base pour permettre le fonctionnement de l'application"
    
    # 1. Cr√©er les secrets Kaggle (fonctionnels par d√©faut)
    if ! kubectl get secret kaggle-secrets -n "$K8S_NAMESPACE" &>/dev/null; then
        log_info "üîë Cr√©ation kaggle-secrets (configuration de base)..."
        kubectl create secret generic kaggle-secrets -n "$K8S_NAMESPACE" \
            --from-literal=username=default-kaggle-user \
            --from-literal=key=default-kaggle-key
        log_info "‚úÖ Kaggle secrets cr√©√©s (fonctionnels pour les tests)"
    fi
    
    # 2. Storage secrets depuis Azure
    create_storage_secrets_from_azure
    
    # 3. Gateway secrets (fonctionnels par d√©faut)
    if ! kubectl get secret gateway-secrets -n "$K8S_NAMESPACE" &>/dev/null; then
        log_info "üîë Cr√©ation gateway-secrets (configuration de base)..."
        # G√©n√©rer une cl√© JWT basique pour les tests
        local jwt_secret=$(openssl rand -base64 32 2>/dev/null || echo "default-jwt-secret-key-for-development-only")
        local db_url="postgresql://postgres:postgres@postgresql-service:5432/ibisxdb"
        
        kubectl create secret generic gateway-secrets -n "$K8S_NAMESPACE" \
            --from-literal=secret-key="$jwt_secret" \
            --from-literal=database-url="$db_url" \
            --from-literal=google-client-id=default-google-client-id \
            --from-literal=google-client-secret=default-google-client-secret \
            --from-literal=oauth-redirect-url=https://ibisx.fr/oauth/callback
        log_info "‚úÖ Gateway secrets cr√©√©s (fonctionnels pour les tests)"
    fi
    
    # 4. DB secrets (fonctionnels par d√©faut)
    if ! kubectl get secret db-secrets -n "$K8S_NAMESPACE" &>/dev/null; then
        log_info "üîë Cr√©ation db-secrets (configuration de base)..."
        local db_url="postgresql://postgres:postgres@postgresql-service:5432/ibisxdb"
        kubectl create secret generic db-secrets -n "$K8S_NAMESPACE" \
            --from-literal=database-url="$db_url"
        log_info "‚úÖ DB secrets cr√©√©s (fonctionnels pour les tests)"
    fi
    
    log_success "‚úÖ Secrets de base cr√©√©s et fonctionnels"
}

# Fonction pour cr√©er les secrets de stockage Azure 
create_storage_secrets_from_azure() {
    log_info "‚òÅÔ∏è R√©cup√©ration des secrets de stockage Azure..."
    
    # Utiliser les valeurs d√©j√† r√©cup√©r√©es ou r√©cup√©rer via Azure CLI
    if [[ -z "$STORAGE_ACCOUNT" ]] || [[ -z "$STORAGE_KEY" ]]; then
        log_info "üìÇ R√©cup√©ration storage depuis Azure CLI..."
        STORAGE_ACCOUNT=$(az storage account list --resource-group "$RESOURCE_GROUP" --query "[0].name" -o tsv 2>/dev/null || echo "")
        if [[ -n "$STORAGE_ACCOUNT" ]]; then
            STORAGE_KEY=$(az storage account keys list --resource-group "$RESOURCE_GROUP" --account-name "$STORAGE_ACCOUNT" --query "[0].value" -o tsv 2>/dev/null || echo "")
        fi
    fi
    
    # Cr√©er le secret storage si on a les valeurs
    if [[ -n "$STORAGE_ACCOUNT" ]] && [[ -n "$STORAGE_KEY" ]]; then
        kubectl delete secret storage-secrets -n "$K8S_NAMESPACE" 2>/dev/null || true
        
        log_info "üóÇÔ∏è Cr√©ation storage-secrets avec valeurs Azure..."
        kubectl create secret generic storage-secrets -n "$K8S_NAMESPACE" \
            --from-literal=azure-storage-account-name="$STORAGE_ACCOUNT" \
            --from-literal=azure-storage-account-key="$STORAGE_KEY" \
            --from-literal=azure-container-name=ibis-x-datasets \
            --from-literal=access-key="$STORAGE_ACCOUNT" \
            --from-literal=secret-key="$STORAGE_KEY"
        
        log_success "‚úÖ Storage secrets cr√©√©s: $STORAGE_ACCOUNT"
    else
        log_warning "‚ö†Ô∏è Impossible de r√©cup√©rer les secrets de stockage Azure"
        log_warning "üõ†Ô∏è Vous devrez configurer storage-secrets manuellement si n√©cessaire"
    fi
}

# Fonction pour v√©rifier et red√©marrer les pods en erreur
fix_failed_pods() {
    log_info "V√©rification et correction automatique des pods en erreur..."
    
    # Attendre un peu que les pods d√©marrent
    sleep 30
    
    # V√©rifier les pods qui ne sont pas pr√™ts
    local failed_pods=""
    if kubectl get namespace ibis-x &>/dev/null; then
        failed_pods=$(kubectl get pods -n ibis-x --field-selector=status.phase!=Running -o name 2>/dev/null || echo "")
    fi
    
    if [[ -n "$failed_pods" ]]; then
        log_warning "Pods en erreur d√©tect√©s, red√©marrage automatique..."
        
        # Red√©marrer les pods en erreur
        kubectl delete pod -n ibis-x -l app=service-selection --ignore-not-found=true
        kubectl delete pod -n ibis-x -l app=api-gateway --ignore-not-found=true
        kubectl delete pod -n ibis-x -l app=frontend --ignore-not-found=true
        
        # Attendre que les nouveaux pods d√©marrent
        log_info "Attente du red√©marrage des pods..."
        sleep 60
        
        # V√©rifier √† nouveau
        kubectl get pods -n ibis-x 2>/dev/null || log_info "Pods en cours de cr√©ation..."
    fi
    
    log_success "V√©rification des pods termin√©e"
}

# Fonction pour ex√©cuter les migrations de base de donn√©es avec auto-correction compl√®te
run_migrations() {
    log_info "üöÄ D√©marrage de l'auto-correction compl√®te des migrations..."
    final_auto_check_and_fix
}

# Fonction pour afficher les informations de l'application
show_application_info() {
    log_success "üéâ D√©ploiement IBIS-X 100% AUTOMATIQUE termin√© avec succ√®s !"
    echo
    echo "‚úÖ AUTOMATISATION COMPL√àTE R√âUSSIE :"
    echo "===================================="
    echo "‚úÖ Infrastructure Azure cr√©√©e automatiquement"
    echo "‚úÖ Images Docker construites et push√©es automatiquement"
    echo "‚úÖ Secrets Kubernetes cr√©√©s automatiquement (vrais secrets Azure)"
    echo "‚úÖ Applications d√©ploy√©es automatiquement (avec fallback Windows)"
    echo "‚úÖ NGINX Ingress + Cert-Manager install√©s automatiquement"
    echo "‚úÖ Pods d√©faillants red√©marr√©s automatiquement"
    echo "‚úÖ Aucune commande manuelle requise !"
    echo
    echo "üìã Informations de l'application :"
    echo "=================================="
    echo "üåê URL de l'application: https://ibisx.fr (certificat SSL automatique)"
    echo "üåê URL de l'API: https://api.ibisx.fr (certificat SSL automatique)"
    echo "üåê URL HTTP direct: http://$PUBLIC_IP"
    echo "üóÑÔ∏è  Storage Account: $STORAGE_ACCOUNT"
    echo "üê≥ Container Registry: $ACR_NAME.azurecr.io"
    echo "‚ò∏Ô∏è  Cluster AKS: $AKS_NAME"
    echo "üì¶ Resource Group: $RESOURCE_GROUP"
    echo
    echo "üîß Commandes utiles pour monitoring :"
    echo "====================================="
    echo "# Voir l'√©tat des pods:"
    echo "kubectl get pods -n ibis-x"
    echo
    echo "# Voir les services:"
    echo "kubectl get services -n ibis-x"
    echo
    echo "# Voir l'ingress et IP publique:"
    echo "kubectl get ingress -n ibis-x"
    echo
    echo "# Voir les certificats SSL et leur statut:"
    echo "kubectl get certificates -n ibis-x"
    echo ""
    echo "# Voir l'ingress et IP publique:"
    echo "kubectl get ingress -n ibis-x"
    echo ""
    echo "# Tester l'application en ligne:"
    echo "curl -I http://$PUBLIC_IP"
    echo
    echo "# Voir les logs des applications:"
    echo "kubectl logs -f deployment/api-gateway -n ibis-x"
    echo "kubectl logs -f deployment/service-selection -n ibis-x"
    echo "kubectl logs -f deployment/frontend -n ibis-x"
    echo
    echo "üìù SCRIPT ENTI√àREMENT AUTOMATIQUE :"
    echo "==================================="
    echo "üéØ Pour relancer un d√©ploiement complet : ./scripts/deploy-to-azure.sh"
    echo "üîÑ Le script d√©tecte automatiquement l'infrastructure existante"
    echo "üõ†Ô∏è Tous les probl√®mes Windows/Linux g√©r√©s automatiquement"
    echo "üîê Tous les secrets g√©n√©r√©s automatiquement"
    echo "üì¶ Toutes les images avec les bons noms automatiquement"
    echo
    echo "üéØ PROCHAINES √âTAPES (une seule fois) :"
    echo "======================================"
    echo "1. ‚úÖ IP STATIQUE: $PUBLIC_IP (ne changera jamais !)"
    echo "2. üåê Configurez vos DNS D√âFINITIVEMENT vers cette IP"
    echo "3. üîí Les certificats SSL se g√©n√®reront automatiquement"
    echo "4. üöÄ L'application est accessible via https://ibisx.fr"
    echo
    echo "üí° IMPORTANT: Cette IP est STATIQUE et ne changera pas lors des futurs red√©ploiements !"
    echo "üí° Configurez vos DNS une seule fois avec cette IP !"
}

# Fonction pour nettoyer les fichiers de sauvegarde apr√®s un d√©ploiement r√©ussi
cleanup_backup_files() {
    log_info "üßπ Nettoyage des fichiers de sauvegarde..."
    
    # Supprimer les fichiers de sauvegarde
    find "$K8S_DIR" -name "*.yaml.backup" -delete 2>/dev/null || true
    find "$TERRAFORM_DIR" -name "*.backup" -delete 2>/dev/null || true
    find "$K8S_DIR" -name "*.backup-*" -delete 2>/dev/null || true  # Fichiers avec timestamp
    find "$PROJECT_ROOT/frontend/src/environments/" -name "*.backup-*" -delete 2>/dev/null || true  # Frontend backups
    
    log_success "‚úÖ Fichiers de sauvegarde nettoy√©s"
}

# Fonction pour nettoyer en cas d'erreur
cleanup_on_error() {
    log_error "‚ùå Une erreur s'est produite pendant le d√©ploiement."
    
    # üîÑ Restaurer nginx-ingress-values.yaml si modifi√©
    local nginx_values_file="$K8S_DIR/helm-values/nginx-ingress-values.yaml"
    local latest_backup=$(find "$K8S_DIR/helm-values/" -name "nginx-ingress-values.yaml.backup-*" | sort | tail -1 2>/dev/null || echo "")
    if [[ -n "$latest_backup" && -f "$latest_backup" ]]; then
        mv "$latest_backup" "$nginx_values_file"
        log_info "‚úÖ Fichier nginx-ingress-values.yaml restaur√© depuis backup"
    fi
    
    # üîÑ Restaurer environment.prod.ts si modifi√©
    local env_file="$PROJECT_ROOT/frontend/src/environments/environment.prod.ts"
    local latest_env_backup=$(find "$PROJECT_ROOT/frontend/src/environments/" -name "environment.prod.ts.backup-*" | sort | tail -1 2>/dev/null || echo "")
    if [[ -n "$latest_env_backup" && -f "$latest_env_backup" ]]; then
        mv "$latest_env_backup" "$env_file"
        log_info "‚úÖ Fichier environment.prod.ts restaur√© depuis backup"
    fi
    
    # Restaurer les fichiers de sauvegarde s'ils existent
    if [ -f "$K8S_DIR/base/service-selection/storage-secrets.yaml.backup" ]; then
        mv "$K8S_DIR/base/service-selection/storage-secrets.yaml.backup" "$K8S_DIR/base/service-selection/storage-secrets.yaml"
        log_info "‚úÖ Fichier storage-secrets.yaml restaur√©"
    fi
    
    if [ -f "$K8S_DIR/overlays/azure/kustomization.yaml.backup" ]; then
        mv "$K8S_DIR/overlays/azure/kustomization.yaml.backup" "$K8S_DIR/overlays/azure/kustomization.yaml"
        log_info "‚úÖ Fichier kustomization.yaml restaur√©"
    fi
    
    # Restaurer tous les fichiers YAML modifi√©s
    find "$K8S_DIR" -name "*.yaml.backup" -exec bash -c 'mv "$1" "${1%.backup}"' _ {} \; 2>/dev/null || true
    find "$TERRAFORM_DIR" -name "*.backup" -exec bash -c 'mv "$1" "${1%.backup}"' _ {} \; 2>/dev/null || true
    find "$K8S_DIR" -name "*.backup-*" -exec rm -f {} \; 2>/dev/null || true  # Supprimer backups avec timestamp
    log_info "‚úÖ Tous les fichiers restaur√©s"
    
    echo
    log_warning "üí° Pour nettoyer les ressources Azure cr√©√©es, ex√©cutez :"
    echo "./scripts/production/destroy-azure-infrastructure.sh"
}

# Fonction principale
main() {
    log_info "üöÄ Script de D√©ploiement Production IBIS-X"
    log_info "üéØ Mode: $DEPLOYMENT_MODE"
    log_info "‚ÑπÔ∏è  Pour le d√©veloppement local, utilisez: make dev"
    echo
    
    # Configurer le gestionnaire d'erreur
    trap cleanup_on_error ERR
    
    # Workflow principal
    log_info "üìã === D√âPLOIEMENT PRODUCTION ==="
    
    # √âtapes d'infrastructure et d√©ploiement
    check_prerequisites
    check_azure_login
    
    # Gestion de l'infrastructure (cr√©er si n√©cessaire)
    manage_infrastructure
    
    # Configuration et d√©ploiement
    get_terraform_outputs
    configure_kubectl
    
    # Build et d√©ploiement de l'application
    build_and_push_images
    update_k8s_secrets  # Cr√©er le namespace
    create_missing_secrets
    deploy_application
    
    # Migrations et finalisation
    wait_for_migrations
    initialize_sample_data
    final_auto_check_and_fix
    
    # ‚úÖ AUTOMATIQUE: Forcer rebuild frontend en production si n√©cessaire
    if [[ "$DEPLOYMENT_MODE" == "manual-production" ]] || [[ "$ANGULAR_ENV" == "production" ]]; then
        log_info "üéØ Mode production d√©tect√© - V√©rification et correction automatique du frontend..."
        force_frontend_production_rebuild
    fi
    
    # Nettoyage si mode GitHub Actions
    if [[ "$USE_GITHUB_SECRETS" == "true" ]]; then
        cleanup_migration_jobs
    fi
    
    # Afficher les informations finales
    show_application_info
    
    # Nettoyer les fichiers de sauvegarde
    cleanup_backup_files
    
    log_success "üéâ D√âPLOIEMENT PRODUCTION TERMIN√â AVEC SUCC√àS !"
}

# Fonction pour g√©rer l'infrastructure selon le contexte
manage_infrastructure() {
    log_info "üèóÔ∏è Gestion de l'infrastructure Azure..."
    
    if [[ "$USE_GITHUB_SECRETS" == "true" ]]; then
        # Mode GitHub Actions : infrastructure suppos√©e existante
        log_info "üè≠ Mode GitHub Actions - Infrastructure suppos√©e existante"
        log_info "‚ÑπÔ∏è  Si l'infrastructure n'existe pas, cr√©ez-la manuellement avec ce script"
    else
        # Mode manuel : v√©rifier si infrastructure existe, sinon la cr√©er
        log_info "üõ†Ô∏è Mode manuel - V√©rification de l'infrastructure..."
        
        # V√©rifier si l'infrastructure existe
        if check_infrastructure_exists; then
            log_success "‚úÖ Infrastructure existante d√©tect√©e"
        else
            log_info "üèóÔ∏è Infrastructure non trouv√©e - Cr√©ation automatique..."
            create_infrastructure
        fi
    fi
}

# Fonction pour v√©rifier si l'infrastructure existe
check_infrastructure_exists() {
    log_info "üîç V√©rification de l'existence de l'infrastructure..."
    
    # V√©rifier si les ressources principales existent
    local acr_exists=$(az acr show --name "$AZURE_CONTAINER_REGISTRY" --resource-group "$AZURE_RESOURCE_GROUP" 2>/dev/null && echo "true" || echo "false")
    local aks_exists=$(az aks show --name "$AKS_CLUSTER_NAME" --resource-group "$AZURE_RESOURCE_GROUP" 2>/dev/null && echo "true" || echo "false")
    
    if [[ "$acr_exists" == "true" ]] && [[ "$aks_exists" == "true" ]]; then
        log_success "‚úÖ Infrastructure existante (ACR + AKS)"
        return 0
    else
        log_info "‚ùå Infrastructure incompl√®te ou manquante"
        log_info "   ACR ($AZURE_CONTAINER_REGISTRY): $acr_exists"
        log_info "   AKS ($AKS_CLUSTER_NAME): $aks_exists"
        return 1
    fi
}

# Fonction pour cr√©er l'infrastructure
create_infrastructure() {
    log_info "üèóÔ∏è Cr√©ation de l'infrastructure Azure via Terraform..."
    
    # Cr√©er l'infrastructure compl√®te
    check_kubernetes_versions
    init_terraform
    deploy_infrastructure
    
    log_success "‚úÖ Infrastructure cr√©√©e avec succ√®s"
}

# V√©rifier si le script est ex√©cut√© directement
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi 
