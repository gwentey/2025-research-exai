#!/usr/bin/env python3
"""
Script d'initialisation pour ins√©rer le dataset EdNet (Riiid Answer Correctness) 
dans la base de donn√©es normalis√©e.

Ce script peut √™tre ex√©cut√© pour r√©ins√©rer les donn√©es de test √† chaque fois.

Usage:
    cd service-selection
    python scripts/init_ednet_dataset.py

Requirements:
    - Base de donn√©es PostgreSQL accessible
    - Variable d'environnement DATABASE_URL d√©finie
    - Migrations Alembic appliqu√©es
"""

import os
import sys
from datetime import datetime, timezone
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Ajouter les r√©pertoires n√©cessaires au path pour importer nos mod√®les
script_dir = os.path.dirname(os.path.abspath(__file__))
service_dir = os.path.dirname(script_dir)

# D√©tection automatique du contexte (local vs Docker)
if os.path.exists(os.path.join(service_dir, 'app')):
    # Contexte local : service-selection/scripts/
    app_dir = os.path.join(service_dir, 'app')
    sys.path.insert(0, app_dir)
    context = "local"
else:
    # Contexte Docker : /app/scripts/
    # Les modules sont directement dans /app/
    sys.path.insert(0, service_dir)
    context = "docker"

try:
    from models import Base, Dataset, DatasetFile, FileColumn
    from database import DATABASE_URL
except ImportError as e:
    print(f"‚ùå Erreur d'import: {e}")
    print(f"üîç Contexte d√©tect√©: {context}")
    print(f"üìÅ R√©pertoire script: {script_dir}")
    print(f"üìÅ R√©pertoire service: {service_dir}")
    if context == "local":
        print("üí° Assurez-vous d'ex√©cuter ce script depuis le r√©pertoire service-selection/")
        print("   cd service-selection && python scripts/init_ednet_dataset.py")
    else:
        print("üí° Probl√®me d'import dans le conteneur Docker")
        print("   V√©rifiez que les modules sont bien copi√©s dans l'image")
    sys.exit(1)

def init_ednet_dataset():
    """
    Initialise le dataset EdNet avec tous ses fichiers et colonnes.
    
    Supprime les donn√©es existantes et recr√©e tout.
    """
    
    # Configuration de la base de donn√©es
    try:
        database_url = DATABASE_URL
        print(f"üîå Connexion √† la base de donn√©es...")
    except Exception as e:
        print(f"‚ùå Erreur de configuration base de donn√©es: {e}")
        print("üí° V√©rifiez que DATABASE_URL est d√©finie dans l'environnement")
        sys.exit(1)
    
    # Cr√©er l'engine et la session
    engine = create_engine(database_url)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    
    with SessionLocal() as session:
        try:
            print("üóëÔ∏è  Suppression des donn√©es existantes du dataset EdNet...")
            
            # Supprimer le dataset EdNet s'il existe d√©j√† (cascade supprimera fichiers et colonnes)
            existing_dataset = session.query(Dataset).filter(
                Dataset.dataset_name == "EdNet (Riiid Answer Correctness)"
            ).first()
            
            if existing_dataset:
                session.delete(existing_dataset)
                session.commit()
                print("‚úÖ Donn√©es existantes supprim√©es")
            
            print("üìä Cr√©ation du dataset EdNet...")
            
            # === CR√âATION DU DATASET PRINCIPAL ===
            dataset = Dataset(
                # UUID sera g√©n√©r√© automatiquement
                
                # === IDENTIFICATION & INFORMATIONS G√âN√âRALES ===
                dataset_name="EdNet (Riiid Answer Correctness)",
                year=2020,
                objective="Pr√©diction de la r√©ussite aux exercices",
                access="public",
                availability="online_download",
                num_citations=50,
                citation_link="Riiid Answer Correctness Prediction | Kaggle",
                sources="Application Santa de Riiid",
                storage_uri=None,  # Vide pour le moment
                
                # === CARACT√âRISTIQUES TECHNIQUES ===
                instances_number=131000000,
                features_description="User ID, question ID, timestamp, correct, etc.",
                features_number=10,  # Colonnes principales dans train.csv
                domain=["√©ducation"],
                representativity_description="Large (plus de 700 000 √©l√®ves)",
                representativity_level="√©lev√©e",
                sample_balance_description=None,
                sample_balance_level=None,
                split=True,
                missing_values_description=None,
                has_missing_values=False,
                global_missing_percentage=0.0,
                missing_values_handling_method="none",
                temporal_factors=True,
                metadata_provided_with_dataset=True,
                external_documentation_available=True,
                documentation_link=None,
                task=["classification"],
                
                # === CRIT√àRES √âTHIQUES ===
                informed_consent=True,
                transparency=False,
                user_control=False,
                equity_non_discrimination=False,
                security_measures_in_place=True,
                data_quality_documented=True,
                data_errors_description=None,
                anonymization_applied=True,
                record_keeping_policy_exists=True,
                purpose_limitation_respected=True,
                accountability_defined=True
            )
            
            session.add(dataset)
            session.flush()  # Pour obtenir l'ID du dataset
            
            print(f"‚úÖ Dataset cr√©√© avec ID: {dataset.id}")
            
            # === CR√âATION DES FICHIERS ===
            files_data = [
                {
                    "name": "train.csv",
                    "role": "training_data",
                    "format": "csv",
                    "mime_type": "text/csv",
                    "size_bytes": 5000000000,  # ~5GB d'apr√®s description
                    "row_count": 131000000,
                    "description": "Fichier principal d'entra√Ænement contenant les interactions utilisateur-question",
                    "columns": [
                        {"name": "row_id", "type_orig": "int64", "type_interp": "numerical", "desc": "ID code for the row", "pos": 1, "is_pk": True, "is_null": False, "is_pii": False, "examples": ["0", "1", "2"]},
                        {"name": "timestamp", "type_orig": "int64", "type_interp": "temporal", "desc": "Time in milliseconds between user interaction and first event", "pos": 2, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0", "1500", "3200"]},
                        {"name": "user_id", "type_orig": "int32", "type_interp": "categorical", "desc": "ID code for the user", "pos": 3, "is_pk": False, "is_null": False, "is_pii": True, "examples": ["115", "501", "1024"]},
                        {"name": "content_id", "type_orig": "int16", "type_interp": "categorical", "desc": "ID code for the user interaction", "pos": 4, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["25", "128", "256"]},
                        {"name": "content_type_id", "type_orig": "int8", "type_interp": "categorical", "desc": "0 for question, 1 for lecture", "pos": 5, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0", "1"]},
                        {"name": "task_container_id", "type_orig": "int16", "type_interp": "categorical", "desc": "ID for batch of questions or lectures", "pos": 6, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["1", "15", "32"]},
                        {"name": "user_answer", "type_orig": "int8", "type_interp": "categorical", "desc": "User's answer to question (-1 for null)", "pos": 7, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["0", "1", "2", "3", "-1"]},
                        {"name": "answered_correctly", "type_orig": "int8", "type_interp": "categorical", "desc": "Whether user responded correctly (-1 for null)", "pos": 8, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["0", "1", "-1"]},
                        {"name": "prior_question_elapsed_time", "type_orig": "float32", "type_interp": "numerical", "desc": "Average time in ms for previous question bundle", "pos": 9, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["1500.5", "2300.8", "null"]},
                        {"name": "prior_question_had_explanation", "type_orig": "bool", "type_interp": "categorical", "desc": "Whether user saw explanation after previous bundle", "pos": 10, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["true", "false", "null"]}
                    ]
                },
                {
                    "name": "questions.csv",
                    "role": "metadata",
                    "format": "csv",
                    "mime_type": "text/csv",
                    "size_bytes": 10000000,  # Estimation
                    "row_count": 13523,  # Estimation bas√©e sur les IDs de questions
                    "description": "M√©tadonn√©es des questions pos√©es aux utilisateurs",
                    "columns": [
                        {"name": "question_id", "type_orig": "int", "type_interp": "categorical", "desc": "Foreign key for content_id when content_type is question", "pos": 1, "is_pk": True, "is_null": False, "is_pii": False, "examples": ["25", "128", "256"]},
                        {"name": "bundle_id", "type_orig": "int", "type_interp": "categorical", "desc": "Code for which questions are served together", "pos": 2, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["1", "15", "32"]},
                        {"name": "correct_answer", "type_orig": "int", "type_interp": "categorical", "desc": "The correct answer to the question", "pos": 3, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0", "1", "2", "3"]},
                        {"name": "part", "type_orig": "int", "type_interp": "categorical", "desc": "The relevant section of the TOEIC test", "pos": 4, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["1", "2", "3", "4", "5", "6", "7"]},
                        {"name": "tags", "type_orig": "string", "type_interp": "text", "desc": "Detailed tag codes for the question", "pos": 5, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["1 2 3", "4 5", "6"]}
                    ]
                },
                {
                    "name": "lectures.csv",
                    "role": "metadata",
                    "format": "csv",
                    "mime_type": "text/csv",
                    "size_bytes": 1000000,  # Estimation
                    "row_count": 418,  # Estimation bas√©e sur les IDs de lectures
                    "description": "M√©tadonn√©es des cours regard√©s par les utilisateurs",
                    "columns": [
                        {"name": "lecture_id", "type_orig": "int", "type_interp": "categorical", "desc": "Foreign key for content_id when content_type is lecture", "pos": 1, "is_pk": True, "is_null": False, "is_pii": False, "examples": ["1", "15", "32"]},
                        {"name": "part", "type_orig": "int", "type_interp": "categorical", "desc": "Top level category code for the lecture", "pos": 2, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["1", "2", "3", "4", "5", "6", "7"]},
                        {"name": "tag", "type_orig": "string", "type_interp": "text", "desc": "Tag code for the lecture", "pos": 3, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["1", "2", "3"]},
                        {"name": "type_of", "type_orig": "string", "type_interp": "text", "desc": "Brief description of the core purpose of the lecture", "pos": 4, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["solving question", "watching", "concept"]}
                    ]
                },
                {
                    "name": "example_test_rows.csv",
                    "role": "test_sample",
                    "format": "csv",
                    "mime_type": "text/csv",
                    "size_bytes": 1000000,  # Estimation
                    "row_count": 1000,  # √âchantillon
                    "description": "√âchantillon de donn√©es de test pour l'API time-series",
                    "columns": [
                        {"name": "row_id", "type_orig": "int64", "type_interp": "numerical", "desc": "ID code for the row", "pos": 1, "is_pk": True, "is_null": False, "is_pii": False, "examples": ["0", "1", "2"]},
                        {"name": "timestamp", "type_orig": "int64", "type_interp": "temporal", "desc": "Time in milliseconds between user interaction and first event", "pos": 2, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0", "1500", "3200"]},
                        {"name": "user_id", "type_orig": "int32", "type_interp": "categorical", "desc": "ID code for the user", "pos": 3, "is_pk": False, "is_null": False, "is_pii": True, "examples": ["115", "501", "1024"]},
                        {"name": "content_id", "type_orig": "int16", "type_interp": "categorical", "desc": "ID code for the user interaction", "pos": 4, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["25", "128", "256"]},
                        {"name": "content_type_id", "type_orig": "int8", "type_interp": "categorical", "desc": "0 for question, 1 for lecture", "pos": 5, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0", "1"]},
                        {"name": "task_container_id", "type_orig": "int16", "type_interp": "categorical", "desc": "ID for batch of questions or lectures", "pos": 6, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["1", "15", "32"]},
                        {"name": "prior_group_responses", "type_orig": "string", "type_interp": "text", "desc": "User answers from previous group as string list", "pos": 7, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["[0, 1, 2]", "[1, 3]", "null"]},
                        {"name": "prior_group_answers_correct", "type_orig": "string", "type_interp": "text", "desc": "Correct answers from previous group as string list", "pos": 8, "is_pk": False, "is_null": True, "is_pii": False, "examples": ["[1, 0, 1]", "[0, 1]", "null"]}
                    ]
                },
                {
                    "name": "example_sample_submission.csv",
                    "role": "submission_template",
                    "format": "csv",
                    "mime_type": "text/csv",
                    "size_bytes": 971,  # Taille exacte donn√©e
                    "row_count": 100,  # Estimation
                    "description": "Fichier d'exemple pour les soumissions de la comp√©tition",
                    "columns": [
                        {"name": "row_id", "type_orig": "int64", "type_interp": "numerical", "desc": "ID code for the row", "pos": 1, "is_pk": True, "is_null": False, "is_pii": False, "examples": ["0", "1", "2"]},
                        {"name": "answered_correctly", "type_orig": "float", "type_interp": "numerical", "desc": "Predicted probability of correct answer", "pos": 2, "is_pk": False, "is_null": False, "is_pii": False, "examples": ["0.5", "0.7", "0.3"]}
                    ]
                }
            ]
            
            # Cr√©er les fichiers et leurs colonnes
            for file_info in files_data:
                print(f"üìÅ Cr√©ation du fichier: {file_info['name']}")
                
                # Cr√©er le fichier
                dataset_file = DatasetFile(
                    dataset_id=dataset.id,
                    file_name_in_storage=file_info["name"],
                    logical_role=file_info["role"],
                    format=file_info["format"],
                    mime_type=file_info["mime_type"],
                    size_bytes=file_info["size_bytes"],
                    row_count=file_info["row_count"],
                    description=file_info["description"]
                )
                
                session.add(dataset_file)
                session.flush()  # Pour obtenir l'ID du fichier
                
                # Cr√©er les colonnes
                for col_info in file_info["columns"]:
                    file_column = FileColumn(
                        dataset_file_id=dataset_file.id,
                        column_name=col_info["name"],
                        data_type_original=col_info["type_orig"],
                        data_type_interpreted=col_info["type_interp"],
                        description=col_info["desc"],
                        is_primary_key_component=col_info["is_pk"],
                        is_nullable=col_info["is_null"],
                        is_pii=col_info["is_pii"],
                        example_values=col_info["examples"],
                        position=col_info["pos"],
                        stats=None  # Pas de statistiques pour le moment
                    )
                    session.add(file_column)
                
                print(f"  ‚úÖ {len(file_info['columns'])} colonnes cr√©√©es")
            
            # Valider toutes les modifications
            session.commit()
            
            print("\nüéâ Dataset EdNet initialis√© avec succ√®s !")
            print(f"üìä Dataset ID: {dataset.id}")
            print(f"üìÅ {len(files_data)} fichiers cr√©√©s")
            
            total_columns = sum(len(f["columns"]) for f in files_data)
            print(f"üìã {total_columns} colonnes cr√©√©es au total")
            
        except Exception as e:
            session.rollback()
            print(f"‚ùå Erreur lors de l'initialisation: {e}")
            raise
        finally:
            session.close()

def main():
    """Point d'entr√©e principal du script."""
    print("üöÄ Initialisation du dataset EdNet (Riiid Answer Correctness)")
    print("=" * 60)
    
    try:
        init_ednet_dataset()
        print("\n‚úÖ Initialisation termin√©e avec succ√®s !")
        
    except Exception as e:
        print(f"\n‚ùå √âchec de l'initialisation: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 