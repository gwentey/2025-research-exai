from fastapi import FastAPI, Depends, HTTPException, Query, Header
from sqlalchemy.orm import Session
from sqlalchemy import func, or_, and_
from typing import List, Optional
from datetime import datetime
import math
import logging
import uuid
from pydantic import UUID4

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Approche hybride pour g√©rer les imports en local et dans Docker
try:
    # Imports relatifs pour le d√©veloppement local
    from . import models
    from . import database
    from . import schemas
except ImportError:
    # Imports absolus pour le conteneur Docker
    import models
    import database
    import schemas
from fastapi.middleware.cors import CORSMiddleware

# --- Configuration de l'application FastAPI ---

app = FastAPI(
    title="Service de S√©lection de Datasets EXAI",
    description="API pour la gestion des datasets avec m√©tadonn√©es techniques et √©thiques.",
    version="2.0.0"
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # √Ä restreindre en production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Authentification via headers ---

def get_current_user_id(x_user_id: str = Header(..., alias="X-User-ID")) -> UUID4:
    """
    Extrait l'ID de l'utilisateur connect√© depuis les headers envoy√©s par l'API Gateway.
    """
    try:
        user_id = uuid.UUID(x_user_id)
        return user_id
    except ValueError:
        raise HTTPException(
            status_code=401,
            detail="ID utilisateur invalide dans les headers"
        )

# --- Utilitaires pour les requ√™tes ---

def apply_filters(query, filters: schemas.DatasetFilterCriteria):
    """
    Applique les filtres √† une requ√™te SQLAlchemy.
    Version compl√®te supportant tous les filtres du frontend, y compris alias et raccourcis.
    """
    # --- FILTRES TEXTUELS ---
    if filters.dataset_name:
        query = query.filter(models.Dataset.dataset_name.ilike(f"%{filters.dataset_name}%"))
    
    if filters.objective:
        query = query.filter(models.Dataset.objective.ilike(f"%{filters.objective}%"))
    
    # --- FILTRES DE LISTES (domaines et t√¢ches) ---
    if filters.domain:
        query = query.filter(models.Dataset.domain.op("&&")(filters.domain))
    
    if filters.task:
        query = query.filter(models.Dataset.task.op("&&")(filters.task))
    
    # --- FILTRES CAT√âGORIELS ---
    if filters.access:
        query = query.filter(models.Dataset.access == filters.access)
    
    if filters.availability:
        query = query.filter(models.Dataset.availability == filters.availability)
    
    # --- FILTRES NUM√âRIQUES AVEC PLAGES ---
    # Ann√©e
    if filters.year_min:
        query = query.filter(models.Dataset.year >= filters.year_min)
    
    if filters.year_max:
        query = query.filter(models.Dataset.year <= filters.year_max)
    
    # Instances (avec alias frontend)
    instances_min = filters.instances_min or filters.instances_number_min
    instances_max = filters.instances_max or filters.instances_number_max
    
    if instances_min:
        query = query.filter(models.Dataset.instances_number >= instances_min)
    
    if instances_max:
        query = query.filter(models.Dataset.instances_number <= instances_max)
    
    # Features (avec alias frontend)
    features_min = filters.features_min or filters.features_number_min
    features_max = filters.features_max or filters.features_number_max
    
    if features_min:
        query = query.filter(models.Dataset.features_number >= features_min)
    
    if features_max:
        query = query.filter(models.Dataset.features_number <= features_max)
    
    # Citations
    if filters.citations_min:
        query = query.filter(models.Dataset.num_citations >= filters.citations_min)
    
    if filters.citations_max:
        query = query.filter(models.Dataset.num_citations <= filters.citations_max)
    
    # --- FILTRES DE SCORES ---
    if filters.ethical_score_min:
        # Filtre par score √©thique calcul√©
        # Nous devons cr√©er une sous-requ√™te pour calculer le score
        from sqlalchemy import case, cast, Float
        
        # Calculer le score √©thique comme pourcentage
        ethical_criteria = [
            models.Dataset.informed_consent,
            models.Dataset.transparency,
            models.Dataset.user_control,
            models.Dataset.equity_non_discrimination,
            models.Dataset.security_measures_in_place,
            models.Dataset.data_quality_documented,
            models.Dataset.anonymization_applied,
            models.Dataset.record_keeping_policy_exists,
            models.Dataset.purpose_limitation_respected,
            models.Dataset.accountability_defined
        ]
        
        # Somme des crit√®res vrais
        true_count = sum(case([(criterion == True, 1)], else_=0) for criterion in ethical_criteria)
        total_criteria = len(ethical_criteria)
        ethical_score_percent = cast(true_count * 100.0 / total_criteria, Float)
        
        query = query.filter(ethical_score_percent >= filters.ethical_score_min)
    
    # --- FILTRES BOOL√âENS TECHNIQUES ---
    if filters.has_missing_values is not None:
        query = query.filter(models.Dataset.has_missing_values == filters.has_missing_values)
    
    # Split (avec alias) - Filtre SEULEMENT si True
    split_filter = filters.split if filters.split is not None else filters.is_split
    if split_filter is True:
        query = query.filter(models.Dataset.split == True)
    
    if filters.metadata_provided_with_dataset is True:
        query = query.filter(models.Dataset.metadata_provided_with_dataset == True)
    
    if filters.external_documentation_available is True:
        query = query.filter(models.Dataset.external_documentation_available == True)
    
    # Facteurs temporels (avec alias) - Filtre SEULEMENT si True
    temporal_filter = filters.temporal_factors if filters.temporal_factors is not None else filters.has_temporal_factors
    if temporal_filter is True:
        query = query.filter(models.Dataset.temporal_factors == True)
    
    # --- FILTRES DE RACCOURCIS ---
    # Anonymisation (raccourci) - Filtre SEULEMENT si True
    if filters.is_anonymized is True:
        query = query.filter(models.Dataset.anonymization_applied == True)
    
    # Acc√®s public (raccourci) - Filtre SEULEMENT si True
    if filters.is_public is True:
        query = query.filter(models.Dataset.access == 'public')
    
    # --- FILTRES BOOL√âENS √âTHIQUES - Filtre SEULEMENT si True ---
    if filters.informed_consent is True:
        query = query.filter(models.Dataset.informed_consent == True)
    
    if filters.transparency is True:
        query = query.filter(models.Dataset.transparency == True)
    
    if filters.user_control is True:
        query = query.filter(models.Dataset.user_control == True)
    
    if filters.equity_non_discrimination is True:
        query = query.filter(models.Dataset.equity_non_discrimination == True)
    
    if filters.security_measures_in_place is True:
        query = query.filter(models.Dataset.security_measures_in_place == True)
    
    if filters.data_quality_documented is True:
        query = query.filter(models.Dataset.data_quality_documented == True)
    
    if filters.anonymization_applied is True:
        query = query.filter(models.Dataset.anonymization_applied == True)
    
    if filters.record_keeping_policy_exists is True:
        query = query.filter(models.Dataset.record_keeping_policy_exists == True)
    
    if filters.purpose_limitation_respected is True:
        query = query.filter(models.Dataset.purpose_limitation_respected == True)
    
    if filters.accountability_defined is True:
        query = query.filter(models.Dataset.accountability_defined == True)
    
    return query


def apply_sorting(query, sort_by: str, sort_order: str):
    """Applique le tri √† une requ√™te SQLAlchemy."""
    # Mapping des noms de champs pour le tri
    sort_mapping = {
        "dataset_name": models.Dataset.dataset_name,
        "year": models.Dataset.year,
        "instances_number": models.Dataset.instances_number,
        "features_number": models.Dataset.features_number,
        "num_citations": models.Dataset.num_citations,
        "created_at": models.Dataset.created_at,
        "updated_at": models.Dataset.updated_at,
    }
    
    sort_field = sort_mapping.get(sort_by, models.Dataset.dataset_name)
    
    if sort_order.lower() == "desc":
        query = query.order_by(sort_field.desc())
    else:
        query = query.order_by(sort_field.asc())
    
    return query


# --- Routes de l'API ---

@app.get("/")
async def root():
    """Route racine simple pour v√©rifier que l'API est en ligne."""
    return {
        "message": "Bienvenue sur l'API du Service de S√©lection de Datasets EXAI",
        "version": app.version,
        "documentation": ["/docs", "/redoc"]
    }

@app.get("/health")
async def health_check():
    """V√©rification de la sant√© du service."""
    return {"status": "healthy", "service": "service-selection"}

@app.get("/datasets", response_model=schemas.DatasetListResponse)
def list_datasets(
    page: int = Query(1, ge=1, description="Num√©ro de page"),
    page_size: int = Query(12, ge=1, le=100, description="Nombre d'√©l√©ments par page"),
    sort_by: str = Query("dataset_name", description="Champ de tri"),
    sort_order: str = Query("asc", description="Ordre de tri (asc/desc)"),
    # Filtres textuels
    dataset_name: Optional[str] = Query(None, description="Filtrer par nom"),
    objective: Optional[str] = Query(None, description="Filtrer par objectif"),
    # Filtres de listes
    domain: Optional[str] = Query(None, description="Filtrer par domaine (s√©par√©s par virgule)"),
    task: Optional[str] = Query(None, description="Filtrer par t√¢che (s√©par√©s par virgule)"),
    # Filtres cat√©goriels
    access: Optional[str] = Query(None, description="Filtrer par acc√®s"),
    availability: Optional[str] = Query(None, description="Filtrer par disponibilit√©"),
    # Filtres num√©riques avec plages
    year_min: Optional[int] = Query(None, description="Ann√©e minimale"),
    year_max: Optional[int] = Query(None, description="Ann√©e maximale"),
    instances_min: Optional[int] = Query(None, description="Nombre minimum d'instances"),
    instances_max: Optional[int] = Query(None, description="Nombre maximum d'instances"),
    # Alias frontend pour instances
    instances_number_min: Optional[int] = Query(None, description="Nombre minimum d'instances (alias)"),
    instances_number_max: Optional[int] = Query(None, description="Nombre maximum d'instances (alias)"),
    features_min: Optional[int] = Query(None, description="Nombre minimum de features"),
    features_max: Optional[int] = Query(None, description="Nombre maximum de features"),
    # Alias frontend pour features  
    features_number_min: Optional[int] = Query(None, description="Nombre minimum de features (alias)"),
    features_number_max: Optional[int] = Query(None, description="Nombre maximum de features (alias)"),
    citations_min: Optional[int] = Query(None, description="Nombre minimum de citations"),
    citations_max: Optional[int] = Query(None, description="Nombre maximum de citations"),
    # Filtres de scores
    ethical_score_min: Optional[int] = Query(None, ge=0, le=100, description="Score √©thique minimum (0-100%)"),
    # Filtres bool√©ens techniques
    has_missing_values: Optional[bool] = Query(None, description="Pr√©sence de valeurs manquantes"),
    split: Optional[bool] = Query(None, description="Dataset d√©j√† split√©"),
    is_split: Optional[bool] = Query(None, description="Dataset d√©j√† split√© (alias)"),
    metadata_provided_with_dataset: Optional[bool] = Query(None, description="M√©tadonn√©es fournies"),
    external_documentation_available: Optional[bool] = Query(None, description="Documentation externe disponible"),
    temporal_factors: Optional[bool] = Query(None, description="Facteurs temporels"),
    has_temporal_factors: Optional[bool] = Query(None, description="Facteurs temporels (alias)"),
    # Filtres de raccourcis
    is_anonymized: Optional[bool] = Query(None, description="Anonymisation appliqu√©e (raccourci)"),
    is_public: Optional[bool] = Query(None, description="Acc√®s public (raccourci)"),
    # Crit√®res √©thiques
    informed_consent: Optional[bool] = Query(None, description="Consentement √©clair√©"),
    transparency: Optional[bool] = Query(None, description="Transparence"),
    user_control: Optional[bool] = Query(None, description="Contr√¥le utilisateur"),
    equity_non_discrimination: Optional[bool] = Query(None, description="√âquit√© et non-discrimination"),
    security_measures_in_place: Optional[bool] = Query(None, description="Mesures de s√©curit√©"),
    data_quality_documented: Optional[bool] = Query(None, description="Qualit√© document√©e"),
    anonymization_applied: Optional[bool] = Query(None, description="Anonymisation appliqu√©e"),
    record_keeping_policy_exists: Optional[bool] = Query(None, description="Politique de conservation"),
    purpose_limitation_respected: Optional[bool] = Query(None, description="Limitation d'objectif"),
    accountability_defined: Optional[bool] = Query(None, description="Responsabilit√© d√©finie"),
    db: Session = Depends(database.get_db)
):
    """R√©cup√®re une liste pagin√©e et filtr√©e de datasets avec support complet des filtres frontend."""
    # Construire les filtres avec support des alias et raccourcis
    filters = schemas.DatasetFilterCriteria(
        # Filtres textuels
        dataset_name=dataset_name,
        objective=objective,
        # Filtres de listes
        domain=domain.split(",") if domain else None,
        task=task.split(",") if task else None,
        # Filtres cat√©goriels
        access=access,
        availability=availability,
        # Filtres num√©riques avec plages
        year_min=year_min,
        year_max=year_max,
        instances_min=instances_min,
        instances_max=instances_max,
        instances_number_min=instances_number_min,
        instances_number_max=instances_number_max,
        features_min=features_min,
        features_max=features_max,
        features_number_min=features_number_min,
        features_number_max=features_number_max,
        citations_min=citations_min,
        citations_max=citations_max,
        # Filtres de scores
        ethical_score_min=ethical_score_min,
        # Filtres bool√©ens techniques
        has_missing_values=has_missing_values,
        split=split,
        is_split=is_split,
        metadata_provided_with_dataset=metadata_provided_with_dataset,
        external_documentation_available=external_documentation_available,
        temporal_factors=temporal_factors,
        has_temporal_factors=has_temporal_factors,
        # Filtres de raccourcis
        is_anonymized=is_anonymized,
        is_public=is_public,
        # Crit√®res √©thiques
        informed_consent=informed_consent,
        transparency=transparency,
        user_control=user_control,
        equity_non_discrimination=equity_non_discrimination,
        security_measures_in_place=security_measures_in_place,
        data_quality_documented=data_quality_documented,
        anonymization_applied=anonymization_applied,
        record_keeping_policy_exists=record_keeping_policy_exists,
        purpose_limitation_respected=purpose_limitation_respected,
        accountability_defined=accountability_defined,
    )
    
    # Construire la requ√™te de base
    query = db.query(models.Dataset)
    
    # Appliquer les filtres
    query = apply_filters(query, filters)
    
    # Compter le total
    total_count = query.count()
    
    # Appliquer le tri
    query = apply_sorting(query, sort_by, sort_order)
    
    # Appliquer la pagination
    offset = (page - 1) * page_size
    datasets = query.offset(offset).limit(page_size).all()
    
    # Calculer le nombre total de pages
    total_pages = math.ceil(total_count / page_size)
    
    return schemas.DatasetListResponse(
        datasets=datasets,
        total_count=total_count,
        page=page,
        page_size=page_size,
        total_pages=total_pages
    )

# Routes sp√©cifiques AVANT la route g√©n√©rique pour √©viter les conflits
@app.get("/datasets/domains", response_model=schemas.DomainResponse)
def get_domains(db: Session = Depends(database.get_db)):
    """R√©cup√®re la liste unique de tous les domaines d'application."""
    # R√©cup√©rer tous les domaines non-null
    domains_query = db.query(models.Dataset.domain).filter(models.Dataset.domain.isnot(None))
    
    # Extraire et aplatir la liste des domaines
    all_domains = set()
    for row in domains_query.all():
        if row.domain:
            all_domains.update(row.domain)
    
    # Trier les domaines
    sorted_domains = sorted(list(all_domains))
    
    return schemas.DomainResponse(domains=sorted_domains)

@app.get("/datasets/tasks", response_model=schemas.TaskResponse)
def get_tasks(db: Session = Depends(database.get_db)):
    """R√©cup√®re la liste unique de toutes les t√¢ches ML."""
    # R√©cup√©rer toutes les t√¢ches non-null
    tasks_query = db.query(models.Dataset.task).filter(models.Dataset.task.isnot(None))
    
    # Extraire et aplatir la liste des t√¢ches
    all_tasks = set()
    for row in tasks_query.all():
        if row.task:
            all_tasks.update(row.task)
    
    # Trier les t√¢ches
    sorted_tasks = sorted(list(all_tasks))
    
    return schemas.TaskResponse(tasks=sorted_tasks)

# Route g√©n√©rique APR√àS les routes sp√©cifiques
@app.get("/datasets/{dataset_id}", response_model=schemas.DatasetRead)
def get_dataset(dataset_id: str, db: Session = Depends(database.get_db)):
    """R√©cup√®re les d√©tails d'un dataset sp√©cifique par son ID."""
    dataset = db.query(models.Dataset).filter(models.Dataset.id == dataset_id).first()
    if dataset is None:
        raise HTTPException(status_code=404, detail=f"Dataset avec l'ID {dataset_id} non trouv√©")
    return dataset

@app.post("/datasets", response_model=schemas.DatasetRead, status_code=201)
def create_dataset(dataset: schemas.DatasetCreate, db: Session = Depends(database.get_db)):
    """Cr√©e un nouvel enregistrement de dataset dans la base de donn√©es."""
    # Cr√©er une instance du mod√®le SQLAlchemy
    db_dataset = models.Dataset(**dataset.dict())
    
    # Ajouter √† la session et sauvegarder
    db.add(db_dataset)
    db.commit()
    db.refresh(db_dataset)
    
    return db_dataset

@app.put("/datasets/{dataset_id}", response_model=schemas.DatasetRead)
def update_dataset(
    dataset_id: str,
    dataset_update: schemas.DatasetUpdate,
    db: Session = Depends(database.get_db)
):
    """Met √† jour les informations d'un dataset existant."""
    db_dataset = db.query(models.Dataset).filter(models.Dataset.id == dataset_id).first()
    if db_dataset is None:
        raise HTTPException(status_code=404, detail=f"Dataset avec l'ID {dataset_id} non trouv√©")
    
    # Mettre √† jour les champs
    update_data = dataset_update.dict(exclude_unset=True)
    for key, value in update_data.items():
        setattr(db_dataset, key, value)
    
    db.commit()
    db.refresh(db_dataset)
    
    return db_dataset

@app.delete("/datasets/{dataset_id}", status_code=200)
def delete_dataset(dataset_id: str, db: Session = Depends(database.get_db)):
    """Supprime un dataset de la base de donn√©es par son ID."""
    db_dataset = db.query(models.Dataset).filter(models.Dataset.id == dataset_id).first()
    if db_dataset is None:
        raise HTTPException(status_code=404, detail=f"Dataset avec l'ID {dataset_id} non trouv√©")
    
    db.delete(db_dataset)
    db.commit()
    
    return {"message": f"Dataset avec l'ID {dataset_id} supprim√© avec succ√®s"}


# --- FONCTIONS UTILITAIRES POUR LE SCORING ---

def calculate_ethical_score(dataset: models.Dataset) -> float:
    """
    Calcule le score √©thique d'un dataset bas√© sur les crit√®res √©thiques.
    
    Args:
        dataset: L'instance du dataset
    
    Returns:
        float: Score √©thique entre 0.0 et 1.0
    """
    ethical_criteria = [
        dataset.informed_consent,
        dataset.transparency,
        dataset.user_control,
        dataset.equity_non_discrimination,
        dataset.security_measures_in_place,
        dataset.data_quality_documented,
        dataset.anonymization_applied,
        dataset.record_keeping_policy_exists,
        dataset.purpose_limitation_respected,
        dataset.accountability_defined
    ]
    
    # Compte les crit√®res respect√©s (True)
    positive_count = sum(1 for criterion in ethical_criteria if criterion is True)
    total_criteria = len(ethical_criteria)
    
    return positive_count / total_criteria if total_criteria > 0 else 0.0


def calculate_technical_score(dataset: models.Dataset) -> float:
    """
    Calcule le score technique d'un dataset bas√© sur les caract√©ristiques techniques.
    
    Args:
        dataset: L'instance du dataset
    
    Returns:
        float: Score technique entre 0.0 et 1.0
    """
    score = 0.0
    max_score = 0.0
    
    # Documentation (poids: 0.3)
    if dataset.metadata_provided_with_dataset is not None:
        max_score += 0.15
        if dataset.metadata_provided_with_dataset:
            score += 0.15
    
    if dataset.external_documentation_available is not None:
        max_score += 0.15
        if dataset.external_documentation_available:
            score += 0.15
    
    # Qualit√© des donn√©es (poids: 0.4)
    if dataset.has_missing_values is not None:
        max_score += 0.2
        # Moins de valeurs manquantes = meilleur score
        if not dataset.has_missing_values:
            score += 0.2
        elif dataset.global_missing_percentage is not None:
            # Score d√©gressif selon le pourcentage de valeurs manquantes
            missing_score = max(0, (100 - dataset.global_missing_percentage) / 100)
            score += 0.2 * missing_score
    
    if dataset.split is not None:
        max_score += 0.2
        if dataset.split:
            score += 0.2
    
    # Taille et richesse (poids: 0.3)
    if dataset.instances_number is not None:
        max_score += 0.15
        # Score logarithmique pour le nombre d'instances
        if dataset.instances_number > 0:
            # Score max pour 100k+ instances, score min pour <100 instances
            log_instances = math.log10(max(1, dataset.instances_number))
            normalized_score = min(1.0, max(0.0, (log_instances - 2) / 3))  # log10(100) = 2, log10(100000) = 5
            score += 0.15 * normalized_score
    
    if dataset.features_number is not None:
        max_score += 0.15
        if dataset.features_number > 0:
            # Score optimal entre 10 et 100 features
            if 10 <= dataset.features_number <= 100:
                score += 0.15
            elif dataset.features_number > 100:
                # Score d√©gressif pour trop de features
                excess_score = max(0.5, 1 - (dataset.features_number - 100) / 1000)
                score += 0.15 * excess_score
            else:
                # Score progressif pour peu de features
                score += 0.15 * (dataset.features_number / 10)
    
    return score / max_score if max_score > 0 else 0.0


def calculate_popularity_score(dataset: models.Dataset) -> float:
    """
    Calcule le score de popularit√© d'un dataset bas√© sur les citations.
    
    Args:
        dataset: L'instance du dataset
    
    Returns:
        float: Score de popularit√© entre 0.0 et 1.0
    """
    if dataset.num_citations is None or dataset.num_citations <= 0:
        return 0.0
    
    # Score logarithmique pour les citations
    # Score max pour 1000+ citations, score min pour 1 citation
    log_citations = math.log10(dataset.num_citations)
    normalized_score = min(1.0, max(0.0, log_citations / 3))  # log10(1000) = 3
    
    return normalized_score


def calculate_relevance_score(dataset: models.Dataset, weights: List[schemas.CriterionWeight]) -> float:
    """
    Calcule le score de pertinence d'un dataset selon les crit√®res pond√©r√©s.
    
    Args:
        dataset: L'instance du dataset
        weights: Liste des crit√®res et leurs poids
    
    Returns:
        float: Score de pertinence entre 0.0 et 1.0
    """
    import logging
    logger = logging.getLogger(__name__)
    
    total_score = 0.0
    total_weight = 0.0
    
    # DEBUG: Log du d√©but du calcul
    logger.info(f"üìä Calcul score pour '{dataset.dataset_name}' avec {len(weights)} crit√®res")
    
    # Dictionnaire des fonctions de calcul disponibles
    score_calculators = {
        'ethical_score': lambda: calculate_ethical_score(dataset),
        'technical_score': lambda: calculate_technical_score(dataset),
        'popularity_score': lambda: calculate_popularity_score(dataset),
        'anonymization': lambda: 1.0 if dataset.anonymization_applied else 0.0,
        'transparency': lambda: 1.0 if dataset.transparency else 0.0,
        'informed_consent': lambda: 1.0 if dataset.informed_consent else 0.0,
        'documentation': lambda: 1.0 if dataset.metadata_provided_with_dataset or dataset.external_documentation_available else 0.0,
        'data_quality': lambda: 1.0 if not dataset.has_missing_values else (
            (100 - (dataset.global_missing_percentage or 0)) / 100 if dataset.global_missing_percentage is not None else 0.5
        ),
        'instances_count': lambda: min(1.0, math.log10(max(1, dataset.instances_number or 1)) / 5) if dataset.instances_number else 0.0,
        'features_count': lambda: min(1.0, (dataset.features_number or 0) / 100) if dataset.features_number else 0.0,
        'citations': lambda: calculate_popularity_score(dataset),
        'year': lambda: min(1.0, max(0.0, ((dataset.year or 2000) - 2000) / 24)) if dataset.year else 0.0,  # Score bas√© sur la nouveaut√© (2000-2024)
    }
    
    for weight_item in weights:
        criterion_name = weight_item.criterion_name
        weight = weight_item.weight
        
        if criterion_name in score_calculators:
            criterion_score = score_calculators[criterion_name]()
            total_score += criterion_score * weight
            total_weight += weight
            logger.info(f"   {criterion_name}: {criterion_score:.3f} (poids: {weight:.1f}) = {criterion_score * weight:.3f}")
        else:
            logger.warning(f"   ‚ö†Ô∏è Crit√®re inconnu: {criterion_name}")
    
    # Si aucun poids n'est fourni, utiliser des poids par d√©faut √©quilibr√©s
    if total_weight == 0.0:
        logger.info("   Aucun poids valide, utilisation des poids par d√©faut")
        default_weights = [
            schemas.CriterionWeight(criterion_name='ethical_score', weight=0.4),
            schemas.CriterionWeight(criterion_name='technical_score', weight=0.4),
            schemas.CriterionWeight(criterion_name='popularity_score', weight=0.2),
        ]
        return calculate_relevance_score(dataset, default_weights)
    
    final_score = total_score / total_weight
    logger.info(f"   Score final: {total_score:.3f} / {total_weight:.1f} = {final_score:.3f}")
    
    return final_score


def calculate_criterion_scores(dataset: models.Dataset) -> dict:
    """
    Calcule les scores d√©taill√©s par crit√®re pour un dataset.
    Utilis√© pour la visualisation heatmap dans l'interface utilisateur.
    
    Args:
        dataset: L'instance du dataset
    
    Returns:
        dict: Dictionnaire avec les scores par crit√®re
    """
    return {
        'ethical_score': calculate_ethical_score(dataset),
        'technical_score': calculate_technical_score(dataset),
        'popularity_score': calculate_popularity_score(dataset),
        'anonymization': 1.0 if dataset.anonymization_applied else 0.0,
        'transparency': 1.0 if dataset.transparency else 0.0,
        'informed_consent': 1.0 if dataset.informed_consent else 0.0,
        'documentation': 1.0 if dataset.metadata_provided_with_dataset or dataset.external_documentation_available else 0.0,
        'data_quality': 1.0 if not dataset.has_missing_values else (
            (100 - (dataset.global_missing_percentage or 0)) / 100 if dataset.global_missing_percentage is not None else 0.5
        ),
        'instances_count': min(1.0, math.log10(max(1, dataset.instances_number or 1)) / 5) if dataset.instances_number else 0.0,
        'features_count': min(1.0, (dataset.features_number or 0) / 100) if dataset.features_number else 0.0,
        'citations': calculate_popularity_score(dataset),
        'year': min(1.0, max(0.0, ((dataset.year or 2000) - 2000) / 24)) if dataset.year else 0.0,
    }


# === ENDPOINTS POUR LES PROJETS ===

@app.get("/projects", response_model=schemas.ProjectListResponse)
def list_projects(
    page: int = Query(1, ge=1, description="Num√©ro de page"),
    page_size: int = Query(12, ge=1, le=100, description="Nombre d'√©l√©ments par page"),
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Liste les projets de l'utilisateur connect√© avec pagination.
    S√âCURIS√â : Filtre automatiquement par user_id.
    """
    offset = (page - 1) * page_size
    
    # S√âCURIT√â : Filtrer OBLIGATOIREMENT par user_id de l'utilisateur connect√©
    query = db.query(models.Project).filter(models.Project.user_id == current_user_id)
    total_count = query.count()
    projects = query.offset(offset).limit(page_size).all()
    
    total_pages = math.ceil(total_count / page_size)
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Liste de {len(projects)} projets sur {total_count}")
    
    return schemas.ProjectListResponse(
        projects=projects,
        total_count=total_count,
        page=page,
        page_size=page_size,
        total_pages=total_pages
    )


@app.post("/projects", response_model=schemas.ProjectRead, status_code=201)
def create_project(
    project: schemas.ProjectCreate,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Cr√©er un nouveau projet pour l'utilisateur connect√©.
    S√âCURIS√â : Associe automatiquement le projet √† l'utilisateur connect√©.
    """
    # Convertir les crit√®res et poids en JSON pour stockage JSONB
    criteria_dict = project.criteria.dict() if project.criteria else None
    weights_dict = [weight.dict() for weight in project.weights] if project.weights else None
    
    # S√âCURIT√â : Utiliser OBLIGATOIREMENT l'user_id de l'utilisateur connect√©
    db_project = models.Project(
        user_id=current_user_id,
        name=project.name,
        description=project.description,
        criteria=criteria_dict,
        weights=weights_dict
    )
    
    db.add(db_project)
    db.commit()
    db.refresh(db_project)
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Nouveau projet cr√©√©: {db_project.id} '{project.name}'")
    
    return db_project


@app.get("/projects/{project_id}", response_model=schemas.ProjectRead)
def get_project(
    project_id: str,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    R√©cup√©rer un projet sp√©cifique appartenant √† l'utilisateur connect√©.
    S√âCURIS√â : V√©rifie l'appartenance du projet √† l'utilisateur.
    """
    # S√âCURIT√â : Filtrer par projet ET user_id pour emp√™cher l'acc√®s √† d'autres projets
    project = db.query(models.Project).filter(
        models.Project.id == project_id,
        models.Project.user_id == current_user_id
    ).first()
    
    if not project:
        # Ne pas r√©v√©ler si le projet existe ou non pour un autre utilisateur
        raise HTTPException(status_code=404, detail="Projet non trouv√©")
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Acc√®s au projet: {project_id}")
    
    return project


@app.put("/projects/{project_id}", response_model=schemas.ProjectRead)
def update_project(
    project_id: str,
    project_update: schemas.ProjectUpdate,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Mettre √† jour un projet appartenant √† l'utilisateur connect√©.
    S√âCURIS√â : V√©rifie l'appartenance du projet √† l'utilisateur.
    """
    # S√âCURIT√â : Filtrer par projet ET user_id pour emp√™cher la modification d'autres projets
    project = db.query(models.Project).filter(
        models.Project.id == project_id,
        models.Project.user_id == current_user_id
    ).first()
    
    if not project:
        # Ne pas r√©v√©ler si le projet existe ou non pour un autre utilisateur
        raise HTTPException(status_code=404, detail="Projet non trouv√©")
    
    # Mettre √† jour les champs modifi√©s
    update_data = project_update.dict(exclude_unset=True)
    
    # Convertir les crit√®res et poids en JSON si fournis
    if 'criteria' in update_data and update_data['criteria']:
        update_data['criteria'] = update_data['criteria'].dict()
    
    if 'weights' in update_data and update_data['weights']:
        update_data['weights'] = [weight.dict() for weight in update_data['weights']]
    
    for field, value in update_data.items():
        setattr(project, field, value)
    
    project.updated_at = datetime.utcnow()
    
    db.commit()
    db.refresh(project)
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Projet mis √† jour: {project_id} '{project.name}'")
    
    return project


@app.delete("/projects/{project_id}", status_code=200)
def delete_project(
    project_id: str,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Supprimer un projet appartenant √† l'utilisateur connect√©.
    S√âCURIS√â : V√©rifie l'appartenance du projet √† l'utilisateur.
    """
    # S√âCURIT√â : Filtrer par projet ET user_id pour emp√™cher la suppression d'autres projets
    project = db.query(models.Project).filter(
        models.Project.id == project_id,
        models.Project.user_id == current_user_id
    ).first()
    
    if not project:
        # Ne pas r√©v√©ler si le projet existe ou non pour un autre utilisateur
        raise HTTPException(status_code=404, detail="Projet non trouv√©")
    
    project_name = project.name  # Sauvegarder pour le log
    
    db.delete(project)
    db.commit()
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Projet supprim√©: {project_id} '{project_name}'")
    
    return {"message": "Projet supprim√© avec succ√®s"}


@app.get("/projects/{project_id}/recommendations", response_model=schemas.ProjectRecommendationResponse)
def get_project_recommendations(
    project_id: str,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Obtenir les datasets recommand√©s pour un projet appartenant √† l'utilisateur connect√©.
    S√âCURIS√â : V√©rifie l'appartenance du projet √† l'utilisateur.
    """
    # S√âCURIT√â : Filtrer par projet ET user_id pour emp√™cher l'acc√®s aux recommandations d'autres projets
    project = db.query(models.Project).filter(
        models.Project.id == project_id,
        models.Project.user_id == current_user_id
    ).first()
    
    if not project:
        # Ne pas r√©v√©ler si le projet existe ou non pour un autre utilisateur
        raise HTTPException(status_code=404, detail="Projet non trouv√©")
    
    # 1. Construire la requ√™te de base
    query = db.query(models.Dataset)
    
    # 2. Appliquer les filtres du projet si d√©finis
    if project.criteria:
        # Convertir le dict JSON en objet DatasetFilterCriteria
        criteria = schemas.DatasetFilterCriteria(**project.criteria)
        query = apply_filters(query, criteria)
    
    # 3. R√©cup√©rer les datasets filtr√©s
    datasets = query.all()
    
    # 4. Pr√©parer les poids pour le scoring
    weights = []
    if project.weights:
        weights = [schemas.CriterionWeight(**weight) for weight in project.weights]
    
    # 5. Calculer les scores pour chaque dataset
    scored_datasets = []
    for dataset in datasets:
        # Calculer le score de pertinence
        score = calculate_relevance_score(dataset, weights)
        
        # Calculer les scores d√©taill√©s par crit√®re pour la heatmap
        criterion_scores = calculate_criterion_scores(dataset)
        
        # Cr√©er une instance DatasetScoredWithDetails
        dataset_scored = schemas.DatasetScoredWithDetails(
            id=dataset.id,
            created_at=dataset.created_at,
            updated_at=dataset.updated_at,
            dataset_name=dataset.dataset_name,
            year=dataset.year,
            objective=dataset.objective,
            access=dataset.access,
            availability=dataset.availability,
            num_citations=dataset.num_citations,
            citation_link=dataset.citation_link,
            sources=dataset.sources,
            storage_uri=dataset.storage_uri,
            instances_number=dataset.instances_number,
            features_description=dataset.features_description,
            features_number=dataset.features_number,
            domain=dataset.domain,
            representativity_description=dataset.representativity_description,
            representativity_level=dataset.representativity_level,
            sample_balance_description=dataset.sample_balance_description,
            sample_balance_level=dataset.sample_balance_level,
            split=dataset.split,
            missing_values_description=dataset.missing_values_description,
            has_missing_values=dataset.has_missing_values,
            global_missing_percentage=dataset.global_missing_percentage,
            missing_values_handling_method=dataset.missing_values_handling_method,
            temporal_factors=dataset.temporal_factors,
            metadata_provided_with_dataset=dataset.metadata_provided_with_dataset,
            external_documentation_available=dataset.external_documentation_available,
            documentation_link=dataset.documentation_link,
            task=dataset.task,
            informed_consent=dataset.informed_consent,
            transparency=dataset.transparency,
            user_control=dataset.user_control,
            equity_non_discrimination=dataset.equity_non_discrimination,
            security_measures_in_place=dataset.security_measures_in_place,
            data_quality_documented=dataset.data_quality_documented,
            data_errors_description=dataset.data_errors_description,
            anonymization_applied=dataset.anonymization_applied,
            record_keeping_policy_exists=dataset.record_keeping_policy_exists,
            purpose_limitation_respected=dataset.purpose_limitation_respected,
            accountability_defined=dataset.accountability_defined,
            score=score,
            criterion_scores=criterion_scores
        )
        scored_datasets.append(dataset_scored)
    
    # 6. Trier par score d√©croissant
    scored_datasets.sort(key=lambda x: x.score, reverse=True)
    
    logger.info(f"‚úÖ Utilisateur {current_user_id} - Recommandations pour projet {project_id}: {len(scored_datasets)} datasets")
    
    return schemas.ProjectRecommendationResponse(
        project=project,
        datasets=scored_datasets,
        total_count=len(scored_datasets)
    )


@app.post("/datasets/score", response_model=List[schemas.DatasetScoredRead])
def score_datasets(
    score_request: schemas.DatasetScoreRequest,
    current_user_id: UUID4 = Depends(get_current_user_id),
    db: Session = Depends(database.get_db)
):
    """
    Score et retourne les datasets selon les crit√®res pond√©r√©s.
    
    Args:
        score_request: Crit√®res de filtrage et poids pour le scoring
        db: Session de base de donn√©es
    
    Returns:
        List[DatasetScoredRead]: Liste des datasets scor√©s tri√©s par score d√©croissant
    """
    import logging
    logger = logging.getLogger(__name__)
    
    # DEBUG: Log des param√®tres de la requ√™te
    logger.info(f"üîç DEBUG - Utilisateur {current_user_id} - Requ√™te scoring re√ßue:")
    logger.info(f"   Filtres: {score_request.filters}")
    logger.info(f"   Poids: {score_request.weights}")
    
    # 1. Construire la requ√™te de base
    query = db.query(models.Dataset)
    total_datasets_before_filter = query.count()
    logger.info(f"   Total datasets en base: {total_datasets_before_filter}")
    
    # 2. Appliquer les filtres si fournis
    if score_request.filters:
        logger.info(f"   Application des filtres...")
        query = apply_filters(query, score_request.filters)
    
    # 3. R√©cup√©rer les datasets filtr√©s
    datasets = query.all()
    logger.info(f"   Datasets apr√®s filtrage: {len(datasets)}")
    
    if len(datasets) == 0:
        logger.warning("‚ö†Ô∏è  Aucun dataset trouv√© apr√®s filtrage - retour d'une liste vide")
        return []
    
    # 4. Calculer les scores pour chaque dataset
    scored_datasets = []
    for i, dataset in enumerate(datasets):
        score = calculate_relevance_score(dataset, score_request.weights)
        logger.info(f"   Dataset '{dataset.dataset_name}': score = {score}")
        
        # Cr√©er une instance DatasetScoredRead
        dataset_scored = schemas.DatasetScoredRead(
            id=dataset.id,
            created_at=dataset.created_at,
            updated_at=dataset.updated_at,
            dataset_name=dataset.dataset_name,
            year=dataset.year,
            objective=dataset.objective,
            access=dataset.access,
            availability=dataset.availability,
            num_citations=dataset.num_citations,
            citation_link=dataset.citation_link,
            sources=dataset.sources,
            storage_uri=dataset.storage_uri,
            instances_number=dataset.instances_number,
            features_description=dataset.features_description,
            features_number=dataset.features_number,
            domain=dataset.domain,
            representativity_description=dataset.representativity_description,
            representativity_level=dataset.representativity_level,
            sample_balance_description=dataset.sample_balance_description,
            sample_balance_level=dataset.sample_balance_level,
            split=dataset.split,
            missing_values_description=dataset.missing_values_description,
            has_missing_values=dataset.has_missing_values,
            global_missing_percentage=dataset.global_missing_percentage,
            missing_values_handling_method=dataset.missing_values_handling_method,
            temporal_factors=dataset.temporal_factors,
            metadata_provided_with_dataset=dataset.metadata_provided_with_dataset,
            external_documentation_available=dataset.external_documentation_available,
            documentation_link=dataset.documentation_link,
            task=dataset.task,
            informed_consent=dataset.informed_consent,
            transparency=dataset.transparency,
            user_control=dataset.user_control,
            equity_non_discrimination=dataset.equity_non_discrimination,
            security_measures_in_place=dataset.security_measures_in_place,
            data_quality_documented=dataset.data_quality_documented,
            data_errors_description=dataset.data_errors_description,
            anonymization_applied=dataset.anonymization_applied,
            record_keeping_policy_exists=dataset.record_keeping_policy_exists,
            purpose_limitation_respected=dataset.purpose_limitation_respected,
            accountability_defined=dataset.accountability_defined,
            score=score
        )
        scored_datasets.append(dataset_scored)
    
    # 5. Trier par score d√©croissant
    scored_datasets.sort(key=lambda x: x.score, reverse=True)
    
    logger.info(f"‚úÖ Retour de {len(scored_datasets)} datasets scor√©s")
    if scored_datasets:
        logger.info(f"   Meilleur score: {scored_datasets[0].score} ({scored_datasets[0].dataset_name})")
    
    return scored_datasets

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 